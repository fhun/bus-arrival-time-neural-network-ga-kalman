{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.2_MLP_GA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "15QOj4VlxcD62P8VCI-uyCC53PUENBRu4",
      "authorship_tag": "ABX9TyMrZ3Bhm9hl2+nlHpXynm3z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBp1TcRyY-US"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm #show a progress meter in the loop"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK5dgeE9ZOR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6463af92-1cbb-4a1b-8464-d9de6b6a7cc5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgyzQRGgNV1z"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zklVI4yPOR_s"
      },
      "source": [
        "Journey 101 ***U Wandsbek Markt to S Rübenkamp***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLSgGl3dZPUO"
      },
      "source": [
        "path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_01_12_19_data_processed.csv\"\n",
        "#path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_0420_data_processed.csv\"\n",
        "#path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_01_02_20_data_processed.csv\"\n",
        "df_proceeded = pd.read_csv(path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAIXPv37ZgEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "81b8617f-cd5b-48bd-99de-c51a36873c7a"
      },
      "source": [
        "df_proceeded"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Driving_time_s_p</th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>month</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Actual_trip_cum</th>\n",
              "      <th>Planned_trip_cum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-01-02 09:47:00</td>\n",
              "      <td>U Wandsbek Markt|Wandsbeker Allee</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>204</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-01-02 09:50:00</td>\n",
              "      <td>Wandsbeker Allee|U Straßburger Straße</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>312</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2019-01-02 09:52:00</td>\n",
              "      <td>U Straßburger Straße|U Alter Teichweg</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>408</td>\n",
              "      <td>420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2019-01-02 09:54:00</td>\n",
              "      <td>U Alter Teichweg|Habichtstraße (Mitte)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>576</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2019-01-02 09:57:00</td>\n",
              "      <td>Habichtstraße (Mitte)|U Habichtstraße</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>630</td>\n",
              "      <td>660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132959</th>\n",
              "      <td>132959</td>\n",
              "      <td>2019-12-23 08:58:00</td>\n",
              "      <td>Habichtsplatz|Neue Wöhr</td>\n",
              "      <td>1.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>864</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132960</th>\n",
              "      <td>132960</td>\n",
              "      <td>2019-12-23 09:01:00</td>\n",
              "      <td>Neue Wöhr|Hartzloh</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>930</td>\n",
              "      <td>960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132961</th>\n",
              "      <td>132961</td>\n",
              "      <td>2019-12-23 09:02:00</td>\n",
              "      <td>Hartzloh|AK Barmbek</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>990</td>\n",
              "      <td>1020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132962</th>\n",
              "      <td>132962</td>\n",
              "      <td>2019-12-23 09:03:00</td>\n",
              "      <td>AK Barmbek|Hebebrandstraße</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1122</td>\n",
              "      <td>1140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132963</th>\n",
              "      <td>132963</td>\n",
              "      <td>2019-12-23 09:05:00</td>\n",
              "      <td>Hebebrandstraße|S Rübenkamp</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1182</td>\n",
              "      <td>1260</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132964 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0                 Time  ... Actual_trip_cum  Planned_trip_cum\n",
              "0                0  2019-01-02 09:47:00  ...             204               180\n",
              "1                1  2019-01-02 09:50:00  ...             312               300\n",
              "2                2  2019-01-02 09:52:00  ...             408               420\n",
              "3                3  2019-01-02 09:54:00  ...             576               600\n",
              "4                4  2019-01-02 09:57:00  ...             630               660\n",
              "...            ...                  ...  ...             ...               ...\n",
              "132959      132959  2019-12-23 08:58:00  ...             864               900\n",
              "132960      132960  2019-12-23 09:01:00  ...             930               960\n",
              "132961      132961  2019-12-23 09:02:00  ...             990              1020\n",
              "132962      132962  2019-12-23 09:03:00  ...            1122              1140\n",
              "132963      132963  2019-12-23 09:05:00  ...            1182              1260\n",
              "\n",
              "[132964 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc-0yo2bil_d"
      },
      "source": [
        "#df_proceeded = df_proceeded.sort_values(by=['Time'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIQmqfYOZaw"
      },
      "source": [
        "Journey 102 ***S Rübenkamp to U Wandsbek Markt***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5OJ7Lm1Ocav"
      },
      "source": [
        "#path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_0420_data_processed102.csv\"\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_01_12_19_data_processed102.csv\"\n",
        "df_proceeded102 = pd.read_csv(path)\n",
        "#df_proceeded102 = df_proceeded102.sort_values(by=['Time'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z64dy9EOeru"
      },
      "source": [
        "Journey 201 ***U Wandsbek Markt to Lufthansa-Basis (Haupteingang)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Bi66sdOhIL"
      },
      "source": [
        "#path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_0420_data_processed201.csv\"\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_01_12_19_data_processed201.csv\"\n",
        "df_proceeded201 = pd.read_csv(path)\n",
        "#df_proceeded201 = df_proceeded201.sort_values(by=['Time'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxEiR1W8OkJB"
      },
      "source": [
        "Journey 202 ***Lufthansa-Basis (Haupteingang) to U Wandsbek Markt***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZdc12QvOn5h"
      },
      "source": [
        "#path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_0420_data_processed202.csv\"\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/Thesis/ist_01_12_19_data_processed202.csv\"\n",
        "df_proceeded202 = pd.read_csv(path)\n",
        "#df_proceeded202 = df_proceeded202.sort_values(by=['Time'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTty1BPGeuSL"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dShXRO_vOy3Y"
      },
      "source": [
        "Journey 101 ***U Wandsbek Markt to S Rübenkamp***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDs6hC7bZiAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d78860-0f1c-46d2-b5a6-ba183dba55f2"
      },
      "source": [
        "data = df_proceeded[['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday', 'Driving_time_s']]\n",
        "data.index = df_proceeded['Time']\n",
        "data['Precipitation'] = data['Precipitation'].astype('int')\n",
        "data['timeofday'] = data['timeofday'].astype('int')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idrT_5hSe_ix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "9de6c9fd-b163-4f6d-f212-2d196c70cce5"
      },
      "source": [
        "data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Driving_time_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:47:00</th>\n",
              "      <td>U Wandsbek Markt|Wandsbeker Allee</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>204.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:50:00</th>\n",
              "      <td>Wandsbeker Allee|U Straßburger Straße</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>108.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:52:00</th>\n",
              "      <td>U Straßburger Straße|U Alter Teichweg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:54:00</th>\n",
              "      <td>U Alter Teichweg|Habichtstraße (Mitte)</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>168.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:57:00</th>\n",
              "      <td>Habichtstraße (Mitte)|U Habichtstraße</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 08:58:00</th>\n",
              "      <td>Habichtsplatz|Neue Wöhr</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>144.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 09:01:00</th>\n",
              "      <td>Neue Wöhr|Hartzloh</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 09:02:00</th>\n",
              "      <td>Hartzloh|AK Barmbek</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 09:03:00</th>\n",
              "      <td>AK Barmbek|Hebebrandstraße</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 09:05:00</th>\n",
              "      <td>Hebebrandstraße|S Rübenkamp</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132964 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Node A to Node B  ...  Driving_time_s\n",
              "Time                                                         ...                \n",
              "2019-01-02 09:47:00       U Wandsbek Markt|Wandsbeker Allee  ...           204.0\n",
              "2019-01-02 09:50:00   Wandsbeker Allee|U Straßburger Straße  ...           108.0\n",
              "2019-01-02 09:52:00   U Straßburger Straße|U Alter Teichweg  ...            96.0\n",
              "2019-01-02 09:54:00  U Alter Teichweg|Habichtstraße (Mitte)  ...           168.0\n",
              "2019-01-02 09:57:00   Habichtstraße (Mitte)|U Habichtstraße  ...            54.0\n",
              "...                                                     ...  ...             ...\n",
              "2019-12-23 08:58:00                 Habichtsplatz|Neue Wöhr  ...           144.0\n",
              "2019-12-23 09:01:00                      Neue Wöhr|Hartzloh  ...            66.0\n",
              "2019-12-23 09:02:00                     Hartzloh|AK Barmbek  ...            60.0\n",
              "2019-12-23 09:03:00              AK Barmbek|Hebebrandstraße  ...           132.0\n",
              "2019-12-23 09:05:00             Hebebrandstraße|S Rübenkamp  ...            60.0\n",
              "\n",
              "[132964 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tWZpdFvMCOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d5ccac-fa94-4e00-dedd-f7f63df831fc"
      },
      "source": [
        "data.loc[data.Precipitation == -499 ]=0 #wrong data in weather data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyIgfLyPMFB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "e4c8e075-3440-4130-adde-fefc56d370ab"
      },
      "source": [
        "data.loc[data.Precipitation == -499 ]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Driving_time_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Node A to Node B, Precipitation, dayofweek, timeofday, Driving_time_s]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAzQCxULMIV4"
      },
      "source": [
        "#data = data.loc[data['dayofweek'].isin([0])]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC8MJMF3OtpQ"
      },
      "source": [
        "#filter only the full correct sequence tours\n",
        "data = data.loc[data['Node A to Node B'].isin(['U Wandsbek Markt|Wandsbeker Allee',\n",
        "       'Wandsbeker Allee|U Straßburger Straße',\n",
        "       'U Straßburger Straße|U Alter Teichweg',\n",
        "       'U Alter Teichweg|Habichtstraße (Mitte)',\n",
        "       'Habichtstraße (Mitte)|U Habichtstraße',\n",
        "       'U Habichtstraße|Habichtsplatz', 'Habichtsplatz|Neue Wöhr',\n",
        "       'Neue Wöhr|Hartzloh', 'Hartzloh|AK Barmbek',\n",
        "       'AK Barmbek|Hebebrandstraße', 'Hebebrandstraße|S Rübenkamp'])]\n",
        "df_proceeded = data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLiw2wEdcRyU"
      },
      "source": [
        "columns_to_category = ['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday']\n",
        "data[columns_to_category] = data[columns_to_category].astype('category') # change datetypes to category"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUdJ_TvledAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d0b4d5-ecf6-4f2b-fbb3-2aeae63321b5"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Node A to Node B    category\n",
              "Precipitation       category\n",
              "dayofweek           category\n",
              "timeofday           category\n",
              "Driving_time_s       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP7fpPv5gGiW"
      },
      "source": [
        "## One-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngmjPjYBgSGb"
      },
      "source": [
        "One-hot encode the categorical feautures.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyXqx2CGfxN4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "3d3d9a1a-5026-4cc2-a945-2978de60d1e2"
      },
      "source": [
        "data = pd.get_dummies(data, columns=columns_to_category) # One hot encoding the categories\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>Node A to Node B_AK Barmbek|Hebebrandstraße</th>\n",
              "      <th>Node A to Node B_Habichtsplatz|Neue Wöhr</th>\n",
              "      <th>Node A to Node B_Habichtstraße (Mitte)|U Habichtstraße</th>\n",
              "      <th>Node A to Node B_Hartzloh|AK Barmbek</th>\n",
              "      <th>Node A to Node B_Hebebrandstraße|S Rübenkamp</th>\n",
              "      <th>Node A to Node B_Neue Wöhr|Hartzloh</th>\n",
              "      <th>Node A to Node B_U Alter Teichweg|Habichtstraße (Mitte)</th>\n",
              "      <th>Node A to Node B_U Habichtstraße|Habichtsplatz</th>\n",
              "      <th>Node A to Node B_U Straßburger Straße|U Alter Teichweg</th>\n",
              "      <th>Node A to Node B_U Wandsbek Markt|Wandsbeker Allee</th>\n",
              "      <th>Node A to Node B_Wandsbeker Allee|U Straßburger Straße</th>\n",
              "      <th>Precipitation_0</th>\n",
              "      <th>Precipitation_1</th>\n",
              "      <th>dayofweek_0</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>dayofweek_5</th>\n",
              "      <th>dayofweek_6</th>\n",
              "      <th>timeofday_0</th>\n",
              "      <th>timeofday_1</th>\n",
              "      <th>timeofday_2</th>\n",
              "      <th>timeofday_3</th>\n",
              "      <th>timeofday_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:47:00</th>\n",
              "      <td>204.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:50:00</th>\n",
              "      <td>108.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:52:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:54:00</th>\n",
              "      <td>168.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 09:57:00</th>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Driving_time_s  ...  timeofday_4\n",
              "Time                                 ...             \n",
              "2019-01-02 09:47:00           204.0  ...            0\n",
              "2019-01-02 09:50:00           108.0  ...            0\n",
              "2019-01-02 09:52:00            96.0  ...            0\n",
              "2019-01-02 09:54:00           168.0  ...            0\n",
              "2019-01-02 09:57:00            54.0  ...            0\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqNZvpJj3Ysa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041a9259-970f-41ea-983b-ad4cd5e0a4a4"
      },
      "source": [
        "data.describe"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                      Driving_time_s  ...  timeofday_4\n",
              "Time                                 ...             \n",
              "2019-01-02 09:47:00           204.0  ...            0\n",
              "2019-01-02 09:50:00           108.0  ...            0\n",
              "2019-01-02 09:52:00            96.0  ...            0\n",
              "2019-01-02 09:54:00           168.0  ...            0\n",
              "2019-01-02 09:57:00            54.0  ...            0\n",
              "...                             ...  ...          ...\n",
              "2019-12-23 08:58:00           144.0  ...            0\n",
              "2019-12-23 09:01:00            66.0  ...            0\n",
              "2019-12-23 09:02:00            60.0  ...            0\n",
              "2019-12-23 09:03:00           132.0  ...            0\n",
              "2019-12-23 09:05:00            60.0  ...            0\n",
              "\n",
              "[132964 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGvKCxKSO9Zv"
      },
      "source": [
        "data101 = data.copy()\n",
        "#data101"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEUSFuXnPnVj"
      },
      "source": [
        "## Preprocessing with other journeys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoXrAJDkPBPb"
      },
      "source": [
        "Journey 102 ***S Rübenkamp to U Wandsbek Markt***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMN02Xn0PL5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5addc99f-d0bf-4e45-b4e3-da64c56b24c8"
      },
      "source": [
        "data = df_proceeded102[['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday', 'Driving_time_s']]\n",
        "data.index = df_proceeded102['Time']\n",
        "data['Precipitation'] = data['Precipitation'].astype('int')\n",
        "data['timeofday'] = data['timeofday'].astype('int')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "T8E0zKgyMBpi",
        "outputId": "002ceef0-9b62-4646-d23a-c05e997bff9e"
      },
      "source": [
        "data.loc[data.Precipitation == -499 ]=0\n",
        "data.loc[data.Precipitation == -499 ]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Driving_time_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Node A to Node B, Precipitation, dayofweek, timeofday, Driving_time_s]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMhTIyTXMpX6"
      },
      "source": [
        "data = data.loc[data['Node A to Node B'].isin(['U Straßburger Straße|Wandsbeker Allee',\n",
        "'AK Barmbek|Hartzloh',\n",
        "'U Habichtstraße|Habichtstraße (Mitte)',\n",
        "'Habichtsplatz|U Habichtstraße',\n",
        "'U Alter Teichweg|U Straßburger Straße',\n",
        "'Wandsbeker Allee|U Wandsbek Markt',\n",
        "'Hartzloh|Habichtsplatz',\n",
        "'S Rübenkamp|AK Barmbek',\n",
        "'Habichtstraße (Mitte)|U Alter Teichweg'])]\n",
        "df_proceeded102 = data"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5voDsmlDPNLc"
      },
      "source": [
        "columns_to_category = ['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday']\n",
        "data[columns_to_category] = data[columns_to_category].astype('category') # change datetypes to category"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CNHFnEBPPyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "def7732c-25b4-4a97-88ff-0a83f650377d"
      },
      "source": [
        "data = pd.get_dummies(data, columns=columns_to_category) # One hot encoding the categories\n",
        "data[:50]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>Node A to Node B_AK Barmbek|Hartzloh</th>\n",
              "      <th>Node A to Node B_Habichtsplatz|U Habichtstraße</th>\n",
              "      <th>Node A to Node B_Habichtstraße (Mitte)|U Alter Teichweg</th>\n",
              "      <th>Node A to Node B_Hartzloh|Habichtsplatz</th>\n",
              "      <th>Node A to Node B_S Rübenkamp|AK Barmbek</th>\n",
              "      <th>Node A to Node B_U Alter Teichweg|U Straßburger Straße</th>\n",
              "      <th>Node A to Node B_U Habichtstraße|Habichtstraße (Mitte)</th>\n",
              "      <th>Node A to Node B_U Straßburger Straße|Wandsbeker Allee</th>\n",
              "      <th>Node A to Node B_Wandsbeker Allee|U Wandsbek Markt</th>\n",
              "      <th>Precipitation_0</th>\n",
              "      <th>Precipitation_1</th>\n",
              "      <th>dayofweek_0</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>dayofweek_5</th>\n",
              "      <th>dayofweek_6</th>\n",
              "      <th>timeofday_0</th>\n",
              "      <th>timeofday_1</th>\n",
              "      <th>timeofday_2</th>\n",
              "      <th>timeofday_3</th>\n",
              "      <th>timeofday_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:25:00</th>\n",
              "      <td>186.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:28:00</th>\n",
              "      <td>90.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:29:00</th>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:32:00</th>\n",
              "      <td>78.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:33:00</th>\n",
              "      <td>90.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:35:00</th>\n",
              "      <td>126.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:38:00</th>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:40:00</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:41:00</th>\n",
              "      <td>126.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:45:00</th>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:48:00</th>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:49:00</th>\n",
              "      <td>156.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:52:00</th>\n",
              "      <td>78.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:53:00</th>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:55:00</th>\n",
              "      <td>174.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:58:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 12:00:00</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 12:01:00</th>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:05:00</th>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:08:00</th>\n",
              "      <td>78.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:09:00</th>\n",
              "      <td>156.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:12:00</th>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:13:00</th>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:15:00</th>\n",
              "      <td>186.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:18:00</th>\n",
              "      <td>108.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:20:00</th>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 13:21:00</th>\n",
              "      <td>126.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:05:00</th>\n",
              "      <td>180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:08:00</th>\n",
              "      <td>108.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:10:00</th>\n",
              "      <td>120.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:12:00</th>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:13:00</th>\n",
              "      <td>108.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:14:00</th>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:17:00</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:18:00</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 05:19:00</th>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:45:00</th>\n",
              "      <td>222.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:47:00</th>\n",
              "      <td>48.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:48:00</th>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:50:00</th>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:51:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:52:00</th>\n",
              "      <td>150.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:55:00</th>\n",
              "      <td>48.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:56:00</th>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 20:57:00</th>\n",
              "      <td>156.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 21:45:00</th>\n",
              "      <td>198.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 21:47:00</th>\n",
              "      <td>54.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 21:48:00</th>\n",
              "      <td>156.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 21:50:00</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03 21:51:00</th>\n",
              "      <td>72.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Driving_time_s  ...  timeofday_4\n",
              "Time                                 ...             \n",
              "2019-01-02 10:25:00           186.0  ...            0\n",
              "2019-01-02 10:28:00            90.0  ...            0\n",
              "2019-01-02 10:29:00           138.0  ...            0\n",
              "2019-01-02 10:32:00            78.0  ...            0\n",
              "2019-01-02 10:33:00            90.0  ...            0\n",
              "2019-01-02 10:35:00           126.0  ...            0\n",
              "2019-01-02 10:38:00           138.0  ...            0\n",
              "2019-01-02 10:40:00            60.0  ...            0\n",
              "2019-01-02 10:41:00           126.0  ...            0\n",
              "2019-01-02 11:45:00           174.0  ...            0\n",
              "2019-01-02 11:48:00            60.0  ...            0\n",
              "2019-01-02 11:49:00           156.0  ...            0\n",
              "2019-01-02 11:52:00            78.0  ...            0\n",
              "2019-01-02 11:53:00           102.0  ...            0\n",
              "2019-01-02 11:55:00           174.0  ...            0\n",
              "2019-01-02 11:58:00            96.0  ...            0\n",
              "2019-01-02 12:00:00            30.0  ...            0\n",
              "2019-01-02 12:01:00           144.0  ...            0\n",
              "2019-01-02 13:05:00           144.0  ...            0\n",
              "2019-01-02 13:08:00            78.0  ...            0\n",
              "2019-01-02 13:09:00           156.0  ...            0\n",
              "2019-01-02 13:12:00            66.0  ...            0\n",
              "2019-01-02 13:13:00           120.0  ...            0\n",
              "2019-01-02 13:15:00           186.0  ...            0\n",
              "2019-01-02 13:18:00           108.0  ...            0\n",
              "2019-01-02 13:20:00            54.0  ...            0\n",
              "2019-01-02 13:21:00           126.0  ...            0\n",
              "2019-01-03 05:05:00           180.0  ...            0\n",
              "2019-01-03 05:08:00           108.0  ...            0\n",
              "2019-01-03 05:10:00           120.0  ...            0\n",
              "2019-01-03 05:12:00            42.0  ...            0\n",
              "2019-01-03 05:13:00           108.0  ...            0\n",
              "2019-01-03 05:14:00           144.0  ...            0\n",
              "2019-01-03 05:17:00            60.0  ...            0\n",
              "2019-01-03 05:18:00            30.0  ...            0\n",
              "2019-01-03 05:19:00           144.0  ...            0\n",
              "2019-01-03 20:45:00           222.0  ...            1\n",
              "2019-01-03 20:47:00            48.0  ...            1\n",
              "2019-01-03 20:48:00           132.0  ...            1\n",
              "2019-01-03 20:50:00            42.0  ...            1\n",
              "2019-01-03 20:51:00            96.0  ...            1\n",
              "2019-01-03 20:52:00           150.0  ...            1\n",
              "2019-01-03 20:55:00            48.0  ...            1\n",
              "2019-01-03 20:56:00            42.0  ...            1\n",
              "2019-01-03 20:57:00           156.0  ...            1\n",
              "2019-01-03 21:45:00           198.0  ...            1\n",
              "2019-01-03 21:47:00            54.0  ...            1\n",
              "2019-01-03 21:48:00           156.0  ...            1\n",
              "2019-01-03 21:50:00            60.0  ...            1\n",
              "2019-01-03 21:51:00            72.0  ...            1\n",
              "\n",
              "[50 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxtY2PbMPSbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "outputId": "77092a47-2b60-4054-ec3e-8315cc549204"
      },
      "source": [
        "data102 = data.copy()\n",
        "data102"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>Node A to Node B_AK Barmbek|Hartzloh</th>\n",
              "      <th>Node A to Node B_Habichtsplatz|U Habichtstraße</th>\n",
              "      <th>Node A to Node B_Habichtstraße (Mitte)|U Alter Teichweg</th>\n",
              "      <th>Node A to Node B_Hartzloh|Habichtsplatz</th>\n",
              "      <th>Node A to Node B_S Rübenkamp|AK Barmbek</th>\n",
              "      <th>Node A to Node B_U Alter Teichweg|U Straßburger Straße</th>\n",
              "      <th>Node A to Node B_U Habichtstraße|Habichtstraße (Mitte)</th>\n",
              "      <th>Node A to Node B_U Straßburger Straße|Wandsbeker Allee</th>\n",
              "      <th>Node A to Node B_Wandsbeker Allee|U Wandsbek Markt</th>\n",
              "      <th>Precipitation_0</th>\n",
              "      <th>Precipitation_1</th>\n",
              "      <th>dayofweek_0</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>dayofweek_5</th>\n",
              "      <th>dayofweek_6</th>\n",
              "      <th>timeofday_0</th>\n",
              "      <th>timeofday_1</th>\n",
              "      <th>timeofday_2</th>\n",
              "      <th>timeofday_3</th>\n",
              "      <th>timeofday_4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:25:00</th>\n",
              "      <td>186.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:28:00</th>\n",
              "      <td>90.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:29:00</th>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:32:00</th>\n",
              "      <td>78.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:33:00</th>\n",
              "      <td>90.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-14 18:21:00</th>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-14 18:23:00</th>\n",
              "      <td>132.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-14 18:26:00</th>\n",
              "      <td>408.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-14 18:28:00</th>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-14 18:29:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62060 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Driving_time_s  ...  timeofday_4\n",
              "Time                                 ...             \n",
              "2019-01-02 10:25:00           186.0  ...            0\n",
              "2019-01-02 10:28:00            90.0  ...            0\n",
              "2019-01-02 10:29:00           138.0  ...            0\n",
              "2019-01-02 10:32:00            78.0  ...            0\n",
              "2019-01-02 10:33:00            90.0  ...            0\n",
              "...                             ...  ...          ...\n",
              "2019-12-14 18:21:00            42.0  ...            0\n",
              "2019-12-14 18:23:00           132.0  ...            0\n",
              "2019-12-14 18:26:00           408.0  ...            0\n",
              "2019-12-14 18:28:00           102.0  ...            0\n",
              "2019-12-14 18:29:00            96.0  ...            0\n",
              "\n",
              "[62060 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcrJ3n7fPVey"
      },
      "source": [
        "Jouney 201 ***U Wandsbek Markt to Lufthansa-Basis (Haupteingang)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw6FHyowPphg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a14f0d6-2cc3-46a9-c38b-bda2a34ce733"
      },
      "source": [
        "data = df_proceeded201[['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday', 'Driving_time_s']]\n",
        "data.index = df_proceeded201['Time']\n",
        "data['Precipitation'] = data['Precipitation'].astype('int')\n",
        "data['timeofday'] = data['timeofday'].astype('int')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "xq0gaaVyC1RZ",
        "outputId": "8eefbcaa-4975-4d9d-a7b5-cf8f7232b07e"
      },
      "source": [
        "data.loc[data.Precipitation == -499 ]=0\n",
        "data.loc[data.Precipitation == -499 ]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Driving_time_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Node A to Node B, Precipitation, dayofweek, timeofday, Driving_time_s]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oCb5ks3C5BI"
      },
      "source": [
        "data = data.loc[data['Node A to Node B'].isin(['Kapstadtring|Manilabrücke',\n",
        "'U Alsterdorf|Hindenburgstraße',\n",
        "'Habichtstraße (Mitte)|U Habichtstraße',\n",
        "'Neue Wöhr|Hartzloh',\n",
        "'Hartzloh|AK Barmbek',\n",
        "'Brabandstraße|Moltrechtweg',\n",
        "'Alsterkrugchaussee (Mitte)|Obenhauptstraße',\n",
        "'Manilabrücke|Sydneystraße',\n",
        "'Hebebrandstraße|S Rübenkamp',\n",
        "'U Habichtstraße|Habichtsplatz',\n",
        "'Moltrechtweg|Alsterkrugchaussee (Mitte)',\n",
        "'Hindenburgstraße|Brabandstraße',\n",
        "'S Rübenkamp|Kapstadtring',\n",
        "'Wandsbeker Allee|U Straßburger Straße',\n",
        "'Sydneystraße|U Alsterdorf',\n",
        "'Habichtsplatz|Neue Wöhr',\n",
        "'AK Barmbek|Hebebrandstraße',\n",
        "'U Straßburger Straße|U Alter Teichweg',\n",
        "'Obenhauptstraße|Lufthansa-Basis (Haupteingang)',\n",
        "'U Alter Teichweg|Habichtstraße (Mitte)',\n",
        "'U Wandsbek Markt|Wandsbeker Allee',\n",
        "])]\n",
        "df_proceeded201 = data"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJCYBpJJPwGT"
      },
      "source": [
        "columns_to_category = ['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday']\n",
        "data[columns_to_category] = data[columns_to_category].astype('category') # change datetypes to category"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOGuVMOP1xG"
      },
      "source": [
        "data = pd.get_dummies(data, columns=columns_to_category) # One hot encoding the categories\n",
        "#data[:50]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7vEjg1uP4yW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "outputId": "9f33980c-44bf-48d6-f9fb-a6b8813c6702"
      },
      "source": [
        "data201 = data.copy()\n",
        "data201"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>Node A to Node B_AK Barmbek|Hebebrandstraße</th>\n",
              "      <th>Node A to Node B_Alsterkrugchaussee (Mitte)|Obenhauptstraße</th>\n",
              "      <th>Node A to Node B_Brabandstraße|Moltrechtweg</th>\n",
              "      <th>Node A to Node B_Habichtsplatz|Neue Wöhr</th>\n",
              "      <th>Node A to Node B_Habichtstraße (Mitte)|U Habichtstraße</th>\n",
              "      <th>Node A to Node B_Hartzloh|AK Barmbek</th>\n",
              "      <th>Node A to Node B_Hebebrandstraße|S Rübenkamp</th>\n",
              "      <th>Node A to Node B_Hindenburgstraße|Brabandstraße</th>\n",
              "      <th>Node A to Node B_Kapstadtring|Manilabrücke</th>\n",
              "      <th>Node A to Node B_Manilabrücke|Sydneystraße</th>\n",
              "      <th>Node A to Node B_Moltrechtweg|Alsterkrugchaussee (Mitte)</th>\n",
              "      <th>Node A to Node B_Neue Wöhr|Hartzloh</th>\n",
              "      <th>Node A to Node B_Obenhauptstraße|Lufthansa-Basis (Haupteingang)</th>\n",
              "      <th>Node A to Node B_S Rübenkamp|Kapstadtring</th>\n",
              "      <th>Node A to Node B_Sydneystraße|U Alsterdorf</th>\n",
              "      <th>Node A to Node B_U Alsterdorf|Hindenburgstraße</th>\n",
              "      <th>Node A to Node B_U Alter Teichweg|Habichtstraße (Mitte)</th>\n",
              "      <th>Node A to Node B_U Habichtstraße|Habichtsplatz</th>\n",
              "      <th>Node A to Node B_U Straßburger Straße|U Alter Teichweg</th>\n",
              "      <th>Node A to Node B_U Wandsbek Markt|Wandsbeker Allee</th>\n",
              "      <th>Node A to Node B_Wandsbeker Allee|U Straßburger Straße</th>\n",
              "      <th>Precipitation_0</th>\n",
              "      <th>Precipitation_1</th>\n",
              "      <th>dayofweek_0</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>timeofday_0</th>\n",
              "      <th>timeofday_1</th>\n",
              "      <th>timeofday_2</th>\n",
              "      <th>timeofday_3</th>\n",
              "      <th>timeofday_4</th>\n",
              "      <th>timeofday_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 10:57:00</th>\n",
              "      <td>186.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:00:00</th>\n",
              "      <td>84.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:02:00</th>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:04:00</th>\n",
              "      <td>162.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:07:00</th>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 07:33:00</th>\n",
              "      <td>90.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 07:35:00</th>\n",
              "      <td>66.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 07:36:00</th>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 07:38:00</th>\n",
              "      <td>72.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23 07:39:00</th>\n",
              "      <td>144.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162080 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Driving_time_s  ...  timeofday_5\n",
              "Time                                 ...             \n",
              "2019-01-02 10:57:00           186.0  ...            0\n",
              "2019-01-02 11:00:00            84.0  ...            0\n",
              "2019-01-02 11:02:00           102.0  ...            0\n",
              "2019-01-02 11:04:00           162.0  ...            0\n",
              "2019-01-02 11:07:00            36.0  ...            0\n",
              "...                             ...  ...          ...\n",
              "2019-12-23 07:33:00            90.0  ...            0\n",
              "2019-12-23 07:35:00            66.0  ...            0\n",
              "2019-12-23 07:36:00           102.0  ...            0\n",
              "2019-12-23 07:38:00            72.0  ...            0\n",
              "2019-12-23 07:39:00           144.0  ...            0\n",
              "\n",
              "[162080 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLdO4NQP56n"
      },
      "source": [
        "Route 202 ***Lufthansa-Basis (Haupteingang) to U Wandsbek Markt***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPGb_2fP_2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7817f9d7-13cc-446b-bb0b-c3c7a18027b5"
      },
      "source": [
        "data = df_proceeded202[['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday', 'Driving_time_s']]\n",
        "data.index = df_proceeded202['Time']\n",
        "data['Precipitation'] = data['Precipitation'].astype('int')\n",
        "data['timeofday'] = data['timeofday'].astype('int')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "T3Fc7VrFDiwi",
        "outputId": "6092345b-5500-4b0a-c931-4404d1f645dd"
      },
      "source": [
        "data.loc[data.Precipitation == -499 ]=0\n",
        "data.loc[data.Precipitation == -499 ]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Node A to Node B</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>timeofday</th>\n",
              "      <th>Driving_time_s</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Node A to Node B, Precipitation, dayofweek, timeofday, Driving_time_s]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNC2FLxSDlql"
      },
      "source": [
        "data = data.loc[data['Node A to Node B'].isin(['Lufthansa-Basis (Haupteingang)|Obenhauptstraße',\n",
        "        'Obenhauptstraße|Alsterkrugchaussee (Mitte)',\n",
        "        'Alsterkrugchaussee (Mitte)|Moltrechtweg',\n",
        "        'Moltrechtweg|Brabandstraße', 'Brabandstraße|Hindenburgstraße',\n",
        "        'Hindenburgstraße|U Alsterdorf', 'U Alsterdorf|Sydneystraße',\n",
        "        'Sydneystraße|Manilabrücke', 'Manilabrücke|Kapstadtring',\n",
        "        'Kapstadtring|S Rübenkamp', 'S Rübenkamp|AK Barmbek', 'AK Barmbek|Hartzloh',\n",
        "        'Hartzloh|Habichtsplatz', 'Habichtsplatz|U Habichtstraße',\n",
        "        'U Habichtstraße|Habichtstraße (Mitte)',\n",
        "        'Habichtstraße (Mitte)|U Alter Teichweg',\n",
        "        'U Alter Teichweg|U Straßburger Straße',\n",
        "        'U Straßburger Straße|Wandsbeker Allee',\n",
        "        'Wandsbeker Allee|U Wandsbek Markt'])]\n",
        "df_proceeded202 = data"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRW5qSTnQBKq"
      },
      "source": [
        "columns_to_category = ['Node A to Node B', 'Precipitation', 'dayofweek', 'timeofday']\n",
        "data[columns_to_category] = data[columns_to_category].astype('category') # change datetypes to category"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGKpSFYaQNar"
      },
      "source": [
        "data = pd.get_dummies(data, columns=columns_to_category) # One hot encoding the categories\n",
        "#data[:50]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX0K6hlXQDyi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "outputId": "38d02e29-3caf-420e-bd19-6e2e5f8c3fdd"
      },
      "source": [
        "data202 = data.copy()\n",
        "data202"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Driving_time_s</th>\n",
              "      <th>Node A to Node B_AK Barmbek|Hartzloh</th>\n",
              "      <th>Node A to Node B_Alsterkrugchaussee (Mitte)|Moltrechtweg</th>\n",
              "      <th>Node A to Node B_Brabandstraße|Hindenburgstraße</th>\n",
              "      <th>Node A to Node B_Habichtsplatz|U Habichtstraße</th>\n",
              "      <th>Node A to Node B_Habichtstraße (Mitte)|U Alter Teichweg</th>\n",
              "      <th>Node A to Node B_Hartzloh|Habichtsplatz</th>\n",
              "      <th>Node A to Node B_Hindenburgstraße|U Alsterdorf</th>\n",
              "      <th>Node A to Node B_Kapstadtring|S Rübenkamp</th>\n",
              "      <th>Node A to Node B_Lufthansa-Basis (Haupteingang)|Obenhauptstraße</th>\n",
              "      <th>Node A to Node B_Manilabrücke|Kapstadtring</th>\n",
              "      <th>Node A to Node B_Moltrechtweg|Brabandstraße</th>\n",
              "      <th>Node A to Node B_Obenhauptstraße|Alsterkrugchaussee (Mitte)</th>\n",
              "      <th>Node A to Node B_S Rübenkamp|AK Barmbek</th>\n",
              "      <th>Node A to Node B_Sydneystraße|Manilabrücke</th>\n",
              "      <th>Node A to Node B_U Alsterdorf|Sydneystraße</th>\n",
              "      <th>Node A to Node B_U Alter Teichweg|U Straßburger Straße</th>\n",
              "      <th>Node A to Node B_U Habichtstraße|Habichtstraße (Mitte)</th>\n",
              "      <th>Node A to Node B_U Straßburger Straße|Wandsbeker Allee</th>\n",
              "      <th>Node A to Node B_Wandsbeker Allee|U Wandsbek Markt</th>\n",
              "      <th>Precipitation_0</th>\n",
              "      <th>Precipitation_1</th>\n",
              "      <th>dayofweek_0</th>\n",
              "      <th>dayofweek_1</th>\n",
              "      <th>dayofweek_2</th>\n",
              "      <th>dayofweek_3</th>\n",
              "      <th>dayofweek_4</th>\n",
              "      <th>timeofday_0</th>\n",
              "      <th>timeofday_1</th>\n",
              "      <th>timeofday_2</th>\n",
              "      <th>timeofday_3</th>\n",
              "      <th>timeofday_4</th>\n",
              "      <th>timeofday_5</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:40:00</th>\n",
              "      <td>186.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:42:00</th>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:43:00</th>\n",
              "      <td>60.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:45:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-02 11:46:00</th>\n",
              "      <td>138.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-13 19:03:00</th>\n",
              "      <td>210.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-13 19:04:00</th>\n",
              "      <td>210.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-13 19:07:00</th>\n",
              "      <td>258.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-13 19:09:00</th>\n",
              "      <td>96.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-13 19:10:00</th>\n",
              "      <td>156.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92862 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Driving_time_s  ...  timeofday_5\n",
              "Time                                 ...             \n",
              "2019-01-02 11:40:00           186.0  ...            0\n",
              "2019-01-02 11:42:00            30.0  ...            0\n",
              "2019-01-02 11:43:00            60.0  ...            0\n",
              "2019-01-02 11:45:00            96.0  ...            0\n",
              "2019-01-02 11:46:00           138.0  ...            0\n",
              "...                             ...  ...          ...\n",
              "2019-12-13 19:03:00           210.0  ...            1\n",
              "2019-12-13 19:04:00           210.0  ...            1\n",
              "2019-12-13 19:07:00           258.0  ...            1\n",
              "2019-12-13 19:09:00            96.0  ...            1\n",
              "2019-12-13 19:10:00           156.0  ...            1\n",
              "\n",
              "[92862 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWr1tngbQS9t"
      },
      "source": [
        "# Select route to implement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27vcUnOvQWAr"
      },
      "source": [
        "#select the route one by one\n",
        "route = 202\n",
        "month = 4\n",
        "\n",
        "if route == 101:\n",
        "  #route 101\n",
        "  data = data101.copy()\n",
        "  path_end = \"data101\"\n",
        "  path_name = \"Route 101 U Wandsbek Markt to S Rübenkamp\"\n",
        "  #bs = 2**4\n",
        "  #bs_name = str(bs)\n",
        "  #n_layers = 3\n",
        "\n",
        "elif route ==102:\n",
        "  #route 102\n",
        "  data = data102.copy()\n",
        "  path_end = \"data102\"\n",
        "  path_name = \"Route 102 S Rübenkamp to U Wandsbek Markt\"\n",
        "  #bs = 2**7\n",
        "  #bs_name = str(bs)\n",
        "  #n_layers = 2\n",
        "\n",
        "elif route == 201:\n",
        "  #route 201\n",
        "  data = data201.copy()\n",
        "  path_end = \"data201\"\n",
        "  path_name = \"Route 201 U Wandsbek Markt to Lufthansa-Basis (Haupteingang)\"\n",
        "  #bs = 2**6\n",
        "  #bs_name = str(bs)\n",
        "  #n_layers = 2\n",
        "\n",
        "elif route == 202:\n",
        "#route 202\n",
        "  data = data202.copy()\n",
        "  path_end = \"data202\"\n",
        "  path_name = \"Route 202 Lufthansa-Basis (Haupteingang) to U Wandsbek Markt\"\n",
        "  #bs = 2**6\n",
        "  #bs_name = str(bs)\n",
        "  #n_layers = 2\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgEcIx1lxEc6"
      },
      "source": [
        "data = data.loc[pd.to_datetime(data.index).month == month]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7MA4pvra7yU"
      },
      "source": [
        "#Import data to collect results and compare\n",
        "comb_result = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/combine_result_\"+path_end+\"_m\"+str(month)+\".csv\")\n",
        "comb_result_rmse = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/combine_result_rmse_\"+path_end+\"_m\"+str(month)+\".csv\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLg54F00aHr"
      },
      "source": [
        "# Feature scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXKas5PI04X9"
      },
      "source": [
        "def df_scaling(df, target_column='target'):\n",
        "    df = df.copy()\n",
        "\n",
        "    # move traget function to last column of the dataframe\n",
        "    df['target'] = df[target_column] # Make a copy of the target column to the last column\n",
        "    df = df.drop(columns=[target_column]) # Drop the original target column\n",
        "    \n",
        "    target_location = df.shape[1] - 1 # column index number of target\n",
        "\n",
        "    \n",
        "    #Split with day of the month\n",
        "    s =pd.to_datetime(data.index).day.tolist()\n",
        "\n",
        "    split_index_val = s.index(15) #validation set is cover on 3th week\n",
        "    split_index_test = s.index(23) #test set covers last week\n",
        "    \n",
        "    '''\n",
        "    #Split with month and first week\n",
        "    s =pd.to_datetime(df.index).month\n",
        "    d = pd.to_datetime(df.index).day\n",
        "\n",
        "    split_index_val = np.where((s == 2))[0][0]\n",
        "    split_index_test = np.where((s == 2) & (d == 11))[0][0]\n",
        "\n",
        "    train = df[:split_index_val]\n",
        "    val = df[split_index_val:split_index_test]\n",
        "    test = df[split_index_test:]\n",
        "    '''\n",
        "    '''\n",
        "    #Split with month\n",
        "    s =pd.to_datetime(df.index).month\n",
        "    d = pd.to_datetime(df.index).day\n",
        "\n",
        "    split_index_val = np.where((s == 4))[0][0]\n",
        "    split_index_test = np.where((s == 5) )[0][0] #& (d == 11)\n",
        "    split_index_end = np.where((s == 6) )[0][0]\n",
        "    '''\n",
        "    train = df[:split_index_val]\n",
        "    val = df[split_index_val:split_index_test]\n",
        "    test = df[split_index_test:] #split_index_end\n",
        "\n",
        "    # features scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    # fit scaler\n",
        "    scaler.fit(train)\n",
        "    # transform training dataset\n",
        "    train = scaler.transform(train)\n",
        "    # transform validation dataset\n",
        "    val = scaler.transform(val)\n",
        "    # transform test dataset\n",
        "    test = scaler.transform(test)\n",
        "\n",
        "    # ...train\n",
        "    X_train = train[:, :target_location]\n",
        "    y_train = train[:, target_location]\n",
        "\n",
        "    # ...validation\n",
        "    X_val = val[:, :target_location]\n",
        "    y_val = val[:, target_location]\n",
        "\n",
        "    # ...test\n",
        "    X_test = test[:, :target_location]\n",
        "    y_test = test[:, target_location] \n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, split_index_test, scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFFvVhA47SBl"
      },
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test, split_index_test, scaler = df_scaling(df=data, target_column='Driving_time_s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pcU1kHX8ZFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771df8b-a503-48e3-eaf5-077ada230658"
      },
      "source": [
        "print('X_train_shape: ', X_train.shape,' ', 'X_test_shape: ', X_test.shape)\n",
        "print('y_train_shape: ', y_train.shape,' ', 'y_test_shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_shape:  (9065, 32)   X_test_shape:  (1441, 32)\n",
            "y_train_shape:  (9065,)   y_test_shape:  (1441,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feIvsKi2Tfeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858c750a-7aaa-4bd8-b29d-edbce3b18783"
      },
      "source": [
        "date_time = pd.to_datetime(data.index)\n",
        "#plot_cols = ['T (degC)', 'p (mbar)', 'rho (g/m**3)']\n",
        "plot_features = data['Driving_time_s']\n",
        "plot_features.index = date_time\n",
        "_ = plot_features.plot()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6VYHgkItcXb"
      },
      "source": [
        "# MLP model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHBG9ECuror",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c809b7-5264-40f5-d087-72152ee98b68"
      },
      "source": [
        "!pip show keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: Keras\n",
            "Version: 2.4.3\n",
            "Summary: Deep Learning for humans\n",
            "Home-page: https://github.com/keras-team/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: pyyaml, numpy, h5py, scipy\n",
            "Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwCYWdLS_OOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6724468d-44f5-44a3-bc96-0f270f24ba5f"
      },
      "source": [
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "keras.backend.clear_session()\n",
        "from keras.optimizers import Adam, SGD, Nadam\n",
        "!pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras\n",
        "#from keras.experimental import CosineDecayRestarts\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/08/1884157a3de72d41fa97cacacafaa49abf00eba53cb7e08615b2b65b4a9d/livelossplot-0.5.3-py3-none-any.whl\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (2.1.1)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.19.5)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.8)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (51.1.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->bokeh; python_version >= \"3.6\"->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.7.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHrjrugr1gNp"
      },
      "source": [
        "MLP model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdeqWRzNzV1I"
      },
      "source": [
        "def MLP_train(X_train = X_train, y_train = y_train, X_val = X_val, y_val = y_val, X_test = X_test, y_test = y_test, n_layers = 2, n_neurons = 64, bs_double = 4):\n",
        "\n",
        "    # to make this notebook's output stable across runs but it doesn't work with search logic.\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    bs = 2**bs_double\n",
        "    bs_name = str(bs)\n",
        "\n",
        "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "    checkpoint1 = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_\"+path_end+bs_name+\".hdf5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    checkpoint2 = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_rmse_\"+path_end+bs_name+\".hdf5\", monitor='val_root_mean_squared_error', verbose=1, save_best_only=True, mode='min')\n",
        "    checkpoint3 = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mae_\"+path_end+bs_name+\".hdf5\", monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "    #crate model\n",
        "    model = keras.models.Sequential() \n",
        "    #model.add(BatchNormalization(name = 'batch_norm_0', input_shape = (look_back, num_features)))\n",
        "    #Hidden Layer 1\n",
        "    model.add(keras.layers.Dense(n_neurons, name = 'dense_1', input_shape=(X_train.shape[1],),  kernel_initializer='TruncatedNormal', use_bias=False))#, activation='relu'))\n",
        "    model.add(BatchNormalization(name = 'batch_norm_1'))\n",
        "    model.add(LeakyReLU(name = 'leaky_relu_1'))\n",
        "    model.add(keras.layers.Dropout(0.2, name = 'dropout_1'))\n",
        "\n",
        "    # Adds remaining hidden layers\n",
        "    for i in range(2, n_layers + 1):\n",
        "        if i == n_layers:\n",
        "            model.add(keras.layers.Dense(n_neurons, name = 'dense_{}'.format(i), kernel_initializer='TruncatedNormal', use_bias=False, activation='relu'))\n",
        "            model.add(BatchNormalization(name = 'batch_norm_{}'.format(i)))\n",
        "            model.add(keras.layers.Dropout(0.2, name = 'dropout_{}'.format(i)))\n",
        "        else:\n",
        "            model.add(keras.layers.Dense(n_neurons, name = 'dense_{}'.format(i), kernel_initializer='TruncatedNormal', use_bias=False)) #,n_neurons*(2**i)\n",
        "                            #name='h{}'.format(i)))#, activation='relu'))\n",
        "            model.add(BatchNormalization(name = 'batch_norm_{}'.format(i)))\n",
        "            model.add(LeakyReLU(name = 'leaky_relu_{}'.format(i)))\n",
        "            model.add(keras.layers.Dropout(0.2, name = 'dropout_{}'.format(i)))\n",
        "\n",
        "    #Layer output\n",
        "    model.add(keras.layers.Dense(1, name = 'dense_out'))\n",
        "\n",
        "    #set learning rate and optimizer\n",
        "    lr=1.e-3\n",
        "    '''\n",
        "    n_steps=2000\n",
        "    global_step=1\n",
        "    LR = keras.experimental.CosineDecayRestarts(\n",
        "        initial_learning_rate=lr,\n",
        "        first_decay_steps=n_steps,\n",
        "        t_mul= 1.5,\n",
        "        m_mul= 1,\n",
        "        alpha=0.1,\n",
        "        name=None\n",
        "    )\n",
        "    '''\n",
        "    adam = Adam(learning_rate=lr) #, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['RootMeanSquaredError', 'mae'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=bs, callbacks=[callback, checkpoint1], # checkpoint2, checkpoint3, PlotLossesKeras()\n",
        "                      validation_data=(X_val, y_val))\n",
        "\n",
        "    # Load the architecture\n",
        "    model = load_model('/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_'+path_end+bs_name+'.hdf5')\n",
        "\n",
        "    # Compile with the same settings as it has been saved with earlier\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['RootMeanSquaredError', 'mae'])\n",
        "\n",
        "    # Calculate the RMSE score as fitness score for GA\n",
        "    rmse = model.evaluate(X_val, y_val)[1]\n",
        "    #print('Validation RMSE: ', rmse,'\\n')\n",
        "    \n",
        "    return rmse,"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fC3uALkfQ3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "068091e1-be64-42de-f3db-28641f222231"
      },
      "source": [
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/c5/013f5aa3b56c6d2c58634bc979773df44ab2226cf4fa787daf0bfeeea0b4/ipython_autotime-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (51.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Installing collected packages: ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.0\n",
            "time: 253 µs (started: 2021-01-15 17:28:25 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUuJxgIPeoM4"
      },
      "source": [
        "# Using genetic algorithms to fine-tune hyperparameters in the model\n",
        "\n",
        "time window size = look back\n",
        "\n",
        "number of unit = nuerons in hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G07oJKZ6nvnB"
      },
      "source": [
        "nn_param_choices = {\n",
        "    'n_neurons': [16, 32, 64, 128, 512, 768, 1024], #\n",
        "    'n_layers': [2, 3, 4], #\n",
        "    'bs_double': [4, 5, 6, 7, 8, 9, 10], #\n",
        "    #'n_timewindow' : [0.5, 1, 1.5, 2],\n",
        "    \n",
        "}\n",
        "network = {} #vector\n",
        "count = 10 # Number of population in each generation.\n",
        "generations = 5  # Number of times to produce the generation.\n",
        "retain=0.4 # the of population that will keep from the current gen to next gen.\n",
        "random_select=0.1 # randomly keep the abandon vectors by compare a random number with this value.\n",
        "mutate_chance=0.2 # Randomly mutate the children that have a random number higher than this number.\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWr0kflMiIh4"
      },
      "source": [
        "#create a random vector(network)\n",
        "def create_rand(nn_param_choices):\n",
        "  np.random.seed(42)\n",
        "  for key in nn_param_choices:\n",
        "    network[key] = random.choice(nn_param_choices[key])\n",
        "  return network"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmzmk8GMpMRu"
      },
      "source": [
        "#create population from the create_rand function as prerequisite size\n",
        "def create_population(nn_param_choices, count):  \n",
        "  pop = []\n",
        "  for _ in range(0, count):\n",
        "      n = create_rand(nn_param_choices).copy()\n",
        "      pop.append(n)\n",
        "  return pop"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnk7dNzqImYJ"
      },
      "source": [
        "#train each vector in population to get fitness value\n",
        "def train_networks(networks, data= data):\n",
        "    pbar = tqdm(total=len(networks))\n",
        "    accuracy = []\n",
        "    for network in networks:\n",
        "        print(network)\n",
        "        print(network['n_neurons'])\n",
        "        X_train, y_train, X_val, y_val, X_test, y_test, split_index_test, scaler = df_scaling(df=data, target_column='Driving_time_s')\n",
        "        accuracy.append(MLP_train(X_train, y_train, X_val, y_val, X_test, y_test, n_neurons= network['n_neurons'], n_layers= network['n_layers'], bs_double= network['bs_double']))\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "    return accuracy"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtagokRzADK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a915bee9-13e5-4eab-a97f-2fae0b558cbb"
      },
      "source": [
        "networks = create_population(nn_param_choices, count)\n",
        "networks"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'bs_double': 4, 'n_layers': 3, 'n_neurons': 32},\n",
              " {'bs_double': 6, 'n_layers': 2, 'n_neurons': 32},\n",
              " {'bs_double': 6, 'n_layers': 2, 'n_neurons': 16},\n",
              " {'bs_double': 5, 'n_layers': 3, 'n_neurons': 1024},\n",
              " {'bs_double': 4, 'n_layers': 2, 'n_neurons': 64},\n",
              " {'bs_double': 10, 'n_layers': 3, 'n_neurons': 128},\n",
              " {'bs_double': 6, 'n_layers': 4, 'n_neurons': 1024},\n",
              " {'bs_double': 9, 'n_layers': 3, 'n_neurons': 512},\n",
              " {'bs_double': 10, 'n_layers': 2, 'n_neurons': 512},\n",
              " {'bs_double': 6, 'n_layers': 2, 'n_neurons': 32}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MatFWkKGZYR6"
      },
      "source": [
        "#offspring children by crossover then two new children are produced\n",
        "def breed(mother, father, nn_param_choices = nn_param_choices, mutate_chance=0.2):\n",
        "    children = []\n",
        "    for _ in range(2):\n",
        "\n",
        "        child = {}\n",
        "\n",
        "        if _ == 1:\n",
        "            for param in nn_param_choices:\n",
        "                if children[0][param] == mother[param]:\n",
        "                    child[param] = father[param]\n",
        "                else:\n",
        "                    child[param] = mother[param]\n",
        "        else:\n",
        "            # Loop through the parameters\n",
        "            for param in nn_param_choices:\n",
        "                child[param] = random.choice(\n",
        "                    [mother[param], father[param]]\n",
        "                )\n",
        "\n",
        "        # Randomly mutate some of the children.\n",
        "        if mutate_chance > random.random():\n",
        "            network = mutate(child)\n",
        "\n",
        "        children.append(child)\n",
        "\n",
        "    return children"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-YPo5YUepX5"
      },
      "source": [
        "#mutate some part of hyperparameter set\n",
        "def mutate(child):\n",
        "    # Choose a random parm.\n",
        "    mutation = random.choice(list(nn_param_choices.keys()))\n",
        "\n",
        "    # Mutate the random params.\n",
        "    child[mutation] = random.choice(nn_param_choices[mutation])\n",
        "\n",
        "    return child"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncHTzX3BOomW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579281f6-5dd3-40e9-e56f-1a7e9d3110ba"
      },
      "source": [
        "#evolve function to generate a new generation\n",
        "def evolve(networks, parent_accuracy=[1,1,1,1], retain=retain, random_select=0.1, nn_param_choices = nn_param_choices, iteration = 1):\n",
        "    \n",
        "    # find the size of parents to retian in the next gen\n",
        "    retain_length = int(len(networks)*retain)\n",
        "    \n",
        "    # Get scores for each network\n",
        "    if iteration == 0: #train all networks to get score\n",
        "        accuracy = train_networks(networks)\n",
        "    else: #in other generation get score for remain parents from previous training\n",
        "        accuracy_parent_last = parent_accuracy\n",
        "        accuracy_child = train_networks(networks[retain_length:])\n",
        "        accuracy = accuracy_parent_last + accuracy_child\n",
        "\n",
        "    # ranking the scores\n",
        "    sorted_network_accuracy = [x for _,x in sorted(zip(accuracy,networks), key=lambda pair: pair[0])]\n",
        "    sorted_accuracy = sorted(accuracy)\n",
        "\n",
        "    # The remain parents\n",
        "    parents = sorted_network_accuracy[:retain_length]\n",
        "    parents_acc = sorted_accuracy[:retain_length]\n",
        "\n",
        "    # randomly keep some of unqualified vectors.\n",
        "    for individual in sorted_network_accuracy[retain_length:]:\n",
        "        if random_select > random.random():\n",
        "            parents.append(individual)\n",
        "\n",
        "    # find number of free spots\n",
        "    parents_length = len(parents)\n",
        "    desired_length = len(networks) - parents_length\n",
        "    children = []\n",
        "\n",
        "    # Add children to the free spaces\n",
        "    while len(children) < desired_length:\n",
        "\n",
        "        # random mother and father.\n",
        "        male = random.randint(0, parents_length-1)\n",
        "        female = random.randint(0, parents_length-1)\n",
        "\n",
        "        # ensure that they are not the same vector\n",
        "        if male != female:\n",
        "            male = parents[male]\n",
        "            female = parents[female]\n",
        "\n",
        "            # Offspring\n",
        "            babies = breed(male, female, nn_param_choices)\n",
        "\n",
        "            # Add kid one by one to make sure it dose not exceed free spaces\n",
        "            for baby in babies:\n",
        "                if (len(children) < desired_length) & ~(baby in parents):\n",
        "                    children.append(baby)\n",
        "\n",
        "    parents.extend(children)\n",
        "    #print(parents_acc)\n",
        "\n",
        "    return parents, parents_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 37.9 ms (started: 2021-01-14 18:14:33 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kyJnnccrjJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02691b57-bf08-4d62-c291-75392fc7ae64"
      },
      "source": [
        "#function to run the genetic algorithm\n",
        "def generate(generations, count, nn_param_choices, networks):\n",
        "    #networks = create_population(nn_param_choices, count) #if want to initial networks here\n",
        "    networks = networks\n",
        "    #dummy parent_acc for the first iteration\n",
        "    parent_acc = list(range(int(len(networks)*retain)))\n",
        "    print(networks)\n",
        "    #run iterations\n",
        "    for i in range(generations-1):\n",
        "        print('Iteration: ', i+1)\n",
        "        #print(networks)\n",
        "        networks, parent_acc = evolve(networks, parent_accuracy= parent_acc, iteration = i)\n",
        "        print(networks)\n",
        "    \n",
        "    #get the score\n",
        "    print('Iteration: ', i+2)\n",
        "    score = train_networks(networks)\n",
        "\n",
        "    #ranking\n",
        "    sorted_network_score = [x for _,x in sorted(zip(score,networks), key=lambda pair: pair[0])]\n",
        "    sorted_score = sorted(score)\n",
        "    return sorted_network_score,sorted_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 13.7 ms (started: 2021-01-14 18:14:38 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGsWKLU1zPil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107b920f-54ab-4122-ac27-24a1915b87f2"
      },
      "source": [
        "ga_network, rmse = generate(generations, count, nn_param_choices, networks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'n_neurons': 32, 'n_layers': 4, 'bs_double': 10}, {'n_neurons': 768, 'n_layers': 2, 'bs_double': 4}, {'n_neurons': 1024, 'n_layers': 4, 'bs_double': 9}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 7}, {'n_neurons': 32, 'n_layers': 2, 'bs_double': 8}, {'n_neurons': 768, 'n_layers': 3, 'bs_double': 10}, {'n_neurons': 64, 'n_layers': 2, 'bs_double': 9}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 128, 'n_layers': 4, 'bs_double': 9}]\n",
            "Iteration:  1\n",
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 10}\n",
            "32\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 83ms/step - loss: 1.6492 - root_mean_squared_error: 1.2759 - mae: 0.9723 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625 - val_mae: 0.1142\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02640, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.6962 - root_mean_squared_error: 0.8342 - mae: 0.6386 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1332 - val_mae: 0.0905\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02640 to 0.01775, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.5356 - root_mean_squared_error: 0.7317 - mae: 0.5494 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0887\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01775 to 0.01517, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.4699 - root_mean_squared_error: 0.6854 - mae: 0.5062 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221 - val_mae: 0.0911\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01517 to 0.01492, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.4108 - root_mean_squared_error: 0.6409 - mae: 0.4711 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0915\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01492 to 0.01489, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.3775 - root_mean_squared_error: 0.6144 - mae: 0.4492 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223 - val_mae: 0.0901\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01489\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.3754 - root_mean_squared_error: 0.6126 - mae: 0.4453 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0897\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01489\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 45ms/step - loss: 0.3404 - root_mean_squared_error: 0.5834 - mae: 0.4258 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0888\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01489\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.3051 - root_mean_squared_error: 0.5523 - mae: 0.4031 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0887\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01489\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.2934 - root_mean_squared_error: 0.5416 - mae: 0.3871 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227 - val_mae: 0.0888\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01489\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.2773 - root_mean_squared_error: 0.5265 - mae: 0.3824 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0895\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01489\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.2656 - root_mean_squared_error: 0.5153 - mae: 0.3694 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0903\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01489\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.2504 - root_mean_squared_error: 0.5003 - mae: 0.3599 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227 - val_mae: 0.0907\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01489\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.2328 - root_mean_squared_error: 0.4824 - mae: 0.3443 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229 - val_mae: 0.0908\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01489\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 44ms/step - loss: 0.2305 - root_mean_squared_error: 0.4800 - mae: 0.3385 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0912\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01489\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - mae: 0.0897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:09<01:21,  9.07s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 768, 'n_layers': 2, 'bs_double': 4}\n",
            "768\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 7s 10ms/step - loss: 1.5093 - root_mean_squared_error: 1.1843 - mae: 0.8764 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1624 - val_mae: 0.1258\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02638, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 5s 10ms/step - loss: 0.0881 - root_mean_squared_error: 0.2956 - mae: 0.2326 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889 - val_mae: 0.0651\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02638 to 0.00790, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0279 - root_mean_squared_error: 0.1667 - mae: 0.1304 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00790 to 0.00631, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0173 - root_mean_squared_error: 0.1316 - mae: 0.1024 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870 - val_mae: 0.0624\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00631\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0097 - root_mean_squared_error: 0.0984 - mae: 0.0750 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863 - val_mae: 0.0616\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00631\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0932 - mae: 0.0708 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825 - val_mae: 0.0588\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00631\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0074 - root_mean_squared_error: 0.0860 - mae: 0.0646 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753 - val_mae: 0.0520\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00631 to 0.00566, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - mae: 0.0592 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00566 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0058 - root_mean_squared_error: 0.0764 - mae: 0.0566 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1912 - val_mae: 0.1576\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00543\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0229 - root_mean_squared_error: 0.1510 - mae: 0.1185 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1359 - val_mae: 0.1096\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00543\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0143 - root_mean_squared_error: 0.1193 - mae: 0.0926 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0994 - val_mae: 0.0738\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00543\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0099 - root_mean_squared_error: 0.0997 - mae: 0.0759 - val_loss: 0.0100 - val_root_mean_squared_error: 0.0999 - val_mae: 0.0767\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00543\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0093 - root_mean_squared_error: 0.0965 - mae: 0.0740 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841 - val_mae: 0.0607\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00543\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0080 - root_mean_squared_error: 0.0892 - mae: 0.0675 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858 - val_mae: 0.0622\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00543\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0065 - root_mean_squared_error: 0.0807 - mae: 0.0610 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00543\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0569 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00543\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0061 - root_mean_squared_error: 0.0779 - mae: 0.0573 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1317 - val_mae: 0.1052\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00543\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 6s 10ms/step - loss: 0.0184 - root_mean_squared_error: 0.1352 - mae: 0.1056 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876 - val_mae: 0.0631\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00543\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 2/10 [01:56<05:09, 38.73s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 1024, 'n_layers': 4, 'bs_double': 9}\n",
            "1024\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 40.3467 - root_mean_squared_error: 5.9813 - mae: 3.5253 - val_loss: 0.3513 - val_root_mean_squared_error: 0.5927 - val_mae: 0.4745\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.35129, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 66s 4s/step - loss: 1.1774 - root_mean_squared_error: 1.0830 - mae: 0.8516 - val_loss: 0.1389 - val_root_mean_squared_error: 0.3726 - val_mae: 0.3214\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.35129 to 0.13885, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.5522 - root_mean_squared_error: 0.7429 - mae: 0.5684 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2484 - val_mae: 0.2059\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.13885 to 0.06169, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.4553 - root_mean_squared_error: 0.6747 - mae: 0.5171 - val_loss: 0.0408 - val_root_mean_squared_error: 0.2021 - val_mae: 0.1548\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.06169 to 0.04083, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.4363 - root_mean_squared_error: 0.6605 - mae: 0.5096 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2265 - val_mae: 0.1793\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.04083\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.4157 - root_mean_squared_error: 0.6448 - mae: 0.4934 - val_loss: 0.0340 - val_root_mean_squared_error: 0.1843 - val_mae: 0.1394\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.04083 to 0.03398, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.4108 - root_mean_squared_error: 0.6409 - mae: 0.4881 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1856 - val_mae: 0.1398\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.03398\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.3932 - root_mean_squared_error: 0.6270 - mae: 0.4819 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887 - val_mae: 0.1465\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.03398\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.3675 - root_mean_squared_error: 0.6062 - mae: 0.4651 - val_loss: 0.0333 - val_root_mean_squared_error: 0.1825 - val_mae: 0.1410\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.03398 to 0.03329, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.3737 - root_mean_squared_error: 0.6113 - mae: 0.4670 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1668 - val_mae: 0.1245\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.03329 to 0.02781, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.3605 - root_mean_squared_error: 0.6004 - mae: 0.4562 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832 - val_mae: 0.1423\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.02781\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.3455 - root_mean_squared_error: 0.5878 - mae: 0.4439 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1693 - val_mae: 0.1299\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.02781\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.3374 - root_mean_squared_error: 0.5808 - mae: 0.4445 - val_loss: 0.0263 - val_root_mean_squared_error: 0.1621 - val_mae: 0.1230\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.02781 to 0.02629, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.3283 - root_mean_squared_error: 0.5729 - mae: 0.4389 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637 - val_mae: 0.1249\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.02629\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.3130 - root_mean_squared_error: 0.5594 - mae: 0.4299 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1617 - val_mae: 0.1250\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.02629 to 0.02614, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 66s 4s/step - loss: 0.3214 - root_mean_squared_error: 0.5669 - mae: 0.4314 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557 - val_mae: 0.1176\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.02614 to 0.02424, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.2909 - root_mean_squared_error: 0.5393 - mae: 0.4155 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1595 - val_mae: 0.1229\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.02424\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.3000 - root_mean_squared_error: 0.5477 - mae: 0.4151 - val_loss: 0.0228 - val_root_mean_squared_error: 0.1511 - val_mae: 0.1148\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.02424 to 0.02284, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.2796 - root_mean_squared_error: 0.5287 - mae: 0.4028 - val_loss: 0.0194 - val_root_mean_squared_error: 0.1394 - val_mae: 0.1055\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.02284 to 0.01944, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.2756 - root_mean_squared_error: 0.5250 - mae: 0.4017 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1535 - val_mae: 0.1196\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01944\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2614 - root_mean_squared_error: 0.5113 - mae: 0.3969 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1306 - val_mae: 0.0983\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01944 to 0.01705, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.2668 - root_mean_squared_error: 0.5164 - mae: 0.3947 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1611 - val_mae: 0.1184\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01705\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2576 - root_mean_squared_error: 0.5075 - mae: 0.3904 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0896\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01705 to 0.01488, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.2449 - root_mean_squared_error: 0.4947 - mae: 0.3772 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247 - val_mae: 0.0947\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01488\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.2327 - root_mean_squared_error: 0.4823 - mae: 0.3736 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240 - val_mae: 0.0929\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.01488\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2303 - root_mean_squared_error: 0.4798 - mae: 0.3689 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1292 - val_mae: 0.0991\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.01488\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2317 - root_mean_squared_error: 0.4811 - mae: 0.3656 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1240 - val_mae: 0.0900\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.01488\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2162 - root_mean_squared_error: 0.4649 - mae: 0.3564 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0917\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01488\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.2063 - root_mean_squared_error: 0.4542 - mae: 0.3489 - val_loss: 0.0183 - val_root_mean_squared_error: 0.1353 - val_mae: 0.1018\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01488\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.2106 - root_mean_squared_error: 0.4588 - mae: 0.3497 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1340 - val_mae: 0.1003\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01488\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1950 - root_mean_squared_error: 0.4416 - mae: 0.3391 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183 - val_mae: 0.0882\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.01488 to 0.01400, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 66s 4s/step - loss: 0.1835 - root_mean_squared_error: 0.4284 - mae: 0.3284 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213 - val_mae: 0.0908\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01400\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1857 - root_mean_squared_error: 0.4308 - mae: 0.3313 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1267 - val_mae: 0.0976\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01400\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.1767 - root_mean_squared_error: 0.4203 - mae: 0.3224 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096 - val_mae: 0.0798\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.01400 to 0.01201, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.1728 - root_mean_squared_error: 0.4157 - mae: 0.3191 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329 - val_mae: 0.0961\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.01201\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1762 - root_mean_squared_error: 0.4197 - mae: 0.3208 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074 - val_mae: 0.0782\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.01201 to 0.01153, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 66s 4s/step - loss: 0.1548 - root_mean_squared_error: 0.3935 - mae: 0.3031 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1233 - val_mae: 0.0934\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01153\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1556 - root_mean_squared_error: 0.3945 - mae: 0.3014 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997 - val_mae: 0.0735\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.01153 to 0.00993, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.1506 - root_mean_squared_error: 0.3881 - mae: 0.2972 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0654\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00993 to 0.00834, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 66s 4s/step - loss: 0.1439 - root_mean_squared_error: 0.3793 - mae: 0.2891 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1166 - val_mae: 0.0897\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00834\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1450 - root_mean_squared_error: 0.3808 - mae: 0.2902 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117 - val_mae: 0.0830\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00834\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.1388 - root_mean_squared_error: 0.3725 - mae: 0.2837 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0916 - val_mae: 0.0662\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00834\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1381 - root_mean_squared_error: 0.3716 - mae: 0.2847 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0969 - val_mae: 0.0686\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00834\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.1322 - root_mean_squared_error: 0.3636 - mae: 0.2762 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959 - val_mae: 0.0711\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00834\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 68s 4s/step - loss: 0.1282 - root_mean_squared_error: 0.3581 - mae: 0.2751 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878 - val_mae: 0.0618\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00834 to 0.00771, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.1272 - root_mean_squared_error: 0.3567 - mae: 0.2758 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920 - val_mae: 0.0651\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00771\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.1172 - root_mean_squared_error: 0.3424 - mae: 0.2627 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951 - val_mae: 0.0699\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00771\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 63s 4s/step - loss: 0.1182 - root_mean_squared_error: 0.3437 - mae: 0.2627 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0877 - val_mae: 0.0625\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00771 to 0.00768, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 64s 4s/step - loss: 0.1159 - root_mean_squared_error: 0.3405 - mae: 0.2632 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846 - val_mae: 0.0597\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00768 to 0.00716, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 65s 4s/step - loss: 0.1133 - root_mean_squared_error: 0.3366 - mae: 0.2583 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0865 - val_mae: 0.0609\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00716\n",
            "46/46 [==============================] - 4s 87ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862 - mae: 0.0648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30%|███       | 3/10 [57:24<1:59:37, 1025.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 2, 'bs_double': 7}\n",
            "16\n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 2s 8ms/step - loss: 0.9382 - root_mean_squared_error: 0.9545 - mae: 0.7289 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1226 - val_mae: 0.0920\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01502, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.2941 - root_mean_squared_error: 0.5421 - mae: 0.4100 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227 - val_mae: 0.0944\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.01502\n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.1787 - root_mean_squared_error: 0.4225 - mae: 0.3161 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229 - val_mae: 0.0956\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01502\n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.1110 - root_mean_squared_error: 0.3330 - mae: 0.2444 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1218 - val_mae: 0.0947\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01502 to 0.01483, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0745 - root_mean_squared_error: 0.2729 - mae: 0.1994 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189 - val_mae: 0.0913\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01483 to 0.01414, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0558 - root_mean_squared_error: 0.2361 - mae: 0.1706 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172 - val_mae: 0.0901\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01414 to 0.01375, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0318 - root_mean_squared_error: 0.1781 - mae: 0.1343 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205 - val_mae: 0.0937\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01375\n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0216 - root_mean_squared_error: 0.1470 - mae: 0.1104 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1160 - val_mae: 0.0892\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01375 to 0.01346, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0155 - root_mean_squared_error: 0.1246 - mae: 0.0931 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0841\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.01346 to 0.01197, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - mae: 0.0854 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1013 - val_mae: 0.0754\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01197 to 0.01026, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0117 - root_mean_squared_error: 0.1080 - mae: 0.0801 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934 - val_mae: 0.0676\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01026 to 0.00873, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - mae: 0.0743 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0918 - val_mae: 0.0676\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00873 to 0.00843, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0096 - root_mean_squared_error: 0.0979 - mae: 0.0719 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885 - val_mae: 0.0641\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00843 to 0.00783, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0090 - root_mean_squared_error: 0.0947 - mae: 0.0691 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873 - val_mae: 0.0615\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00783 to 0.00763, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - mae: 0.0671 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00763 to 0.00718, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - mae: 0.0669 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851 - val_mae: 0.0593\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00718\n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - mae: 0.0664 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835 - val_mae: 0.0572\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00718 to 0.00698, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - mae: 0.0647 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835 - val_mae: 0.0563\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00698 to 0.00697, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.0076 - root_mean_squared_error: 0.0871 - mae: 0.0641 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824 - val_mae: 0.0563\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00697 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0078 - root_mean_squared_error: 0.0883 - mae: 0.0636 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0817 - val_mae: 0.0556\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00678 to 0.00668, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0069 - root_mean_squared_error: 0.0833 - mae: 0.0611 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821 - val_mae: 0.0562\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00668\n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862 - mae: 0.0630 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0822 - val_mae: 0.0558\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00668\n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - mae: 0.0620 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0542\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00668 to 0.00660, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0606 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00660 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0070 - root_mean_squared_error: 0.0837 - mae: 0.0607 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00644\n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0860 - mae: 0.0621 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00644\n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0841 - mae: 0.0612 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0552\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00644\n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0860 - mae: 0.0618 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0556\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00644\n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0859 - mae: 0.0615 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0550\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00644 to 0.00619, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.0070 - root_mean_squared_error: 0.0837 - mae: 0.0607 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0565\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00619\n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0792 - mae: 0.0576 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0810 - val_mae: 0.0557\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00619\n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - mae: 0.0595 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0520\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00619\n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0066 - root_mean_squared_error: 0.0809 - mae: 0.0579 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0534\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00619 to 0.00606, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0066 - root_mean_squared_error: 0.0812 - mae: 0.0586 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00606 to 0.00591, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0573 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0537\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00591\n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0804 - mae: 0.0576 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00591\n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0778 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00591\n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0552 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0527\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00591 to 0.00584, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786 - mae: 0.0565 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00584\n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 0s 7ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0555 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00584 to 0.00574, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0762 - mae: 0.0547 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0520\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00574\n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0546 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00574\n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0541 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00574 to 0.00570, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0771 - mae: 0.0554 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00570\n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0762 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0777 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00570\n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0542 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00570 to 0.00568, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0540 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00568\n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - mae: 0.0551 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.00568 to 0.00550, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0535 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00550\n",
            "Epoch 50/50\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0531 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00550\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0045 - root_mean_squared_error: 0.0672 - mae: 0.0482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 4/10 [57:42<1:12:19, 723.22s/it] \u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 2, 'bs_double': 8}\n",
            "32\n",
            "Epoch 1/50\n",
            "36/36 [==============================] - 1s 14ms/step - loss: 1.1063 - root_mean_squared_error: 1.0419 - mae: 0.8044 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1243 - val_mae: 0.0966\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01544, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 2/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4933 - root_mean_squared_error: 0.7020 - mae: 0.5444 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1241 - val_mae: 0.0964\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01544 to 0.01539, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 3/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.3727 - root_mean_squared_error: 0.6105 - mae: 0.4723 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1302 - val_mae: 0.1050\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01539\n",
            "Epoch 4/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.3107 - root_mean_squared_error: 0.5573 - mae: 0.4247 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1315 - val_mae: 0.1071\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01539\n",
            "Epoch 5/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.2433 - root_mean_squared_error: 0.4932 - mae: 0.3789 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287 - val_mae: 0.1041\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01539\n",
            "Epoch 6/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.2042 - root_mean_squared_error: 0.4519 - mae: 0.3461 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349 - val_mae: 0.1115\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01539\n",
            "Epoch 7/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1701 - root_mean_squared_error: 0.4123 - mae: 0.3112 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1318 - val_mae: 0.1088\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01539\n",
            "Epoch 8/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.1307 - root_mean_squared_error: 0.3615 - mae: 0.2778 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298 - val_mae: 0.1070\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01539\n",
            "Epoch 9/50\n",
            "36/36 [==============================] - 0s 13ms/step - loss: 0.1175 - root_mean_squared_error: 0.3428 - mae: 0.2604 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1273 - val_mae: 0.1052\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01539\n",
            "Epoch 10/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0960 - root_mean_squared_error: 0.3098 - mae: 0.2369 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247 - val_mae: 0.1030\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01539\n",
            "Epoch 11/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0779 - root_mean_squared_error: 0.2790 - mae: 0.2157 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230 - val_mae: 0.1027\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01539 to 0.01514, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 12/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0690 - root_mean_squared_error: 0.2626 - mae: 0.2008 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145 - val_mae: 0.0934\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01514 to 0.01311, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 13/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0572 - root_mean_squared_error: 0.2392 - mae: 0.1833 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054 - val_mae: 0.0846\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01311 to 0.01112, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 14/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0498 - root_mean_squared_error: 0.2232 - mae: 0.1698 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1015 - val_mae: 0.0804\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01112 to 0.01031, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 15/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - mae: 0.1577 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961 - val_mae: 0.0745\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01031 to 0.00924, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 16/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0354 - root_mean_squared_error: 0.1880 - mae: 0.1439 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949 - val_mae: 0.0742\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00924 to 0.00901, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 17/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0315 - root_mean_squared_error: 0.1774 - mae: 0.1362 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00901 to 0.00764, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 18/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0285 - root_mean_squared_error: 0.1689 - mae: 0.1303 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0849 - val_mae: 0.0620\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00764 to 0.00720, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 19/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0250 - root_mean_squared_error: 0.1581 - mae: 0.1213 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0605\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00720 to 0.00694, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 20/50\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0212 - root_mean_squared_error: 0.1457 - mae: 0.1120 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0591\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00694 to 0.00683, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 21/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0191 - root_mean_squared_error: 0.1380 - mae: 0.1051 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0567\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00683 to 0.00659, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 22/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0178 - root_mean_squared_error: 0.1335 - mae: 0.1011 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0555\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00659 to 0.00645, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 23/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0153 - root_mean_squared_error: 0.1237 - mae: 0.0939 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0798 - val_mae: 0.0545\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00645 to 0.00636, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 24/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1199 - mae: 0.0912 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00636\n",
            "Epoch 25/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0133 - root_mean_squared_error: 0.1155 - mae: 0.0878 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0546\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00636 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 26/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0125 - root_mean_squared_error: 0.1117 - mae: 0.0852 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00635\n",
            "Epoch 27/50\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0115 - root_mean_squared_error: 0.1071 - mae: 0.0818 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0542\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00635 to 0.00634, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 28/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0111 - root_mean_squared_error: 0.1054 - mae: 0.0807 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793 - val_mae: 0.0541\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00634 to 0.00629, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 29/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - root_mean_squared_error: 0.1011 - mae: 0.0770 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00629\n",
            "Epoch 30/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0102 - root_mean_squared_error: 0.1008 - mae: 0.0769 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00629\n",
            "Epoch 31/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0090 - root_mean_squared_error: 0.0948 - mae: 0.0722 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00629 to 0.00628, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 32/50\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954 - mae: 0.0723 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00628 to 0.00623, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 33/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0090 - root_mean_squared_error: 0.0948 - mae: 0.0705 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00623\n",
            "Epoch 34/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0086 - root_mean_squared_error: 0.0930 - mae: 0.0700 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00623\n",
            "Epoch 35/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - mae: 0.0677 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00623\n",
            "Epoch 36/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0672 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00623 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 37/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0076 - root_mean_squared_error: 0.0874 - mae: 0.0649 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0790 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00622\n",
            "Epoch 38/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0079 - root_mean_squared_error: 0.0888 - mae: 0.0659 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0528\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00622 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 39/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - mae: 0.0642 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00622 to 0.00616, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 40/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0634 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00616\n",
            "Epoch 41/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0841 - mae: 0.0625 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00616\n",
            "Epoch 42/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0073 - root_mean_squared_error: 0.0852 - mae: 0.0633 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00616\n",
            "Epoch 43/50\n",
            "36/36 [==============================] - 0s 12ms/step - loss: 0.0070 - root_mean_squared_error: 0.0838 - mae: 0.0624 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00616 to 0.00613, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 44/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0070 - root_mean_squared_error: 0.0834 - mae: 0.0618 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00613 to 0.00611, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202256.hdf5\n",
            "Epoch 45/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - root_mean_squared_error: 0.0841 - mae: 0.0626 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00611\n",
            "Epoch 46/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0620 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00611\n",
            "Epoch 47/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0069 - root_mean_squared_error: 0.0830 - mae: 0.0615 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00611\n",
            "Epoch 48/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0071 - root_mean_squared_error: 0.0842 - mae: 0.0616 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00611\n",
            "Epoch 49/50\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0613 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0784 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00611\n",
            "Epoch 50/50\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.0067 - root_mean_squared_error: 0.0820 - mae: 0.0606 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00611\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0051 - root_mean_squared_error: 0.0711 - mae: 0.0516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [57:57<42:34, 510.82s/it]  \u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 768, 'n_layers': 3, 'bs_double': 10}\n",
            "768\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 8s 773ms/step - loss: 19.1867 - root_mean_squared_error: 4.2233 - mae: 2.9230 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2541 - val_mae: 0.2105\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.06455, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 6s 717ms/step - loss: 3.4243 - root_mean_squared_error: 1.8394 - mae: 1.4727 - val_loss: 0.0400 - val_root_mean_squared_error: 0.1999 - val_mae: 0.1667\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.06455 to 0.03996, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 6s 714ms/step - loss: 1.3820 - root_mean_squared_error: 1.1719 - mae: 0.9387 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1584 - val_mae: 0.1243\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.03996 to 0.02510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 6s 717ms/step - loss: 0.7191 - root_mean_squared_error: 0.8480 - mae: 0.6729 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575 - val_mae: 0.1314\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.02510 to 0.02480, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 6s 717ms/step - loss: 0.5524 - root_mean_squared_error: 0.7429 - mae: 0.5797 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1491 - val_mae: 0.1269\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.02480 to 0.02224, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 6s 715ms/step - loss: 0.4697 - root_mean_squared_error: 0.6853 - mae: 0.5356 - val_loss: 0.0210 - val_root_mean_squared_error: 0.1448 - val_mae: 0.1209\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.02224 to 0.02096, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 7s 733ms/step - loss: 0.4316 - root_mean_squared_error: 0.6569 - mae: 0.5114 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1503 - val_mae: 0.1279\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.02096\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 6s 713ms/step - loss: 0.4144 - root_mean_squared_error: 0.6437 - mae: 0.4942 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514 - val_mae: 0.1292\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.02096\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 6s 720ms/step - loss: 0.4045 - root_mean_squared_error: 0.6359 - mae: 0.4893 - val_loss: 0.0217 - val_root_mean_squared_error: 0.1475 - val_mae: 0.1245\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.02096\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 6s 720ms/step - loss: 0.3800 - root_mean_squared_error: 0.6164 - mae: 0.4759 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370 - val_mae: 0.1133\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.02096 to 0.01877, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 6s 722ms/step - loss: 0.3848 - root_mean_squared_error: 0.6204 - mae: 0.4799 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550 - val_mae: 0.1326\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01877\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 6s 729ms/step - loss: 0.3712 - root_mean_squared_error: 0.6092 - mae: 0.4706 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504 - val_mae: 0.1275\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01877\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 7s 735ms/step - loss: 0.3525 - root_mean_squared_error: 0.5937 - mae: 0.4649 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1360 - val_mae: 0.1121\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01877 to 0.01849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 6s 710ms/step - loss: 0.3496 - root_mean_squared_error: 0.5913 - mae: 0.4611 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497 - val_mae: 0.1263\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01849\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 7s 733ms/step - loss: 0.3453 - root_mean_squared_error: 0.5876 - mae: 0.4569 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465 - val_mae: 0.1233\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01849\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 6s 706ms/step - loss: 0.3405 - root_mean_squared_error: 0.5835 - mae: 0.4503 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317 - val_mae: 0.1063\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01849 to 0.01736, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 6s 717ms/step - loss: 0.3163 - root_mean_squared_error: 0.5624 - mae: 0.4324 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1458 - val_mae: 0.1226\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.01736\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 7s 737ms/step - loss: 0.3186 - root_mean_squared_error: 0.5644 - mae: 0.4383 - val_loss: 0.0221 - val_root_mean_squared_error: 0.1488 - val_mae: 0.1261\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01736\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 6s 711ms/step - loss: 0.3169 - root_mean_squared_error: 0.5629 - mae: 0.4310 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1371 - val_mae: 0.1118\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.01736\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 6s 715ms/step - loss: 0.2963 - root_mean_squared_error: 0.5444 - mae: 0.4194 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1260 - val_mae: 0.0988\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.01736 to 0.01588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 6s 722ms/step - loss: 0.2903 - root_mean_squared_error: 0.5388 - mae: 0.4160 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1247 - val_mae: 0.0981\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01588 to 0.01555, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 6s 718ms/step - loss: 0.2825 - root_mean_squared_error: 0.5315 - mae: 0.4116 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1263 - val_mae: 0.0998\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.01555\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 7s 734ms/step - loss: 0.2669 - root_mean_squared_error: 0.5166 - mae: 0.4008 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1219 - val_mae: 0.0952\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.01555 to 0.01486, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 6s 718ms/step - loss: 0.2722 - root_mean_squared_error: 0.5217 - mae: 0.4041 - val_loss: 0.0158 - val_root_mean_squared_error: 0.1259 - val_mae: 0.1012\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.01486\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 7s 731ms/step - loss: 0.2618 - root_mean_squared_error: 0.5117 - mae: 0.3951 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204 - val_mae: 0.0930\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.01486 to 0.01449, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 7s 740ms/step - loss: 0.2506 - root_mean_squared_error: 0.5006 - mae: 0.3851 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163 - val_mae: 0.0866\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.01449 to 0.01354, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 6s 721ms/step - loss: 0.2428 - root_mean_squared_error: 0.4927 - mae: 0.3795 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144 - val_mae: 0.0870\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.01354 to 0.01309, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 7s 746ms/step - loss: 0.2350 - root_mean_squared_error: 0.4847 - mae: 0.3760 - val_loss: 0.0136 - val_root_mean_squared_error: 0.1165 - val_mae: 0.0903\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.01309\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 6s 718ms/step - loss: 0.2326 - root_mean_squared_error: 0.4822 - mae: 0.3721 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200 - val_mae: 0.0935\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.01309\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 6s 714ms/step - loss: 0.2237 - root_mean_squared_error: 0.4729 - mae: 0.3667 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1188 - val_mae: 0.0940\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.01309\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 6s 714ms/step - loss: 0.2228 - root_mean_squared_error: 0.4720 - mae: 0.3656 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121 - val_mae: 0.0836\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.01309 to 0.01258, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 6s 715ms/step - loss: 0.2053 - root_mean_squared_error: 0.4531 - mae: 0.3506 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1184 - val_mae: 0.0928\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.01258\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 6s 729ms/step - loss: 0.1996 - root_mean_squared_error: 0.4467 - mae: 0.3420 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174 - val_mae: 0.0923\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.01258\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 6s 715ms/step - loss: 0.1955 - root_mean_squared_error: 0.4421 - mae: 0.3426 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1147 - val_mae: 0.0910\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.01258\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 6s 714ms/step - loss: 0.1852 - root_mean_squared_error: 0.4303 - mae: 0.3344 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086 - val_mae: 0.0824\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.01258 to 0.01180, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 6s 717ms/step - loss: 0.1859 - root_mean_squared_error: 0.4311 - mae: 0.3315 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1122 - val_mae: 0.0877\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.01180\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 7s 733ms/step - loss: 0.1836 - root_mean_squared_error: 0.4285 - mae: 0.3285 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1112 - val_mae: 0.0851\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.01180\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 6s 709ms/step - loss: 0.1720 - root_mean_squared_error: 0.4147 - mae: 0.3198 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.01180 to 0.01123, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 7s 742ms/step - loss: 0.1741 - root_mean_squared_error: 0.4171 - mae: 0.3199 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101 - val_mae: 0.0851\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.01123\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 7s 733ms/step - loss: 0.1620 - root_mean_squared_error: 0.4025 - mae: 0.3110 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1051 - val_mae: 0.0781\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.01123 to 0.01105, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 6s 721ms/step - loss: 0.1617 - root_mean_squared_error: 0.4021 - mae: 0.3064 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979 - val_mae: 0.0719\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.01105 to 0.00958, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 6s 723ms/step - loss: 0.1606 - root_mean_squared_error: 0.4008 - mae: 0.3079 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996 - val_mae: 0.0732\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00958\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 7s 735ms/step - loss: 0.1491 - root_mean_squared_error: 0.3862 - mae: 0.2969 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1017 - val_mae: 0.0774\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00958\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 6s 718ms/step - loss: 0.1444 - root_mean_squared_error: 0.3800 - mae: 0.2931 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995 - val_mae: 0.0726\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00958\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 6s 716ms/step - loss: 0.1408 - root_mean_squared_error: 0.3752 - mae: 0.2867 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - val_mae: 0.0669\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00958 to 0.00871, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 6s 727ms/step - loss: 0.1363 - root_mean_squared_error: 0.3691 - mae: 0.2832 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1076 - val_mae: 0.0859\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00871\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 7s 741ms/step - loss: 0.1334 - root_mean_squared_error: 0.3651 - mae: 0.2813 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936 - val_mae: 0.0660\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00871\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 6s 715ms/step - loss: 0.1313 - root_mean_squared_error: 0.3623 - mae: 0.2778 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971 - val_mae: 0.0757\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00871\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 6s 723ms/step - loss: 0.1190 - root_mean_squared_error: 0.3450 - mae: 0.2682 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936 - val_mae: 0.0692\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00871\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 7s 732ms/step - loss: 0.1209 - root_mean_squared_error: 0.3477 - mae: 0.2677 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910 - val_mae: 0.0643\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00871 to 0.00829, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0082 - root_mean_squared_error: 0.0907 - mae: 0.0694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [1:03:53<30:57, 464.36s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 64, 'n_layers': 2, 'bs_double': 9}\n",
            "64\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 2s 26ms/step - loss: 1.4888 - root_mean_squared_error: 1.2094 - mae: 0.9354 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0907\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01488, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.5724 - root_mean_squared_error: 0.7562 - mae: 0.5939 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1294 - val_mae: 0.1037\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.01488\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4467 - root_mean_squared_error: 0.6683 - mae: 0.5241 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1266 - val_mae: 0.1003\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01488\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3825 - root_mean_squared_error: 0.6184 - mae: 0.4806 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1336 - val_mae: 0.1090\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01488\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3441 - root_mean_squared_error: 0.5864 - mae: 0.4521 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1342 - val_mae: 0.1101\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01488\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.2964 - root_mean_squared_error: 0.5443 - mae: 0.4211 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1378 - val_mae: 0.1143\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01488\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.2554 - root_mean_squared_error: 0.5054 - mae: 0.3927 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1377 - val_mae: 0.1142\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01488\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.2207 - root_mean_squared_error: 0.4698 - mae: 0.3660 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347 - val_mae: 0.1116\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01488\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1902 - root_mean_squared_error: 0.4362 - mae: 0.3382 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367 - val_mae: 0.1139\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01488\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1746 - root_mean_squared_error: 0.4178 - mae: 0.3208 - val_loss: 0.0200 - val_root_mean_squared_error: 0.1413 - val_mae: 0.1193\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01488\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.1551 - root_mean_squared_error: 0.3938 - mae: 0.3060 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1369 - val_mae: 0.1145\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01488\n",
            "46/46 [==============================] - 0s 960us/step - loss: 0.0132 - root_mean_squared_error: 0.1148 - mae: 0.0888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 70%|███████   | 7/10 [1:03:58<16:19, 326.53s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}\n",
            "16\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 3s 4ms/step - loss: 0.6746 - root_mean_squared_error: 0.8047 - mae: 0.6149 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367 - val_mae: 0.0967\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.1080 - root_mean_squared_error: 0.3281 - mae: 0.2476 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109 - val_mae: 0.0802\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01870 to 0.01230, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0505 - root_mean_squared_error: 0.2245 - mae: 0.1678 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054 - val_mae: 0.0748\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01230 to 0.01112, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - mae: 0.1432 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026 - val_mae: 0.0745\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01112 to 0.01053, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - mae: 0.0992 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993 - val_mae: 0.0700\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01053 to 0.00986, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - mae: 0.0818 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914 - val_mae: 0.0626\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00986 to 0.00835, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - mae: 0.0710 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0575\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00835 to 0.00738, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - mae: 0.0675 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842 - val_mae: 0.0560\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00738 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0536\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00710 to 0.00633, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - mae: 0.0643 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0518\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00633 to 0.00612, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0610 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00612\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0799 - mae: 0.0573 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00612 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0790 - mae: 0.0565 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00557 to 0.00541, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0797 - mae: 0.0576 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00541 to 0.00532, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0557 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00532 to 0.00521, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0558 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00521\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0784 - mae: 0.0563 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00521\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0577 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00521\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0565 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00521\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0550 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00521 to 0.00506, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0550 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00506\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0771 - mae: 0.0553 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00506\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0533 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00506 to 0.00502, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00502\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0535 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00502\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0751 - mae: 0.0530 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00502\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0532 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00502\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0738 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00502\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0529 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00502\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0547 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00502\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0534 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00502\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0539 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00502\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0532 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00502\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0643 - mae: 0.0453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 8/10 [1:05:02<08:15, 247.62s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 5ms/step - loss: 0.5924 - root_mean_squared_error: 0.7563 - mae: 0.5581 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417 - val_mae: 0.0957\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02007, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.1639 - root_mean_squared_error: 0.4044 - mae: 0.2868 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267 - val_mae: 0.0866\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02007 to 0.01607, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0953 - root_mean_squared_error: 0.3084 - mae: 0.2129 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118 - val_mae: 0.0777\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01607 to 0.01249, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0644 - root_mean_squared_error: 0.2535 - mae: 0.1713 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019 - val_mae: 0.0702\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01249 to 0.01039, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0439 - root_mean_squared_error: 0.2092 - mae: 0.1418 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945 - val_mae: 0.0653\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01039 to 0.00892, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - mae: 0.1193 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912 - val_mae: 0.0622\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00892 to 0.00832, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0228 - root_mean_squared_error: 0.1508 - mae: 0.1062 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895 - val_mae: 0.0615\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00832 to 0.00800, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - mae: 0.0976 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876 - val_mae: 0.0596\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00800 to 0.00768, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - mae: 0.0912 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871 - val_mae: 0.0598\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00768 to 0.00758, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0152 - root_mean_squared_error: 0.1231 - mae: 0.0876 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00758 to 0.00747, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180 - mae: 0.0847 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00747 to 0.00746, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - mae: 0.0811 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0583\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00746 to 0.00737, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - mae: 0.0796 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857 - val_mae: 0.0583\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00737 to 0.00735, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - mae: 0.0779 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856 - val_mae: 0.0584\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00735 to 0.00733, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039 - mae: 0.0764 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00733 to 0.00693, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0085 - root_mean_squared_error: 0.0923 - mae: 0.0680 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00693 to 0.00686, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - mae: 0.0657 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00686 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0073 - root_mean_squared_error: 0.0857 - mae: 0.0610 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00678 to 0.00660, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00660 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0585 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00622\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0577 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00622\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0800 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00622 to 0.00606, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0564 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00606 to 0.00598, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0557 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00598 to 0.00580, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0551 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00580\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0558 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00580\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0550 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0507\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00580\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0779 - mae: 0.0552 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00580\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0776 - mae: 0.0551 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00580 to 0.00577, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0546 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00577\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0534 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00577\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00577\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0536 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00577\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0539 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00577\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0540 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00577\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - mae: 0.0552 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00577 to 0.00566, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0536 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00566 to 0.00553, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0519 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00553\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0534 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00553\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0740 - mae: 0.0525 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00553\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0513 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00553\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0521 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00553\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0504 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00553 to 0.00546, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0518 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00546\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - mae: 0.0525 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00546\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0731 - mae: 0.0513 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00546\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0515 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00546\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0513 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00546\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - mae: 0.0511 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00546\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0503 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00546 to 0.00545, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0043 - root_mean_squared_error: 0.0655 - mae: 0.0459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 90%|█████████ | 9/10 [1:05:32<03:02, 182.29s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 128, 'n_layers': 4, 'bs_double': 9}\n",
            "128\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 6s 105ms/step - loss: 2.0667 - root_mean_squared_error: 1.4249 - mae: 1.1050 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0925\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01490, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.6228 - root_mean_squared_error: 0.7888 - mae: 0.6098 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250 - val_mae: 0.0918\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.01490\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.4357 - root_mean_squared_error: 0.6601 - mae: 0.5108 - val_loss: 0.0176 - val_root_mean_squared_error: 0.1325 - val_mae: 0.0915\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01490\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.3737 - root_mean_squared_error: 0.6113 - mae: 0.4709 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1299 - val_mae: 0.0888\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01490\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.3268 - root_mean_squared_error: 0.5717 - mae: 0.4421 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1284 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01490\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.2889 - root_mean_squared_error: 0.5375 - mae: 0.4102 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1230 - val_mae: 0.0839\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01490\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.2663 - root_mean_squared_error: 0.5160 - mae: 0.3967 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182 - val_mae: 0.0829\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01490 to 0.01398, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.2226 - root_mean_squared_error: 0.4718 - mae: 0.3614 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1202 - val_mae: 0.0824\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01398\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 2s 97ms/step - loss: 0.1984 - root_mean_squared_error: 0.4454 - mae: 0.3414 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0829\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01398\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.1672 - root_mean_squared_error: 0.4089 - mae: 0.3135 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1190 - val_mae: 0.0822\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01398\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.1502 - root_mean_squared_error: 0.3875 - mae: 0.2950 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144 - val_mae: 0.0801\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.01398 to 0.01308, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.1341 - root_mean_squared_error: 0.3661 - mae: 0.2759 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1149 - val_mae: 0.0781\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01308\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.1174 - root_mean_squared_error: 0.3426 - mae: 0.2602 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106 - val_mae: 0.0777\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.01308 to 0.01223, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.1070 - root_mean_squared_error: 0.3271 - mae: 0.2465 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1101 - val_mae: 0.0769\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.01223 to 0.01213, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0885 - root_mean_squared_error: 0.2975 - mae: 0.2244 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086 - val_mae: 0.0748\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.01213 to 0.01178, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0788 - root_mean_squared_error: 0.2808 - mae: 0.2134 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1056 - val_mae: 0.0732\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.01178 to 0.01115, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0723 - root_mean_squared_error: 0.2689 - mae: 0.2055 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1032 - val_mae: 0.0741\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.01115 to 0.01066, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0607 - root_mean_squared_error: 0.2464 - mae: 0.1871 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1038 - val_mae: 0.0709\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.01066\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 0.0550 - root_mean_squared_error: 0.2344 - mae: 0.1783 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009 - val_mae: 0.0704\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.01066 to 0.01019, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0466 - root_mean_squared_error: 0.2158 - mae: 0.1674 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014 - val_mae: 0.0688\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.01019\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 0.0421 - root_mean_squared_error: 0.2051 - mae: 0.1545 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973 - val_mae: 0.0685\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.01019 to 0.00946, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - mae: 0.1469 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0967 - val_mae: 0.0660\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00946 to 0.00936, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0329 - root_mean_squared_error: 0.1814 - mae: 0.1380 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00936 to 0.00868, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0287 - root_mean_squared_error: 0.1695 - mae: 0.1294 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920 - val_mae: 0.0640\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00868 to 0.00846, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0267 - root_mean_squared_error: 0.1633 - mae: 0.1229 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0903 - val_mae: 0.0628\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00846 to 0.00816, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 0.0242 - root_mean_squared_error: 0.1554 - mae: 0.1176 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900 - val_mae: 0.0616\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00816 to 0.00809, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 0.0211 - root_mean_squared_error: 0.1452 - mae: 0.1110 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869 - val_mae: 0.0596\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00809 to 0.00756, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 0.0189 - root_mean_squared_error: 0.1376 - mae: 0.1051 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853 - val_mae: 0.0576\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00756 to 0.00727, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 0.0171 - root_mean_squared_error: 0.1307 - mae: 0.1002 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0569\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00727 to 0.00711, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0159 - root_mean_squared_error: 0.1263 - mae: 0.0954 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0549\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00711 to 0.00684, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0138 - root_mean_squared_error: 0.1173 - mae: 0.0891 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815 - val_mae: 0.0545\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00684 to 0.00665, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 0.0129 - root_mean_squared_error: 0.1136 - mae: 0.0867 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00665 to 0.00650, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0122 - root_mean_squared_error: 0.1104 - mae: 0.0830 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.00650 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0110 - root_mean_squared_error: 0.1049 - mae: 0.0792 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00626\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - mae: 0.0759 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0514\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00626 to 0.00605, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0094 - root_mean_squared_error: 0.0972 - mae: 0.0740 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00605 to 0.00594, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0090 - root_mean_squared_error: 0.0947 - mae: 0.0715 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00594 to 0.00581, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0086 - root_mean_squared_error: 0.0928 - mae: 0.0701 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00581 to 0.00580, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - mae: 0.0676 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.00580 to 0.00571, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.0075 - root_mean_squared_error: 0.0867 - mae: 0.0651 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00571 to 0.00551, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0074 - root_mean_squared_error: 0.0862 - mae: 0.0642 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00551 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0073 - root_mean_squared_error: 0.0857 - mae: 0.0635 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00543 to 0.00540, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0608 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00540\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0604 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00540 to 0.00538, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0595 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00538\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0065 - root_mean_squared_error: 0.0804 - mae: 0.0592 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00538 to 0.00535, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0578 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.00535 to 0.00534, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 0.0064 - root_mean_squared_error: 0.0799 - mae: 0.0584 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00534\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0567 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00534\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0563 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00534 to 0.00532, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0044 - root_mean_squared_error: 0.0662 - mae: 0.0466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [1:07:03<00:00, 402.38s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 128, 'n_layers': 4, 'bs_double': 9}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 7}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 10}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 9}, {'n_neurons': 128, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 6}]\n",
            "Iteration:  2\n",
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 10}\n",
            "32\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 106ms/step - loss: 1.6492 - root_mean_squared_error: 1.2759 - mae: 0.9723 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1625 - val_mae: 0.1142\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02640, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.6962 - root_mean_squared_error: 0.8342 - mae: 0.6386 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1332 - val_mae: 0.0905\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02640 to 0.01775, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.5356 - root_mean_squared_error: 0.7317 - mae: 0.5494 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0887\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01775 to 0.01517, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.4699 - root_mean_squared_error: 0.6854 - mae: 0.5062 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221 - val_mae: 0.0911\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01517 to 0.01492, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.4108 - root_mean_squared_error: 0.6409 - mae: 0.4711 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0915\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01492 to 0.01489, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data2021024.hdf5\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.3775 - root_mean_squared_error: 0.6144 - mae: 0.4492 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1223 - val_mae: 0.0901\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01489\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 42ms/step - loss: 0.3754 - root_mean_squared_error: 0.6126 - mae: 0.4453 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0897\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01489\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.3404 - root_mean_squared_error: 0.5834 - mae: 0.4258 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0888\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01489\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.3051 - root_mean_squared_error: 0.5523 - mae: 0.4031 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0887\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01489\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.2934 - root_mean_squared_error: 0.5416 - mae: 0.3871 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227 - val_mae: 0.0888\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01489\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.2773 - root_mean_squared_error: 0.5265 - mae: 0.3824 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0895\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01489\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 43ms/step - loss: 0.2656 - root_mean_squared_error: 0.5153 - mae: 0.3694 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0903\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01489\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 41ms/step - loss: 0.2504 - root_mean_squared_error: 0.5003 - mae: 0.3599 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1227 - val_mae: 0.0907\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.01489\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 47ms/step - loss: 0.2328 - root_mean_squared_error: 0.4824 - mae: 0.3443 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229 - val_mae: 0.0908\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.01489\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 0.2305 - root_mean_squared_error: 0.4800 - mae: 0.3385 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1232 - val_mae: 0.0912\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.01489\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - mae: 0.0897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|█▋        | 1/6 [00:10<00:53, 10.71s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 2, 'bs_double': 4}\n",
            "16\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.4804 - root_mean_squared_error: 0.6732 - mae: 0.5077 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157 - val_mae: 0.0901\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01340, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0542 - root_mean_squared_error: 0.2323 - mae: 0.1739 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1018 - val_mae: 0.0724\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01340 to 0.01036, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0253 - root_mean_squared_error: 0.1589 - mae: 0.1196 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0975 - val_mae: 0.0669\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01036 to 0.00952, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0181 - root_mean_squared_error: 0.1346 - mae: 0.1029 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0600\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00952 to 0.00738, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0102 - root_mean_squared_error: 0.1007 - mae: 0.0751 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00738 to 0.00706, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - mae: 0.0675 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0815 - val_mae: 0.0558\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00706 to 0.00665, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0078 - root_mean_squared_error: 0.0886 - mae: 0.0643 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0537\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00665 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - mae: 0.0615 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0539\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00635\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - mae: 0.0615 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00635 to 0.00596, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0074 - root_mean_squared_error: 0.0859 - mae: 0.0625 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00596\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0067 - root_mean_squared_error: 0.0820 - mae: 0.0591 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0503\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00596\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0560 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00596 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0060 - root_mean_squared_error: 0.0776 - mae: 0.0552 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00543 to 0.00535, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0061 - root_mean_squared_error: 0.0779 - mae: 0.0563 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00535 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0057 - root_mean_squared_error: 0.0752 - mae: 0.0540 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00530 to 0.00513, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0548 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00513\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0548 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00513\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0799 - mae: 0.0570 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00513\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0059 - root_mean_squared_error: 0.0770 - mae: 0.0552 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00513\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0058 - root_mean_squared_error: 0.0764 - mae: 0.0550 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00513\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0535 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00513\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0551 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00513\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0532 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00513\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0521 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00513 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0540 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00505\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0529 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00505\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0533 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00505\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0529 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00505\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0526 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00505\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0539 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00505\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0526 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00505\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0537 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00505\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0524 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00505\n",
            "Epoch 34/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0530 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00505\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0645 - mae: 0.0454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 2/6 [00:54<01:22, 20.59s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 9}\n",
            "16\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 2s 32ms/step - loss: 1.4389 - root_mean_squared_error: 1.1910 - mae: 0.9176 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1569 - val_mae: 0.1087\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02460, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.6099 - root_mean_squared_error: 0.7809 - mae: 0.5864 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1379 - val_mae: 0.0933\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02460 to 0.01902, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202512.hdf5\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4985 - root_mean_squared_error: 0.7060 - mae: 0.5174 - val_loss: 0.0212 - val_root_mean_squared_error: 0.1456 - val_mae: 0.0988\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01902\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4357 - root_mean_squared_error: 0.6600 - mae: 0.4827 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619 - val_mae: 0.1136\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.01902\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.3992 - root_mean_squared_error: 0.6318 - mae: 0.4657 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772 - val_mae: 0.1303\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.01902\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.3729 - root_mean_squared_error: 0.6106 - mae: 0.4440 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784 - val_mae: 0.1319\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01902\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3299 - root_mean_squared_error: 0.5743 - mae: 0.4174 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1832 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01902\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.2969 - root_mean_squared_error: 0.5448 - mae: 0.3976 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1793 - val_mae: 0.1330\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01902\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.2890 - root_mean_squared_error: 0.5375 - mae: 0.3848 - val_loss: 0.0335 - val_root_mean_squared_error: 0.1831 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01902\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2408 - root_mean_squared_error: 0.4907 - mae: 0.3595 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740 - val_mae: 0.1270\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.01902\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2304 - root_mean_squared_error: 0.4800 - mae: 0.3451 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709 - val_mae: 0.1233\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01902\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2139 - root_mean_squared_error: 0.4624 - mae: 0.3328 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662 - val_mae: 0.1184\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.01902\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 3/6 [01:01<00:49, 16.65s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 128, 'n_layers': 4, 'bs_double': 6}\n",
            "128\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 5s 24ms/step - loss: 1.2229 - root_mean_squared_error: 1.0824 - mae: 0.8325 - val_loss: 0.0465 - val_root_mean_squared_error: 0.2156 - val_mae: 0.1795\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04650, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.2658 - root_mean_squared_error: 0.5143 - mae: 0.3964 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1220 - val_mae: 0.0862\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04650 to 0.01489, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.1242 - root_mean_squared_error: 0.3522 - mae: 0.2745 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1045 - val_mae: 0.0718\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01489 to 0.01091, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0667 - root_mean_squared_error: 0.2580 - mae: 0.1985 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893 - val_mae: 0.0610\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01091 to 0.00798, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0389 - root_mean_squared_error: 0.1971 - mae: 0.1523 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814 - val_mae: 0.0545\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00798 to 0.00662, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0231 - root_mean_squared_error: 0.1518 - mae: 0.1178 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00662 to 0.00634, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - mae: 0.0975 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793 - val_mae: 0.0520\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00634 to 0.00629, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0118 - root_mean_squared_error: 0.1086 - mae: 0.0833 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00629\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0745 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00629 to 0.00589, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - mae: 0.0688 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00589 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0079 - root_mean_squared_error: 0.0887 - mae: 0.0663 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00587 to 0.00576, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0074 - root_mean_squared_error: 0.0859 - mae: 0.0643 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00576 to 0.00572, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0616 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00572 to 0.00553, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0621 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00553\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0606 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00553 to 0.00540, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - mae: 0.0574 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00540 to 0.00540, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0549 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00540\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0543 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00540 to 0.00539, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0535 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00539 to 0.00517, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - mae: 0.0526 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00517\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0511 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00517\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00517 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0517 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00505\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.0050 - root_mean_squared_error: 0.0703 - mae: 0.0504 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00505 to 0.00494, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0511 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00494\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0515 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00494\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - mae: 0.0508 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00494\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0509 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00494\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0501 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00494\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 3s 23ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0496 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00494\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - mae: 0.0489 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00494\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 3s 24ms/step - loss: 0.0047 - root_mean_squared_error: 0.0683 - mae: 0.0496 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00494\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0048 - root_mean_squared_error: 0.0694 - mae: 0.0483 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708 - val_mae: 0.0462\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00494\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 3s 22ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0490 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705 - val_mae: 0.0462\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00494\n",
            "46/46 [==============================] - 1s 4ms/step - loss: 0.0042 - root_mean_squared_error: 0.0650 - mae: 0.0461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 4/6 [02:59<01:34, 47.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}\n",
            "32\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 8ms/step - loss: 0.8953 - root_mean_squared_error: 0.9294 - mae: 0.7074 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249 - val_mae: 0.0923\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01559, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.2509 - root_mean_squared_error: 0.5004 - mae: 0.3758 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239 - val_mae: 0.0883\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01559 to 0.01536, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.1483 - root_mean_squared_error: 0.3845 - mae: 0.2828 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106 - val_mae: 0.0789\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01536 to 0.01223, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0874 - root_mean_squared_error: 0.2954 - mae: 0.2186 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984 - val_mae: 0.0704\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01223 to 0.00969, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0550 - root_mean_squared_error: 0.2343 - mae: 0.1756 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908 - val_mae: 0.0633\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00969 to 0.00824, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0376 - root_mean_squared_error: 0.1935 - mae: 0.1427 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870 - val_mae: 0.0601\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00824 to 0.00757, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0273 - root_mean_squared_error: 0.1650 - mae: 0.1229 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867 - val_mae: 0.0597\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00757 to 0.00751, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1057 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863 - val_mae: 0.0593\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00751 to 0.00746, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - mae: 0.0954 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00746 to 0.00739, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0144 - root_mean_squared_error: 0.1198 - mae: 0.0901 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853 - val_mae: 0.0582\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00739 to 0.00728, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147 - mae: 0.0862 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00728 to 0.00713, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - mae: 0.0799 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0574\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00713 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - mae: 0.0770 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00710 to 0.00708, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0109 - root_mean_squared_error: 0.1041 - mae: 0.0781 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840 - val_mae: 0.0569\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00708 to 0.00705, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0094 - root_mean_squared_error: 0.0967 - mae: 0.0728 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814 - val_mae: 0.0546\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00705 to 0.00663, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - mae: 0.0657 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00663 to 0.00654, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0072 - root_mean_squared_error: 0.0848 - mae: 0.0627 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808 - val_mae: 0.0528\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00654 to 0.00654, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0070 - root_mean_squared_error: 0.0835 - mae: 0.0604 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00654 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0570 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00635 to 0.00611, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - mae: 0.0576 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0507\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00611 to 0.00605, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0554 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00605\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0778 - mae: 0.0563 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00605 to 0.00584, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - mae: 0.0560 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00584 to 0.00579, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0546 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00579 to 0.00565, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0542 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00565\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0059 - root_mean_squared_error: 0.0765 - mae: 0.0546 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00565\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0541 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00565\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0541 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00565\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0537 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00565 to 0.00560, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - mae: 0.0531 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00560\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0524 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00560\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0532 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00560\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00560\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0526 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00560 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0521 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00557\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0527 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00557 to 0.00546, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0530 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00546 to 0.00535, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0518 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00535\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0526 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00535\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0513 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00535\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0718 - mae: 0.0509 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00535 to 0.00521, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0718 - mae: 0.0514 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00521\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0494 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00521 to 0.00511, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0504 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00511\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0505 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00511 to 0.00510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - mae: 0.0511 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00510\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0707 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00510\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0505 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00510\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0491 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00510\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0049 - root_mean_squared_error: 0.0696 - mae: 0.0488 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00510\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - mae: 0.0451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 83%|████████▎ | 5/6 [03:45<00:46, 46.55s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 2, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 5ms/step - loss: 0.7602 - root_mean_squared_error: 0.8575 - mae: 0.6512 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0932\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.1838 - root_mean_squared_error: 0.4282 - mae: 0.3200 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1206 - val_mae: 0.0928\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01498 to 0.01456, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0871 - root_mean_squared_error: 0.2949 - mae: 0.2181 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169 - val_mae: 0.0909\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01456 to 0.01366, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0516 - root_mean_squared_error: 0.2270 - mae: 0.1671 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086 - val_mae: 0.0820\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01366 to 0.01179, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1778 - mae: 0.1331 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055 - val_mae: 0.0781\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01179 to 0.01112, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414 - mae: 0.1078 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001 - val_mae: 0.0765\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01112 to 0.01002, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0135 - root_mean_squared_error: 0.1160 - mae: 0.0868 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955 - val_mae: 0.0724\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01002 to 0.00911, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0111 - root_mean_squared_error: 0.1055 - mae: 0.0784 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891 - val_mae: 0.0654\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00911 to 0.00794, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0100 - root_mean_squared_error: 0.0998 - mae: 0.0737 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867 - val_mae: 0.0631\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00794 to 0.00751, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - mae: 0.0725 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851 - val_mae: 0.0607\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00751 to 0.00724, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - mae: 0.0703 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0602\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00724 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0952 - mae: 0.0694 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838 - val_mae: 0.0596\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00710 to 0.00703, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0934 - mae: 0.0681 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837 - val_mae: 0.0591\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00703 to 0.00701, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - mae: 0.0668 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835 - val_mae: 0.0594\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00701 to 0.00697, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - mae: 0.0661 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0594\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00697 to 0.00694, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - mae: 0.0650 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0575\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00694 to 0.00683, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - mae: 0.0638 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00683 to 0.00652, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0627 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811 - val_mae: 0.0527\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00652\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0596 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00652 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0817 - mae: 0.0595 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00587\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0776 - mae: 0.0565 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00587\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - mae: 0.0574 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00587 to 0.00577, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0567 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00577 to 0.00573, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0555 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00573 to 0.00540, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - mae: 0.0554 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00540\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - mae: 0.0554 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00540\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - mae: 0.0549 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00540\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - mae: 0.0552 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00540\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0549 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00540 to 0.00528, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0534 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00528\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0524 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00528\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00528\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0537 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00528\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0529 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00528\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0533 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00528\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0541 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00528\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0547 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00528\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0528 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00528\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0529 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00528\n",
            "46/46 [==============================] - 0s 972us/step - loss: 0.0044 - root_mean_squared_error: 0.0666 - mae: 0.0484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 6/6 [04:04<00:00, 40.82s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 4}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 7}, {'n_neurons': 64, 'n_layers': 3, 'bs_double': 6}]\n",
            "Iteration:  3\n",
            "{'n_neurons': 16, 'n_layers': 3, 'bs_double': 4}\n",
            "16\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 3s 3ms/step - loss: 0.4178 - root_mean_squared_error: 0.6281 - mae: 0.4659 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164 - val_mae: 0.0812\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01355, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0560 - root_mean_squared_error: 0.2357 - mae: 0.1746 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1072 - val_mae: 0.0738\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01355 to 0.01150, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0262 - root_mean_squared_error: 0.1617 - mae: 0.1218 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050 - val_mae: 0.0728\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01150 to 0.01103, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0191 - root_mean_squared_error: 0.1381 - mae: 0.1035 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995 - val_mae: 0.0695\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01103 to 0.00990, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0111 - root_mean_squared_error: 0.1055 - mae: 0.0789 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0887 - val_mae: 0.0602\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00990 to 0.00788, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0661 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0551\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00788 to 0.00687, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0074 - root_mean_squared_error: 0.0859 - mae: 0.0622 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00687 to 0.00651, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0069 - root_mean_squared_error: 0.0829 - mae: 0.0605 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804 - val_mae: 0.0527\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00651 to 0.00647, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0595 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00647 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0607 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0534\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00608\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0069 - root_mean_squared_error: 0.0830 - mae: 0.0591 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00608\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786 - mae: 0.0564 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00608 to 0.00558, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0561 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00558 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0788 - mae: 0.0570 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00557 to 0.00553, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - mae: 0.0548 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00553 to 0.00538, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0557 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00538\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0060 - root_mean_squared_error: 0.0778 - mae: 0.0560 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00538\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0065 - root_mean_squared_error: 0.0805 - mae: 0.0573 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00538\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00538\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - mae: 0.0549 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00538 to 0.00536, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0542 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00536 to 0.00507, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0555 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00507\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0541 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00507\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0533 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00507 to 0.00506, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0752 - mae: 0.0540 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00506\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0536 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00506\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - mae: 0.0529 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00506\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - mae: 0.0531 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00506\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - mae: 0.0537 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00506\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0548 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00506\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0536 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00506\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0541 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00506\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0758 - mae: 0.0532 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00506\n",
            "Epoch 34/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0534 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00506\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - mae: 0.0462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|█▋        | 1/6 [00:53<04:27, 53.49s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 4}\n",
            "32\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 4s 4ms/step - loss: 0.6689 - root_mean_squared_error: 0.7945 - mae: 0.5923 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174 - val_mae: 0.0830\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01377, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0974 - root_mean_squared_error: 0.3107 - mae: 0.2311 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01377 to 0.01005, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0414 - root_mean_squared_error: 0.2032 - mae: 0.1548 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963 - val_mae: 0.0651\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01005 to 0.00928, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - mae: 0.1259 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0646\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00928 to 0.00847, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1065 - mae: 0.0804 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841 - val_mae: 0.0573\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00847 to 0.00708, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - mae: 0.0663 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804 - val_mae: 0.0536\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00708 to 0.00647, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0617 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00647 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0815 - mae: 0.0594 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00644 to 0.00628, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0595 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00628 to 0.00612, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - mae: 0.0611 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00612\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0826 - mae: 0.0597 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00612\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0785 - mae: 0.0564 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00612 to 0.00562, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - mae: 0.0555 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00562 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0775 - mae: 0.0562 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00543 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0539 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00543 to 0.00520, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - mae: 0.0556 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00520\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0553 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00520\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - mae: 0.0568 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00520\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0770 - mae: 0.0555 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00520\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0745 - mae: 0.0540 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00520\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0731 - mae: 0.0527 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00520\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0542 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00520 to 0.00504, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0734 - mae: 0.0525 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00504 to 0.00500, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0519 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00500\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00500\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0525 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00500\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0516 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00500\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - mae: 0.0514 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0461\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00500\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0515 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0745 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00500\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0544 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00500\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0527 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00500\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0532 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00500\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00500\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0040 - root_mean_squared_error: 0.0634 - mae: 0.0452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 2/6 [02:09<04:01, 60.36s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.8881 - root_mean_squared_error: 0.9301 - mae: 0.7069 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694 - val_mae: 0.1222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2833 - root_mean_squared_error: 0.5319 - mae: 0.3976 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408 - val_mae: 0.0953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02870 to 0.01982, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1816 - root_mean_squared_error: 0.4259 - mae: 0.3081 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01982 to 0.01542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.1112 - root_mean_squared_error: 0.3333 - mae: 0.2453 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01542 to 0.01196, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0750 - root_mean_squared_error: 0.2736 - mae: 0.2041 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mae: 0.0730\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01196 to 0.01099, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - mae: 0.1703 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01099 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mae: 0.1474 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977 - val_mae: 0.0684\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00980 to 0.00955, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - mae: 0.1324 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0675\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00955 to 0.00918, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - mae: 0.1204 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0661\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00918 to 0.00886, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - mae: 0.1133 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00886 to 0.00857, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1064 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00857 to 0.00849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0176 - root_mean_squared_error: 0.1328 - mae: 0.1000 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917 - val_mae: 0.0637\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00849 to 0.00840, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0984 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00840 to 0.00833, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - mae: 0.0973 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906 - val_mae: 0.0630\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00833 to 0.00821, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - mae: 0.0919 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872 - val_mae: 0.0606\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00821 to 0.00761, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - mae: 0.0778 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00761 to 0.00729, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - mae: 0.0709 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0658 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00722 to 0.00699, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0630 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00699 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0622 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0529\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00644 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0604 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00626\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00626 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00622 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0572 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00608 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0568 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00588\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - mae: 0.0576 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00588\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0558 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00588\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0511\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00588\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0560 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00588\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00588\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00588\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00588\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0534 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00588\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 8ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00588\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 3/6 [02:40<02:33, 51.32s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 9ms/step - loss: 0.8881 - root_mean_squared_error: 0.9301 - mae: 0.7069 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694 - val_mae: 0.1222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.2833 - root_mean_squared_error: 0.5319 - mae: 0.3976 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408 - val_mae: 0.0953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02870 to 0.01982, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1816 - root_mean_squared_error: 0.4259 - mae: 0.3081 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01982 to 0.01542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1112 - root_mean_squared_error: 0.3333 - mae: 0.2453 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01542 to 0.01196, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0750 - root_mean_squared_error: 0.2736 - mae: 0.2041 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mae: 0.0730\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01196 to 0.01099, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - mae: 0.1703 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01099 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mae: 0.1474 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977 - val_mae: 0.0684\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00980 to 0.00955, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - mae: 0.1324 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0675\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00955 to 0.00918, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - mae: 0.1204 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0661\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00918 to 0.00886, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - mae: 0.1133 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00886 to 0.00857, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1064 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00857 to 0.00849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0176 - root_mean_squared_error: 0.1328 - mae: 0.1000 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917 - val_mae: 0.0637\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00849 to 0.00840, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0984 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00840 to 0.00833, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - mae: 0.0973 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906 - val_mae: 0.0630\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00833 to 0.00821, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - mae: 0.0919 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872 - val_mae: 0.0606\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00821 to 0.00761, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - mae: 0.0778 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00761 to 0.00729, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - mae: 0.0709 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0658 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00722 to 0.00699, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0630 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00699 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0622 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0529\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00644 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0604 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00626\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00626 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00622 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0572 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00608 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0568 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00588\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - mae: 0.0576 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00588\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0558 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00588\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0511\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00588\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0560 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00588\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00588\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00588\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00588\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0534 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00588\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00588\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 4/6 [03:08<01:28, 44.31s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 3, 'bs_double': 7}\n",
            "16\n",
            "Epoch 1/50\n",
            "71/71 [==============================] - 2s 9ms/step - loss: 0.6833 - root_mean_squared_error: 0.8142 - mae: 0.6014 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1305 - val_mae: 0.0897\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01704, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 2/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.2282 - root_mean_squared_error: 0.4774 - mae: 0.3383 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1339 - val_mae: 0.0910\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.01704\n",
            "Epoch 3/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.1698 - root_mean_squared_error: 0.4118 - mae: 0.2845 - val_loss: 0.0175 - val_root_mean_squared_error: 0.1324 - val_mae: 0.0896\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.01704\n",
            "Epoch 4/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.1263 - root_mean_squared_error: 0.3550 - mae: 0.2456 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1275 - val_mae: 0.0865\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01704 to 0.01625, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 5/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0888 - root_mean_squared_error: 0.2977 - mae: 0.2044 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1213 - val_mae: 0.0821\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01625 to 0.01472, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 6/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0619 - root_mean_squared_error: 0.2488 - mae: 0.1765 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1146 - val_mae: 0.0772\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01472 to 0.01313, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 7/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - mae: 0.1592 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050 - val_mae: 0.0708\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01313 to 0.01102, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 8/50\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0442 - root_mean_squared_error: 0.2102 - mae: 0.1475 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970 - val_mae: 0.0663\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.01102 to 0.00942, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 9/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - mae: 0.1282 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930 - val_mae: 0.0635\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00942 to 0.00866, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 10/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0292 - root_mean_squared_error: 0.1709 - mae: 0.1216 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885 - val_mae: 0.0609\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00866 to 0.00784, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 11/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0250 - root_mean_squared_error: 0.1579 - mae: 0.1105 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00784 to 0.00746, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 12/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - mae: 0.0994 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0579\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00746 to 0.00723, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 13/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - mae: 0.0961 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00723 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 14/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0163 - root_mean_squared_error: 0.1276 - mae: 0.0927 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00710 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 15/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0141 - root_mean_squared_error: 0.1189 - mae: 0.0870 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839 - val_mae: 0.0565\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00710 to 0.00705, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 16/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - mae: 0.0831 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0558\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00705 to 0.00687, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 17/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0125 - root_mean_squared_error: 0.1116 - mae: 0.0811 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832 - val_mae: 0.0558\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00687\n",
            "Epoch 18/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0120 - root_mean_squared_error: 0.1094 - mae: 0.0794 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00687\n",
            "Epoch 19/50\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1037 - mae: 0.0760 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00687 to 0.00684, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 20/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0112 - root_mean_squared_error: 0.1057 - mae: 0.0766 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00684\n",
            "Epoch 21/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0100 - root_mean_squared_error: 0.0998 - mae: 0.0732 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00684\n",
            "Epoch 22/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0097 - root_mean_squared_error: 0.0987 - mae: 0.0726 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00684\n",
            "Epoch 23/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0096 - root_mean_squared_error: 0.0978 - mae: 0.0716 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0552\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00684\n",
            "Epoch 24/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0091 - root_mean_squared_error: 0.0953 - mae: 0.0698 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828 - val_mae: 0.0552\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00684\n",
            "Epoch 25/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - mae: 0.0692 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825 - val_mae: 0.0550\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.00684 to 0.00681, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 26/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - mae: 0.0697 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.00681 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 27/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0087 - root_mean_squared_error: 0.0931 - mae: 0.0679 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0549\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00678 to 0.00677, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 28/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - mae: 0.0687 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0825 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00677\n",
            "Epoch 29/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - mae: 0.0681 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00677 to 0.00662, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 30/50\n",
            "71/71 [==============================] - 1s 7ms/step - loss: 0.0078 - root_mean_squared_error: 0.0885 - mae: 0.0648 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0818 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00662\n",
            "Epoch 31/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0070 - root_mean_squared_error: 0.0834 - mae: 0.0612 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0534\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.00662 to 0.00654, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 32/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0599 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.00654 to 0.00638, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 33/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0069 - root_mean_squared_error: 0.0831 - mae: 0.0590 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00638\n",
            "Epoch 34/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0066 - root_mean_squared_error: 0.0813 - mae: 0.0586 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00638 to 0.00616, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 35/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - mae: 0.0581 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0518\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00616\n",
            "Epoch 36/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0066 - root_mean_squared_error: 0.0811 - mae: 0.0582 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00616 to 0.00612, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 37/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0570 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0503\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00612 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 38/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0784 - mae: 0.0552 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0507\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00608\n",
            "Epoch 39/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0561 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00608\n",
            "Epoch 40/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0556 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00608 to 0.00606, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 41/50\n",
            "71/71 [==============================] - 1s 8ms/step - loss: 0.0057 - root_mean_squared_error: 0.0752 - mae: 0.0535 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0774 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00606 to 0.00599, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 42/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0555 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00599\n",
            "Epoch 43/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0537 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.00599\n",
            "Epoch 44/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0543 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00599 to 0.00597, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 45/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0547 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00597\n",
            "Epoch 46/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - mae: 0.0541 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.00597 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data202128.hdf5\n",
            "Epoch 47/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0534 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00587\n",
            "Epoch 48/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - mae: 0.0535 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0503\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00587\n",
            "Epoch 49/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0750 - mae: 0.0532 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00587\n",
            "Epoch 50/50\n",
            "71/71 [==============================] - 0s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0528 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00587\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0047 - root_mean_squared_error: 0.0683 - mae: 0.0474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 83%|████████▎ | 5/6 [03:30<00:37, 37.85s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 64, 'n_layers': 3, 'bs_double': 6}\n",
            "64\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.9925 - root_mean_squared_error: 0.9788 - mae: 0.7517 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - val_mae: 0.1657\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04172, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.2428 - root_mean_squared_error: 0.4921 - mae: 0.3815 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405 - val_mae: 0.0969\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04172 to 0.01974, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1255 - root_mean_squared_error: 0.3537 - mae: 0.2716 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067 - val_mae: 0.0722\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01974 to 0.01138, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0670 - root_mean_squared_error: 0.2586 - mae: 0.1980 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905 - val_mae: 0.0613\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01138 to 0.00818, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0380 - root_mean_squared_error: 0.1948 - mae: 0.1510 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852 - val_mae: 0.0576\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00818 to 0.00725, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - mae: 0.1222 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00725 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0186 - root_mean_squared_error: 0.1361 - mae: 0.1031 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819 - val_mae: 0.0545\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00678 to 0.00671, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147 - mae: 0.0871 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00671 to 0.00666, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043 - mae: 0.0792 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00666 to 0.00639, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0099 - root_mean_squared_error: 0.0994 - mae: 0.0750 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00639 to 0.00639, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0092 - root_mean_squared_error: 0.0958 - mae: 0.0703 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00639\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - mae: 0.0674 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00639 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0078 - root_mean_squared_error: 0.0884 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00635 to 0.00631, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00631\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0624 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00631 to 0.00596, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - mae: 0.0596 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00596\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - mae: 0.0575 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00596 to 0.00593, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0568 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00593 to 0.00579, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0550 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00579 to 0.00538, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0544 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00538\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0535 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00538\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00538 to 0.00522, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0534 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00522\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0740 - mae: 0.0525 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00522 to 0.00514, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0531 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00514\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0524 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00514\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0513 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00514\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0518 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00514\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00514 to 0.00509, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0510 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00509\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0502 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00509\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0707 - mae: 0.0506 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00509\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0502 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00509\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0503 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00509\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - mae: 0.0498 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00509\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00509 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0509 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00505\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0515 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00505\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0529 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00505\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - mae: 0.0519 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00505\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0510 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00505\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0511 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00505\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0489 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706 - val_mae: 0.0461\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00505 to 0.00498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0503 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00498\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00498\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0497 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00498\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0499 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00498\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0498 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0460\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00498\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0047 - root_mean_squared_error: 0.0683 - mae: 0.0483 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706 - val_mae: 0.0460\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00498 to 0.00498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - mae: 0.0488 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00498\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0041 - root_mean_squared_error: 0.0637 - mae: 0.0443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 6/6 [04:13<00:00, 42.20s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'n_neurons': 64, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 2, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 64, 'n_layers': 4, 'bs_double': 6}]\n",
            "Iteration:  4\n",
            "{'n_neurons': 16, 'n_layers': 2, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 5ms/step - loss: 0.7602 - root_mean_squared_error: 0.8575 - mae: 0.6512 - val_loss: 0.0150 - val_root_mean_squared_error: 0.1224 - val_mae: 0.0932\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1838 - root_mean_squared_error: 0.4282 - mae: 0.3200 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1206 - val_mae: 0.0928\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01498 to 0.01456, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0871 - root_mean_squared_error: 0.2949 - mae: 0.2181 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1169 - val_mae: 0.0909\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01456 to 0.01366, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0516 - root_mean_squared_error: 0.2270 - mae: 0.1671 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086 - val_mae: 0.0820\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01366 to 0.01179, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0317 - root_mean_squared_error: 0.1778 - mae: 0.1331 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055 - val_mae: 0.0781\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01179 to 0.01112, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414 - mae: 0.1078 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001 - val_mae: 0.0765\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01112 to 0.01002, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0135 - root_mean_squared_error: 0.1160 - mae: 0.0868 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955 - val_mae: 0.0724\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.01002 to 0.00911, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0111 - root_mean_squared_error: 0.1055 - mae: 0.0784 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891 - val_mae: 0.0654\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00911 to 0.00794, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0100 - root_mean_squared_error: 0.0998 - mae: 0.0737 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867 - val_mae: 0.0631\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00794 to 0.00751, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - mae: 0.0725 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851 - val_mae: 0.0607\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00751 to 0.00724, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - mae: 0.0703 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0602\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00724 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0091 - root_mean_squared_error: 0.0952 - mae: 0.0694 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838 - val_mae: 0.0596\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00710 to 0.00703, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0087 - root_mean_squared_error: 0.0934 - mae: 0.0681 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837 - val_mae: 0.0591\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00703 to 0.00701, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - mae: 0.0668 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835 - val_mae: 0.0594\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00701 to 0.00697, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - mae: 0.0661 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0594\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00697 to 0.00694, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - mae: 0.0650 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0575\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00694 to 0.00683, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0075 - root_mean_squared_error: 0.0868 - mae: 0.0638 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00683 to 0.00652, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0627 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811 - val_mae: 0.0527\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00652\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0596 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00652 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0067 - root_mean_squared_error: 0.0817 - mae: 0.0595 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00587\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0776 - mae: 0.0565 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00587\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - mae: 0.0574 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00587 to 0.00577, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0567 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00577 to 0.00573, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0555 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00573 to 0.00540, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - mae: 0.0554 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00540\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0780 - mae: 0.0554 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00540\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0768 - mae: 0.0549 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0755 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00540\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - mae: 0.0552 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00540\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0549 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00540 to 0.00528, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0534 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0753 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00528\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0524 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00528\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00528\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0537 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00528\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0529 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00528\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0533 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00528\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0541 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0741 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00528\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0547 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00528\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0528 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00528\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0529 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00528\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0044 - root_mean_squared_error: 0.0666 - mae: 0.0484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|█▋        | 1/6 [00:20<01:42, 20.57s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}\n",
            "32\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 8ms/step - loss: 0.7697 - root_mean_squared_error: 0.8638 - mae: 0.6633 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558 - val_mae: 0.1082\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02427, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2186 - root_mean_squared_error: 0.4670 - mae: 0.3561 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1440 - val_mae: 0.0985\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02427 to 0.02072, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1246 - root_mean_squared_error: 0.3527 - mae: 0.2626 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02072 to 0.01338, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0746 - root_mean_squared_error: 0.2728 - mae: 0.1999 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0660\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01338 to 0.00917, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - mae: 0.1597 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880 - val_mae: 0.0608\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00917 to 0.00775, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0308 - root_mean_squared_error: 0.1754 - mae: 0.1309 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855 - val_mae: 0.0579\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00775 to 0.00731, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1498 - mae: 0.1118 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00731 to 0.00717, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - mae: 0.0969 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0570\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00717\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0136 - root_mean_squared_error: 0.1164 - mae: 0.0873 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00717 to 0.00702, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0127 - root_mean_squared_error: 0.1129 - mae: 0.0833 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00702 to 0.00695, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040 - mae: 0.0782 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00695 to 0.00685, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0103 - root_mean_squared_error: 0.1014 - mae: 0.0756 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00685\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0723 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00685 to 0.00675, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - mae: 0.0722 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0549\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00675\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - mae: 0.0677 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0539\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00675 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0073 - root_mean_squared_error: 0.0855 - mae: 0.0637 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00644 to 0.00642, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0603 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00642 to 0.00640, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0818 - mae: 0.0585 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00640\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0561 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00640 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0562 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00588\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00588\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0560 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00588 to 0.00572, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0549 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00572\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0536 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00572 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0538 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00557\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00557\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00557\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0542 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00557\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00557 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0525 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00552\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0521 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00552\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0529 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00552\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00552\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0519 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00552\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0519 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00552\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00552 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0517 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00552 to 0.00542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0516 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00542\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0521 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00542\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0510 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00542 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0509 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00530\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712 - mae: 0.0506 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00530\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - mae: 0.0497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00530 to 0.00510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0512 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00510\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0502 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00510\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0504 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00510\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0504 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00510\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0498 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00510\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - mae: 0.0492 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00510\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0485 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00510\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - mae: 0.0450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 2/6 [00:54<01:37, 24.49s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 6ms/step - loss: 0.8881 - root_mean_squared_error: 0.9301 - mae: 0.7069 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694 - val_mae: 0.1222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2833 - root_mean_squared_error: 0.5319 - mae: 0.3976 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408 - val_mae: 0.0953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02870 to 0.01982, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1816 - root_mean_squared_error: 0.4259 - mae: 0.3081 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01982 to 0.01542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1112 - root_mean_squared_error: 0.3333 - mae: 0.2453 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01542 to 0.01196, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0750 - root_mean_squared_error: 0.2736 - mae: 0.2041 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mae: 0.0730\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01196 to 0.01099, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - mae: 0.1703 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01099 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mae: 0.1474 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977 - val_mae: 0.0684\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00980 to 0.00955, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - mae: 0.1324 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0675\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00955 to 0.00918, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - mae: 0.1204 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0661\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00918 to 0.00886, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - mae: 0.1133 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00886 to 0.00857, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1064 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00857 to 0.00849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0176 - root_mean_squared_error: 0.1328 - mae: 0.1000 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917 - val_mae: 0.0637\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00849 to 0.00840, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0984 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00840 to 0.00833, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - mae: 0.0973 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906 - val_mae: 0.0630\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00833 to 0.00821, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - mae: 0.0919 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872 - val_mae: 0.0606\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00821 to 0.00761, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - mae: 0.0778 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00761 to 0.00729, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - mae: 0.0709 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0658 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00722 to 0.00699, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0630 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00699 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0622 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0529\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00644 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0604 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00626\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00626 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00622 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0572 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00608 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0568 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00588\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - mae: 0.0576 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00588\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0558 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00588\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0511\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00588\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0560 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00588\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00588\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00588\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00588\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0534 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00588\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00588\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 3/6 [01:21<01:15, 25.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 6ms/step - loss: 0.8881 - root_mean_squared_error: 0.9301 - mae: 0.7069 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694 - val_mae: 0.1222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2833 - root_mean_squared_error: 0.5319 - mae: 0.3976 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408 - val_mae: 0.0953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02870 to 0.01982, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.1816 - root_mean_squared_error: 0.4259 - mae: 0.3081 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01982 to 0.01542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1112 - root_mean_squared_error: 0.3333 - mae: 0.2453 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01542 to 0.01196, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0750 - root_mean_squared_error: 0.2736 - mae: 0.2041 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mae: 0.0730\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01196 to 0.01099, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - mae: 0.1703 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01099 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mae: 0.1474 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977 - val_mae: 0.0684\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00980 to 0.00955, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - mae: 0.1324 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0675\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00955 to 0.00918, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - mae: 0.1204 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0661\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00918 to 0.00886, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - mae: 0.1133 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00886 to 0.00857, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1064 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00857 to 0.00849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0176 - root_mean_squared_error: 0.1328 - mae: 0.1000 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917 - val_mae: 0.0637\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00849 to 0.00840, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0984 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00840 to 0.00833, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - mae: 0.0973 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906 - val_mae: 0.0630\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00833 to 0.00821, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - mae: 0.0919 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872 - val_mae: 0.0606\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00821 to 0.00761, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - mae: 0.0778 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00761 to 0.00729, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - mae: 0.0709 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0658 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00722 to 0.00699, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0630 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00699 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0622 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0529\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00644 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0604 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00626\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00626 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00622 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0572 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00608 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0568 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00588\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - mae: 0.0576 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00588\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0558 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00588\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0511\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00588\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0560 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00588\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00588\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00588\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00588\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0534 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00588\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00588\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 4/6 [01:48<00:51, 25.73s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}\n",
            "32\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 8ms/step - loss: 0.7697 - root_mean_squared_error: 0.8638 - mae: 0.6633 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558 - val_mae: 0.1082\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02427, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2186 - root_mean_squared_error: 0.4670 - mae: 0.3561 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1440 - val_mae: 0.0985\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02427 to 0.02072, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1246 - root_mean_squared_error: 0.3527 - mae: 0.2626 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02072 to 0.01338, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0746 - root_mean_squared_error: 0.2728 - mae: 0.1999 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0660\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01338 to 0.00917, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - mae: 0.1597 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880 - val_mae: 0.0608\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00917 to 0.00775, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0308 - root_mean_squared_error: 0.1754 - mae: 0.1309 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855 - val_mae: 0.0579\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00775 to 0.00731, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1498 - mae: 0.1118 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00731 to 0.00717, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - mae: 0.0969 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0570\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00717\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0136 - root_mean_squared_error: 0.1164 - mae: 0.0873 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00717 to 0.00702, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0127 - root_mean_squared_error: 0.1129 - mae: 0.0833 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00702 to 0.00695, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040 - mae: 0.0782 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00695 to 0.00685, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0103 - root_mean_squared_error: 0.1014 - mae: 0.0756 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00685\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0723 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00685 to 0.00675, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - mae: 0.0722 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0549\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00675\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - mae: 0.0677 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0539\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00675 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0073 - root_mean_squared_error: 0.0855 - mae: 0.0637 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00644 to 0.00642, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0603 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00642 to 0.00640, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0818 - mae: 0.0585 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00640\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0561 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00640 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0562 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00588\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00588\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0560 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00588 to 0.00572, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0549 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00572\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0536 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00572 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0538 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00557\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00557\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00557\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0542 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00557\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00557 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0525 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00552\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0521 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00552\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0529 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00552\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00552\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0519 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00552\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0519 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00552\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00552 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0517 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00552 to 0.00542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0516 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00542\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0521 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00542\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0510 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00542 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0509 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00530\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712 - mae: 0.0506 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00530\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - mae: 0.0497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00530 to 0.00510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0512 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00510\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0502 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00510\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0504 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00510\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0504 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00510\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0498 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00510\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - mae: 0.0492 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00510\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0485 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00510\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - mae: 0.0450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 83%|████████▎ | 5/6 [02:20<00:27, 27.85s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 64, 'n_layers': 4, 'bs_double': 6}\n",
            "64\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 12ms/step - loss: 1.0935 - root_mean_squared_error: 1.0254 - mae: 0.7728 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615 - val_mae: 0.1159\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02609, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.2787 - root_mean_squared_error: 0.5271 - mae: 0.3949 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172 - val_mae: 0.0860\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02609 to 0.01373, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.1460 - root_mean_squared_error: 0.3820 - mae: 0.2822 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104 - val_mae: 0.0778\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01373 to 0.01218, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0867 - root_mean_squared_error: 0.2942 - mae: 0.2175 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938 - val_mae: 0.0670\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01218 to 0.00880, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0533 - root_mean_squared_error: 0.2308 - mae: 0.1724 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879 - val_mae: 0.0610\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00880 to 0.00773, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0362 - root_mean_squared_error: 0.1900 - mae: 0.1405 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0580\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00773 to 0.00738, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0247 - root_mean_squared_error: 0.1570 - mae: 0.1176 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837 - val_mae: 0.0560\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00738 to 0.00700, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - mae: 0.0997 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826 - val_mae: 0.0552\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00700 to 0.00683, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0141 - root_mean_squared_error: 0.1189 - mae: 0.0889 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00683 to 0.00671, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0128 - root_mean_squared_error: 0.1131 - mae: 0.0834 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00671 to 0.00662, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0110 - root_mean_squared_error: 0.1051 - mae: 0.0786 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00662 to 0.00649, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - mae: 0.0760 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00649 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0727 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00644 to 0.00630, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0961 - mae: 0.0719 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00630\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - mae: 0.0673 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0528\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00630 to 0.00611, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - mae: 0.0627 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00611 to 0.00593, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0065 - root_mean_squared_error: 0.0804 - mae: 0.0587 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00593 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0573 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00587\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0560 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00587 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0555 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00557\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - mae: 0.0538 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00557\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0545 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00557 to 0.00548, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0547 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00548 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0529 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00543 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0538 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00530\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0530 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00530\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0523 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00530\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0524 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00530\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0518 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00530 to 0.00522, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00522\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0049 - root_mean_squared_error: 0.0701 - mae: 0.0507 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00522\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0513 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00522\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0505 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00522\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0510 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0725 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00522\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0511 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00522\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0522 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00522\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0513 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00522 to 0.00518, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0514 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00518\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0521 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00518\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0052 - root_mean_squared_error: 0.0717 - mae: 0.0516 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00518\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00518\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0507 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00518 to 0.00518, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0048 - root_mean_squared_error: 0.0692 - mae: 0.0495 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00518 to 0.00502, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0500 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00502\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - mae: 0.0499 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00502\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0505 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00502\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00502\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0500 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00502\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 2s 12ms/step - loss: 0.0047 - root_mean_squared_error: 0.0689 - mae: 0.0485 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00502\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0048 - root_mean_squared_error: 0.0694 - mae: 0.0489 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00502\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0043 - root_mean_squared_error: 0.0652 - mae: 0.0455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 6/6 [03:42<00:00, 37.08s/it]\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'n_neurons': 64, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 64, 'n_layers': 4, 'bs_double': 6}, {'n_neurons': 32, 'n_layers': 3, 'bs_double': 4}, {'n_neurons': 768, 'n_layers': 4, 'bs_double': 4}, {'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}]\n",
            "Iteration:  5\n",
            "{'n_neurons': 64, 'n_layers': 3, 'bs_double': 6}\n",
            "64\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.9925 - root_mean_squared_error: 0.9788 - mae: 0.7517 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2043 - val_mae: 0.1657\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04172, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.2428 - root_mean_squared_error: 0.4921 - mae: 0.3815 - val_loss: 0.0197 - val_root_mean_squared_error: 0.1405 - val_mae: 0.0969\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04172 to 0.01974, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1255 - root_mean_squared_error: 0.3537 - mae: 0.2716 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1067 - val_mae: 0.0722\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01974 to 0.01138, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0670 - root_mean_squared_error: 0.2586 - mae: 0.1980 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0905 - val_mae: 0.0613\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01138 to 0.00818, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0380 - root_mean_squared_error: 0.1948 - mae: 0.1510 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852 - val_mae: 0.0576\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00818 to 0.00725, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0253 - root_mean_squared_error: 0.1590 - mae: 0.1222 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00725 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0186 - root_mean_squared_error: 0.1361 - mae: 0.1031 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819 - val_mae: 0.0545\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00678 to 0.00671, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147 - mae: 0.0871 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00671 to 0.00666, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043 - mae: 0.0792 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00666 to 0.00639, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0099 - root_mean_squared_error: 0.0994 - mae: 0.0750 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00639 to 0.00639, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0092 - root_mean_squared_error: 0.0958 - mae: 0.0703 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00639\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - mae: 0.0674 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00639 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0078 - root_mean_squared_error: 0.0884 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00635 to 0.00631, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0077 - root_mean_squared_error: 0.0876 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0523\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00631\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0624 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00631 to 0.00596, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - mae: 0.0596 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00596\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - mae: 0.0575 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00596 to 0.00593, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0568 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00593 to 0.00579, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0550 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00579 to 0.00538, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0544 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00538\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0535 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00538\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00538 to 0.00522, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0534 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00522\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0055 - root_mean_squared_error: 0.0740 - mae: 0.0525 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00522 to 0.00514, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0531 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00514\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 8ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0524 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00514\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0513 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00514\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0518 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00514\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00514 to 0.00509, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0510 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00509\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0502 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00509\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0050 - root_mean_squared_error: 0.0707 - mae: 0.0506 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00509\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0502 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00509\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0503 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00509\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - mae: 0.0498 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - val_mae: 0.0469\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00509\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00509 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0509 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00505\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0515 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00505\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0529 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00505\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - mae: 0.0519 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00505\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0510 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00505\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0511 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00505\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0489 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706 - val_mae: 0.0461\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00505 to 0.00498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0503 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00498\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00498\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0497 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00498\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0499 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00498\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0498 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0460\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00498\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0047 - root_mean_squared_error: 0.0683 - mae: 0.0483 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706 - val_mae: 0.0460\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.00498 to 0.00498, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - mae: 0.0488 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00498\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0041 - root_mean_squared_error: 0.0637 - mae: 0.0443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [00:39<05:53, 39.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 6}\n",
            "32\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 7ms/step - loss: 0.8953 - root_mean_squared_error: 0.9294 - mae: 0.7074 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249 - val_mae: 0.0923\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01559, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.2509 - root_mean_squared_error: 0.5004 - mae: 0.3758 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1239 - val_mae: 0.0883\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01559 to 0.01536, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.1483 - root_mean_squared_error: 0.3845 - mae: 0.2828 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1106 - val_mae: 0.0789\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01536 to 0.01223, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0874 - root_mean_squared_error: 0.2954 - mae: 0.2186 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0984 - val_mae: 0.0704\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01223 to 0.00969, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0550 - root_mean_squared_error: 0.2343 - mae: 0.1756 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0908 - val_mae: 0.0633\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00969 to 0.00824, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0376 - root_mean_squared_error: 0.1935 - mae: 0.1427 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870 - val_mae: 0.0601\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00824 to 0.00757, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0273 - root_mean_squared_error: 0.1650 - mae: 0.1229 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867 - val_mae: 0.0597\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00757 to 0.00751, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1057 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863 - val_mae: 0.0593\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00751 to 0.00746, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - mae: 0.0954 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00746 to 0.00739, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0144 - root_mean_squared_error: 0.1198 - mae: 0.0901 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0853 - val_mae: 0.0582\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00739 to 0.00728, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.1147 - mae: 0.0862 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00728 to 0.00713, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0114 - root_mean_squared_error: 0.1067 - mae: 0.0799 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843 - val_mae: 0.0574\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00713 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - mae: 0.0770 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00710 to 0.00708, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0109 - root_mean_squared_error: 0.1041 - mae: 0.0781 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840 - val_mae: 0.0569\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00708 to 0.00705, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0094 - root_mean_squared_error: 0.0967 - mae: 0.0728 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0814 - val_mae: 0.0546\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00705 to 0.00663, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - mae: 0.0657 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0531\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00663 to 0.00654, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0072 - root_mean_squared_error: 0.0848 - mae: 0.0627 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0808 - val_mae: 0.0528\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00654 to 0.00654, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0070 - root_mean_squared_error: 0.0835 - mae: 0.0604 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0797 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00654 to 0.00635, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0570 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00635 to 0.00611, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - mae: 0.0576 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0507\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00611 to 0.00605, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0554 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0787 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00605\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0778 - mae: 0.0563 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00605 to 0.00584, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - mae: 0.0560 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00584 to 0.00579, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0546 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00579 to 0.00565, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 8ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0542 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00565\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0059 - root_mean_squared_error: 0.0765 - mae: 0.0546 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0757 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00565\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0541 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00565\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0541 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00565\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0537 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00565 to 0.00560, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - mae: 0.0531 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00560\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0524 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00560\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0532 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00560\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00560\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0526 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.00560 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0521 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00557\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0527 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00557 to 0.00546, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0530 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00546 to 0.00535, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0518 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00535\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0526 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00535\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 7ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0513 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00535\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0718 - mae: 0.0509 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00535 to 0.00521, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0718 - mae: 0.0514 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00521\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0494 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00521 to 0.00511, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0504 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00511\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0505 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.00511 to 0.00510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - mae: 0.0511 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00510\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0050 - root_mean_squared_error: 0.0707 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00510\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0505 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00510\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - mae: 0.0491 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00510\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0049 - root_mean_squared_error: 0.0696 - mae: 0.0488 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00510\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - mae: 0.0451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 2/10 [01:24<05:29, 41.20s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 4, 'bs_double': 4}\n",
            "32\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 4s 4ms/step - loss: 0.6689 - root_mean_squared_error: 0.7945 - mae: 0.5923 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1174 - val_mae: 0.0830\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01377, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0974 - root_mean_squared_error: 0.3107 - mae: 0.2311 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1002 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01377 to 0.01005, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0414 - root_mean_squared_error: 0.2032 - mae: 0.1548 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0963 - val_mae: 0.0651\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01005 to 0.00928, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - mae: 0.1259 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0646\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00928 to 0.00847, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0114 - root_mean_squared_error: 0.1065 - mae: 0.0804 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841 - val_mae: 0.0573\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00847 to 0.00708, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - mae: 0.0663 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0804 - val_mae: 0.0536\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00708 to 0.00647, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0617 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00647 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0067 - root_mean_squared_error: 0.0815 - mae: 0.0594 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0793 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00644 to 0.00628, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0595 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00628 to 0.00612, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0071 - root_mean_squared_error: 0.0843 - mae: 0.0611 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834 - val_mae: 0.0547\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00612\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0826 - mae: 0.0597 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00612\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0785 - mae: 0.0564 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00612 to 0.00562, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0774 - mae: 0.0555 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00562 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0775 - mae: 0.0562 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00543 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0539 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00543 to 0.00520, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0761 - mae: 0.0556 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00520\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0553 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00520\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0791 - mae: 0.0568 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00520\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0770 - mae: 0.0555 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00520\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0745 - mae: 0.0540 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00520\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0731 - mae: 0.0527 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00520\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0542 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00520 to 0.00504, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0734 - mae: 0.0525 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00504 to 0.00500, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0519 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00500\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00500\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0525 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00500\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0516 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00500\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - mae: 0.0514 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0461\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00500\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0515 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0745 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00500\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0544 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00500\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0527 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00500\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0532 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0721 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00500\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 2s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0522 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00500\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0040 - root_mean_squared_error: 0.0634 - mae: 0.0452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30%|███       | 3/10 [02:35<05:50, 50.05s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 3, 'bs_double': 6}\n",
            "32\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 8ms/step - loss: 0.7697 - root_mean_squared_error: 0.8638 - mae: 0.6633 - val_loss: 0.0243 - val_root_mean_squared_error: 0.1558 - val_mae: 0.1082\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02427, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.2186 - root_mean_squared_error: 0.4670 - mae: 0.3561 - val_loss: 0.0207 - val_root_mean_squared_error: 0.1440 - val_mae: 0.0985\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02427 to 0.02072, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1246 - root_mean_squared_error: 0.3527 - mae: 0.2626 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1157 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.02072 to 0.01338, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0746 - root_mean_squared_error: 0.2728 - mae: 0.1999 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0660\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01338 to 0.00917, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - mae: 0.1597 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880 - val_mae: 0.0608\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00917 to 0.00775, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0308 - root_mean_squared_error: 0.1754 - mae: 0.1309 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855 - val_mae: 0.0579\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00775 to 0.00731, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0225 - root_mean_squared_error: 0.1498 - mae: 0.1118 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847 - val_mae: 0.0571\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00731 to 0.00717, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - mae: 0.0969 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0570\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.00717\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0136 - root_mean_squared_error: 0.1164 - mae: 0.0873 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00717 to 0.00702, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0127 - root_mean_squared_error: 0.1129 - mae: 0.0833 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00702 to 0.00695, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.1040 - mae: 0.0782 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0827 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00695 to 0.00685, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0103 - root_mean_squared_error: 0.1014 - mae: 0.0756 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829 - val_mae: 0.0554\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00685\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0723 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0821 - val_mae: 0.0548\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00685 to 0.00675, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - mae: 0.0722 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0823 - val_mae: 0.0549\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00675\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - mae: 0.0677 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0539\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00675 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0073 - root_mean_squared_error: 0.0855 - mae: 0.0637 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00644 to 0.00642, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0603 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0800 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00642 to 0.00640, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0818 - mae: 0.0585 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0517\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00640\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0561 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00640 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0562 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0778 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00588\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0799 - val_mae: 0.0522\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00588\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0560 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00588 to 0.00572, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0756 - mae: 0.0549 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00572\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0536 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00572 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0538 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00557\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00557\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00557\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0758 - mae: 0.0542 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00557\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00557 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0525 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00552\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0521 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00552\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0529 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00552\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0741 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00552\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0519 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00552\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0519 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00552\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0531 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00552 to 0.00552, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0517 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00552 to 0.00542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0516 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00542\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0521 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00542\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0510 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.00542 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - mae: 0.0509 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00530\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712 - mae: 0.0506 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00530\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - mae: 0.0497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00530 to 0.00510, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0512 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00510\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0502 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00510\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0504 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00510\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0504 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00510\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0498 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00510\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - mae: 0.0492 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0715 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00510\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - mae: 0.0485 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00510\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - mae: 0.0450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 4/10 [03:08<04:29, 44.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 3, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 7ms/step - loss: 0.5924 - root_mean_squared_error: 0.7563 - mae: 0.5581 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1417 - val_mae: 0.0957\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02007, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.1639 - root_mean_squared_error: 0.4044 - mae: 0.2868 - val_loss: 0.0161 - val_root_mean_squared_error: 0.1267 - val_mae: 0.0866\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02007 to 0.01607, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0953 - root_mean_squared_error: 0.3084 - mae: 0.2129 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1118 - val_mae: 0.0777\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01607 to 0.01249, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0644 - root_mean_squared_error: 0.2535 - mae: 0.1713 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1019 - val_mae: 0.0702\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01249 to 0.01039, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0439 - root_mean_squared_error: 0.2092 - mae: 0.1418 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945 - val_mae: 0.0653\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01039 to 0.00892, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0289 - root_mean_squared_error: 0.1699 - mae: 0.1193 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912 - val_mae: 0.0622\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00892 to 0.00832, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0228 - root_mean_squared_error: 0.1508 - mae: 0.1062 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895 - val_mae: 0.0615\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00832 to 0.00800, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - mae: 0.0976 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0876 - val_mae: 0.0596\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00800 to 0.00768, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0157 - root_mean_squared_error: 0.1252 - mae: 0.0912 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871 - val_mae: 0.0598\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00768 to 0.00758, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0152 - root_mean_squared_error: 0.1231 - mae: 0.0876 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00758 to 0.00747, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180 - mae: 0.0847 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00747 to 0.00746, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0125 - root_mean_squared_error: 0.1118 - mae: 0.0811 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0583\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00746 to 0.00737, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - mae: 0.0796 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0857 - val_mae: 0.0583\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00737 to 0.00735, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - mae: 0.0779 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856 - val_mae: 0.0584\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00735 to 0.00733, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0108 - root_mean_squared_error: 0.1039 - mae: 0.0764 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00733 to 0.00693, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0085 - root_mean_squared_error: 0.0923 - mae: 0.0680 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00693 to 0.00686, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - mae: 0.0657 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00686 to 0.00678, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0073 - root_mean_squared_error: 0.0857 - mae: 0.0610 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00678 to 0.00660, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00660 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0585 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0789 - val_mae: 0.0510\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00622\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0577 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0812 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00622\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0800 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00622 to 0.00606, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0564 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0773 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00606 to 0.00598, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0782 - mae: 0.0557 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00598 to 0.00580, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0551 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00580\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0558 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00580\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0550 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0785 - val_mae: 0.0507\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00580\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - root_mean_squared_error: 0.0779 - mae: 0.0552 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00580\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0060 - root_mean_squared_error: 0.0776 - mae: 0.0551 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00580 to 0.00577, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0546 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00577\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - mae: 0.0534 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00577\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0540 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0769 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00577\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0536 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0494\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00577\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0539 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0762 - val_mae: 0.0490\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00577\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0759 - mae: 0.0540 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0492\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00577\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - mae: 0.0552 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.00577 to 0.00566, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0536 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00566 to 0.00553, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0519 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00553\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0745 - mae: 0.0534 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00553\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0740 - mae: 0.0525 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00553\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0513 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0486\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00553\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 5ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0521 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.00553\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0504 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00553 to 0.00546, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0518 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0764 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00546\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0055 - root_mean_squared_error: 0.0744 - mae: 0.0525 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00546\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0731 - mae: 0.0513 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0748 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00546\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0053 - root_mean_squared_error: 0.0731 - mae: 0.0515 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00546\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0728 - mae: 0.0513 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00546\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0723 - mae: 0.0511 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00546\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0503 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.00546 to 0.00545, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0043 - root_mean_squared_error: 0.0655 - mae: 0.0459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [03:37<03:20, 40.04s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 6}\n",
            "16\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 2s 8ms/step - loss: 0.8881 - root_mean_squared_error: 0.9301 - mae: 0.7069 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694 - val_mae: 0.1222\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2833 - root_mean_squared_error: 0.5319 - mae: 0.3976 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1408 - val_mae: 0.0953\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02870 to 0.01982, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1816 - root_mean_squared_error: 0.4259 - mae: 0.3081 - val_loss: 0.0154 - val_root_mean_squared_error: 0.1242 - val_mae: 0.0871\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01982 to 0.01542, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.1112 - root_mean_squared_error: 0.3333 - mae: 0.2453 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094 - val_mae: 0.0780\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01542 to 0.01196, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0750 - root_mean_squared_error: 0.2736 - mae: 0.2041 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048 - val_mae: 0.0730\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01196 to 0.01099, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0526 - root_mean_squared_error: 0.2293 - mae: 0.1703 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0990 - val_mae: 0.0693\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.01099 to 0.00980, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mae: 0.1474 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0977 - val_mae: 0.0684\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00980 to 0.00955, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - mae: 0.1324 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958 - val_mae: 0.0675\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00955 to 0.00918, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0255 - root_mean_squared_error: 0.1597 - mae: 0.1204 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0661\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00918 to 0.00886, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - mae: 0.1133 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0926 - val_mae: 0.0650\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00886 to 0.00857, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - mae: 0.1064 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921 - val_mae: 0.0644\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00857 to 0.00849, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0176 - root_mean_squared_error: 0.1328 - mae: 0.1000 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917 - val_mae: 0.0637\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00849 to 0.00840, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0166 - root_mean_squared_error: 0.1287 - mae: 0.0984 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913 - val_mae: 0.0634\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00840 to 0.00833, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - mae: 0.0973 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0906 - val_mae: 0.0630\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00833 to 0.00821, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0149 - root_mean_squared_error: 0.1220 - mae: 0.0919 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872 - val_mae: 0.0606\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00821 to 0.00761, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - mae: 0.0778 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0854 - val_mae: 0.0589\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00761 to 0.00729, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - mae: 0.0709 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850 - val_mae: 0.0578\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00729 to 0.00722, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - mae: 0.0658 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836 - val_mae: 0.0559\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00722 to 0.00699, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0074 - root_mean_squared_error: 0.0861 - mae: 0.0630 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0802 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00699 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0071 - root_mean_squared_error: 0.0840 - mae: 0.0622 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0791 - val_mae: 0.0529\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00644 to 0.00626, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0604 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0809 - val_mae: 0.0543\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00626\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0597 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0788 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00626 to 0.00622, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - mae: 0.0581 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0780 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00622 to 0.00608, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0063 - root_mean_squared_error: 0.0794 - mae: 0.0572 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0767 - val_mae: 0.0509\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00608 to 0.00588, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0568 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0516\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00588\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0803 - mae: 0.0576 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0513\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00588\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0558 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0519\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00588\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0563 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781 - val_mae: 0.0511\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00588\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 6ms/step - loss: 0.0061 - root_mean_squared_error: 0.0783 - mae: 0.0560 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0505\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00588\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0564 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00588\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0548 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0776 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00588\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00588\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0057 - root_mean_squared_error: 0.0754 - mae: 0.0534 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0772 - val_mae: 0.0504\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00588\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0060 - root_mean_squared_error: 0.0773 - mae: 0.0552 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0501\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00588\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0048 - root_mean_squared_error: 0.0693 - mae: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [04:02<02:21, 35.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 64, 'n_layers': 4, 'bs_double': 6}\n",
            "64\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 3s 12ms/step - loss: 1.0935 - root_mean_squared_error: 1.0254 - mae: 0.7728 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615 - val_mae: 0.1159\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.02609, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.2787 - root_mean_squared_error: 0.5271 - mae: 0.3949 - val_loss: 0.0137 - val_root_mean_squared_error: 0.1172 - val_mae: 0.0860\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.02609 to 0.01373, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.1460 - root_mean_squared_error: 0.3820 - mae: 0.2822 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104 - val_mae: 0.0778\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01373 to 0.01218, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0867 - root_mean_squared_error: 0.2942 - mae: 0.2175 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938 - val_mae: 0.0670\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01218 to 0.00880, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0533 - root_mean_squared_error: 0.2308 - mae: 0.1724 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879 - val_mae: 0.0610\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00880 to 0.00773, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0362 - root_mean_squared_error: 0.1900 - mae: 0.1405 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0580\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00773 to 0.00738, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0247 - root_mean_squared_error: 0.1570 - mae: 0.1176 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837 - val_mae: 0.0560\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00738 to 0.00700, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - mae: 0.0997 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0826 - val_mae: 0.0552\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00700 to 0.00683, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0141 - root_mean_squared_error: 0.1189 - mae: 0.0889 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00683 to 0.00671, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0128 - root_mean_squared_error: 0.1131 - mae: 0.0834 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0813 - val_mae: 0.0544\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00671 to 0.00662, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0110 - root_mean_squared_error: 0.1051 - mae: 0.0786 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0806 - val_mae: 0.0535\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.00662 to 0.00649, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0106 - root_mean_squared_error: 0.1029 - mae: 0.0760 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0803 - val_mae: 0.0532\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00649 to 0.00644, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0727 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0794 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00644 to 0.00630, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0961 - mae: 0.0719 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0795 - val_mae: 0.0524\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00630\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - mae: 0.0673 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0528\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00630 to 0.00611, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - mae: 0.0627 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0770 - val_mae: 0.0508\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00611 to 0.00593, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0065 - root_mean_squared_error: 0.0804 - mae: 0.0587 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.00593 to 0.00587, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0573 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0766 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00587\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0060 - root_mean_squared_error: 0.0772 - mae: 0.0560 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.00587 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0555 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0500\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00557\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - mae: 0.0538 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0506\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00557\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0545 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00557 to 0.00548, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - mae: 0.0547 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00548 to 0.00543, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0529 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00543 to 0.00530, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0538 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00530\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0747 - mae: 0.0530 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0733 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00530\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0523 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00530\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0054 - root_mean_squared_error: 0.0733 - mae: 0.0524 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0487\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00530\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0727 - mae: 0.0518 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.00530 to 0.00522, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0520 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00522\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0049 - root_mean_squared_error: 0.0701 - mae: 0.0507 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0737 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00522\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - mae: 0.0513 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0477\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00522\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0505 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00522\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0715 - mae: 0.0510 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0725 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00522\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0511 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00522\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0522 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00522\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0513 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00522 to 0.00518, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - mae: 0.0514 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00518\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 1s 9ms/step - loss: 0.0053 - root_mean_squared_error: 0.0730 - mae: 0.0521 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726 - val_mae: 0.0481\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00518\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0052 - root_mean_squared_error: 0.0717 - mae: 0.0516 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0724 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00518\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0712 - mae: 0.0503 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.00518\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0713 - mae: 0.0507 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0478\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00518 to 0.00518, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0048 - root_mean_squared_error: 0.0692 - mae: 0.0495 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00518 to 0.00502, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20264.hdf5\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0500 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.00502\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0709 - mae: 0.0499 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00502\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - mae: 0.0505 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0738 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00502\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0050 - root_mean_squared_error: 0.0705 - mae: 0.0497 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00502\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 2s 11ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - mae: 0.0500 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00502\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 1s 10ms/step - loss: 0.0047 - root_mean_squared_error: 0.0689 - mae: 0.0485 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00502\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 1s 11ms/step - loss: 0.0048 - root_mean_squared_error: 0.0694 - mae: 0.0489 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00502\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0043 - root_mean_squared_error: 0.0652 - mae: 0.0455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 70%|███████   | 7/10 [05:22<02:26, 48.91s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 32, 'n_layers': 3, 'bs_double': 4}\n",
            "32\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 3s 3ms/step - loss: 0.5599 - root_mean_squared_error: 0.7305 - mae: 0.5586 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105 - val_mae: 0.0777\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01220, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0693 - root_mean_squared_error: 0.2626 - mae: 0.2000 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897 - val_mae: 0.0618\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01220 to 0.00805, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0308 - root_mean_squared_error: 0.1753 - mae: 0.1343 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878 - val_mae: 0.0597\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00805 to 0.00771, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - mae: 0.1071 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863 - val_mae: 0.0592\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00771 to 0.00745, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0736 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00745 to 0.00651, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0074 - root_mean_squared_error: 0.0858 - mae: 0.0633 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00651 to 0.00618, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0069 - root_mean_squared_error: 0.0833 - mae: 0.0601 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00618\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0792 - mae: 0.0577 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00618 to 0.00613, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0800 - mae: 0.0585 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00613 to 0.00595, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0604 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00595\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0590 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00595\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - mae: 0.0556 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00595 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0548 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00557 to 0.00539, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0557 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00539\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0542 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00539 to 0.00523, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0552 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00523\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0548 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00523\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0570 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00523\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0550 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00523\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0537 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00523\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0531 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00523 to 0.00513, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0539 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00513 to 0.00509, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0530 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00509 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00505 to 0.00503, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - mae: 0.0527 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00503\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0518 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00503\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00503\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0516 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00503 to 0.00500, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0510 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0514\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00500\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00500\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0523 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00500\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0524 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00500\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - mae: 0.0517 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00500\n",
            "Epoch 34/50\n",
            "567/567 [==============================] - 1s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00500\n",
            "Epoch 35/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0514 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00500\n",
            "Epoch 36/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0516 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00500\n",
            "Epoch 37/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0516 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00500\n",
            "Epoch 38/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0462\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00500\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - mae: 0.0445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 8/10 [06:25<01:46, 53.29s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 768, 'n_layers': 4, 'bs_double': 4}\n",
            "768\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 128s 224ms/step - loss: 2.4649 - root_mean_squared_error: 1.4279 - mae: 0.9620 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733 - val_mae: 0.1360\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03004, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 128s 226ms/step - loss: 0.1245 - root_mean_squared_error: 0.3513 - mae: 0.2724 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156 - val_mae: 0.0855\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.03004 to 0.01335, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 128s 226ms/step - loss: 0.0508 - root_mean_squared_error: 0.2252 - mae: 0.1754 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0870 - val_mae: 0.0612\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01335 to 0.00757, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 126s 223ms/step - loss: 0.0341 - root_mean_squared_error: 0.1845 - mae: 0.1433 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221 - val_mae: 0.0930\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00757\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 126s 223ms/step - loss: 0.0159 - root_mean_squared_error: 0.1259 - mae: 0.0965 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1187 - val_mae: 0.0933\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00757\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0742 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0816 - val_mae: 0.0570\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00757 to 0.00667, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0079 - root_mean_squared_error: 0.0887 - mae: 0.0664 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0564\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00667 to 0.00633, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 127s 224ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - mae: 0.0609 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00633 to 0.00546, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 128s 225ms/step - loss: 0.0062 - root_mean_squared_error: 0.0789 - mae: 0.0585 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1200 - val_mae: 0.0932\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.00546\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0175 - root_mean_squared_error: 0.1322 - mae: 0.1030 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941 - val_mae: 0.0677\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00546\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0143 - root_mean_squared_error: 0.1195 - mae: 0.0915 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0801 - val_mae: 0.0561\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00546\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0097 - root_mean_squared_error: 0.0984 - mae: 0.0751 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974 - val_mae: 0.0726\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.00546\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0738 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0897 - val_mae: 0.0651\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00546\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - mae: 0.0664 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0759 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00546\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 127s 223ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - mae: 0.0611 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831 - val_mae: 0.0605\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00546\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 126s 222ms/step - loss: 0.0062 - root_mean_squared_error: 0.0786 - mae: 0.0586 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0792 - val_mae: 0.0533\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00546\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 126s 223ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - mae: 0.0576 - val_loss: 0.0184 - val_root_mean_squared_error: 0.1355 - val_mae: 0.1056\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00546\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 126s 223ms/step - loss: 0.0161 - root_mean_squared_error: 0.1266 - mae: 0.0973 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055 - val_mae: 0.0769\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00546\n",
            "46/46 [==============================] - 3s 52ms/step - loss: 0.0046 - root_mean_squared_error: 0.0679 - mae: 0.0477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 90%|█████████ | 9/10 [44:45<12:07, 727.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_neurons': 16, 'n_layers': 4, 'bs_double': 4}\n",
            "16\n",
            "Epoch 1/50\n",
            "567/567 [==============================] - 4s 4ms/step - loss: 0.6746 - root_mean_squared_error: 0.8047 - mae: 0.6149 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367 - val_mae: 0.0967\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01870, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.1080 - root_mean_squared_error: 0.3281 - mae: 0.2476 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1109 - val_mae: 0.0802\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01870 to 0.01230, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0505 - root_mean_squared_error: 0.2245 - mae: 0.1678 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1054 - val_mae: 0.0748\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.01230 to 0.01112, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - mae: 0.1432 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1026 - val_mae: 0.0745\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.01112 to 0.01053, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0172 - root_mean_squared_error: 0.1310 - mae: 0.0992 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993 - val_mae: 0.0700\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.01053 to 0.00986, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - mae: 0.0818 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914 - val_mae: 0.0626\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00986 to 0.00835, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - mae: 0.0710 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859 - val_mae: 0.0575\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.00835 to 0.00738, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - mae: 0.0675 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0842 - val_mae: 0.0560\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00738 to 0.00710, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - mae: 0.0652 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0796 - val_mae: 0.0536\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00710 to 0.00633, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0077 - root_mean_squared_error: 0.0879 - mae: 0.0643 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0782 - val_mae: 0.0518\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.00633 to 0.00612, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0072 - root_mean_squared_error: 0.0846 - mae: 0.0610 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811 - val_mae: 0.0530\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00612\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0799 - mae: 0.0573 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0484\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00612 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0063 - root_mean_squared_error: 0.0790 - mae: 0.0565 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0736 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00557 to 0.00541, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0064 - root_mean_squared_error: 0.0797 - mae: 0.0576 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00541 to 0.00532, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0771 - mae: 0.0557 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00532 to 0.00521, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0558 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00521\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0784 - mae: 0.0563 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00521\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0065 - root_mean_squared_error: 0.0808 - mae: 0.0577 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00521\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0062 - root_mean_squared_error: 0.0787 - mae: 0.0565 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0495\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00521\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0550 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.00521 to 0.00506, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0760 - mae: 0.0550 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00506\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0060 - root_mean_squared_error: 0.0771 - mae: 0.0553 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00506\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0533 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0463\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00506 to 0.00502, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00502\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - mae: 0.0535 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0718 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00502\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0751 - mae: 0.0530 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00502\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0532 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00502\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0738 - mae: 0.0526 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0465\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00502\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0739 - mae: 0.0529 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00502\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0057 - root_mean_squared_error: 0.0757 - mae: 0.0547 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0728 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00502\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0534 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00502\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0539 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0744 - val_mae: 0.0502\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00502\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 2s 3ms/step - loss: 0.0058 - root_mean_squared_error: 0.0763 - mae: 0.0532 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00502\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0042 - root_mean_squared_error: 0.0643 - mae: 0.0453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [45:49<00:00, 274.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 2h 4min 53s (started: 2021-01-14 18:14:43 +00:00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2cGpGHZuBV",
        "outputId": "0d4bf12e-c932-4098-8385-b3df70986a08"
      },
      "source": [
        "rmse, ga_network"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(0.0683944970369339,),\n",
              "  (0.06849377602338791,),\n",
              "  (0.06914170831441879,),\n",
              "  (0.06920970976352692,),\n",
              "  (0.069307841360569,),\n",
              "  (0.06957530975341797,),\n",
              "  (0.07013912498950958,),\n",
              "  (0.07075611501932144,),\n",
              "  (0.0721215084195137,),\n",
              "  (0.07318631559610367,)],\n",
              " [{'bs_double': 4, 'n_layers': 3, 'n_neurons': 32},\n",
              "  {'bs_double': 6, 'n_layers': 3, 'n_neurons': 64},\n",
              "  {'bs_double': 6, 'n_layers': 4, 'n_neurons': 32},\n",
              "  {'bs_double': 4, 'n_layers': 4, 'n_neurons': 32},\n",
              "  {'bs_double': 6, 'n_layers': 3, 'n_neurons': 32},\n",
              "  {'bs_double': 6, 'n_layers': 3, 'n_neurons': 16},\n",
              "  {'bs_double': 4, 'n_layers': 4, 'n_neurons': 16},\n",
              "  {'bs_double': 6, 'n_layers': 4, 'n_neurons': 64},\n",
              "  {'bs_double': 4, 'n_layers': 4, 'n_neurons': 768},\n",
              "  {'bs_double': 6, 'n_layers': 4, 'n_neurons': 16}])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        },
        {
          "output_type": "stream",
          "text": [
            "time: 5.89 ms (started: 2021-01-14 20:19:37 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sx3xJ9B0Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1921e28-9b3a-44ef-856e-5fb19858b71c"
      },
      "source": [
        "#assign the first order as the best model\n",
        "best_model = ga_network[0]\n",
        "#best_model = {'bs_double': 4, 'n_layers': 3, 'n_neurons': 32}\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bs_double': 4, 'n_layers': 3, 'n_neurons': 32}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "stream",
          "text": [
            "time: 6.62 ms (started: 2021-01-15 17:28:44 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnG601CDbinI"
      },
      "source": [
        "#best_model['n_timewindow']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpm7PWFqmdTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c4efd3-8600-496c-a746-5b83c66c55da"
      },
      "source": [
        "bs = 2**best_model['bs_double']\n",
        "bs_name = str(bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1 ms (started: 2021-01-15 17:28:47 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCGpkf1xbJj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c9cfe3-873f-4065-9cd9-5dce7da55ae2"
      },
      "source": [
        "#retrain the final model\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, split_index_test, scaler = df_scaling(df=data, target_column='Driving_time_s')\n",
        "MLP_train(X_train, y_train, X_val, y_val, X_test, y_test, n_neurons= best_model['n_neurons'], n_layers= best_model['n_layers'], bs_double= best_model['bs_double'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "567/567 [==============================] - 3s 3ms/step - loss: 0.5599 - root_mean_squared_error: 0.7305 - mae: 0.5586 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1105 - val_mae: 0.0777\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.01220, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 2/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0693 - root_mean_squared_error: 0.2626 - mae: 0.2000 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0897 - val_mae: 0.0618\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.01220 to 0.00805, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 3/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0308 - root_mean_squared_error: 0.1753 - mae: 0.1343 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878 - val_mae: 0.0597\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00805 to 0.00771, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 4/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - mae: 0.1071 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0863 - val_mae: 0.0592\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.00771 to 0.00745, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 5/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - mae: 0.0736 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0807 - val_mae: 0.0538\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.00745 to 0.00651, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 6/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0074 - root_mean_squared_error: 0.0858 - mae: 0.0633 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0521\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.00651 to 0.00618, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 7/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0069 - root_mean_squared_error: 0.0833 - mae: 0.0601 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0786 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00618\n",
            "Epoch 8/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0792 - mae: 0.0577 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0783 - val_mae: 0.0512\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.00618 to 0.00613, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 9/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0064 - root_mean_squared_error: 0.0800 - mae: 0.0585 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0771 - val_mae: 0.0515\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.00613 to 0.00595, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 10/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0069 - root_mean_squared_error: 0.0828 - mae: 0.0604 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.00595\n",
            "Epoch 11/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0067 - root_mean_squared_error: 0.0819 - mae: 0.0590 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775 - val_mae: 0.0498\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.00595\n",
            "Epoch 12/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0060 - root_mean_squared_error: 0.0777 - mae: 0.0556 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746 - val_mae: 0.0489\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.00595 to 0.00557, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 13/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0548 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734 - val_mae: 0.0483\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.00557 to 0.00539, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 14/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0557 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0739 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00539\n",
            "Epoch 15/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0542 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0723 - val_mae: 0.0471\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.00539 to 0.00523, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 16/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - mae: 0.0552 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730 - val_mae: 0.0480\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00523\n",
            "Epoch 17/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - mae: 0.0548 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0752 - val_mae: 0.0496\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00523\n",
            "Epoch 18/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - mae: 0.0570 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735 - val_mae: 0.0475\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00523\n",
            "Epoch 19/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0059 - root_mean_squared_error: 0.0767 - mae: 0.0550 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729 - val_mae: 0.0482\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00523\n",
            "Epoch 20/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0746 - mae: 0.0537 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743 - val_mae: 0.0488\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00523\n",
            "Epoch 21/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - mae: 0.0531 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0474\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.00523 to 0.00513, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 22/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0056 - root_mean_squared_error: 0.0749 - mae: 0.0539 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00513 to 0.00509, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 23/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0736 - mae: 0.0530 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0476\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.00509 to 0.00505, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 24/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0052 - root_mean_squared_error: 0.0722 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0709 - val_mae: 0.0467\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00505 to 0.00503, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 25/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - mae: 0.0527 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716 - val_mae: 0.0473\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00503\n",
            "Epoch 26/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - mae: 0.0518 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00503\n",
            "Epoch 27/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711 - val_mae: 0.0466\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00503\n",
            "Epoch 28/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0516 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.00503 to 0.00500, saving model to /content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20216.hdf5\n",
            "Epoch 29/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0050 - root_mean_squared_error: 0.0710 - mae: 0.0510 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0768 - val_mae: 0.0514\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00500\n",
            "Epoch 30/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0055 - root_mean_squared_error: 0.0743 - mae: 0.0535 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750 - val_mae: 0.0493\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00500\n",
            "Epoch 31/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - mae: 0.0523 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0756 - val_mae: 0.0526\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00500\n",
            "Epoch 32/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0524 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0719 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00500\n",
            "Epoch 33/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0054 - root_mean_squared_error: 0.0737 - mae: 0.0517 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747 - val_mae: 0.0499\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00500\n",
            "Epoch 34/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0515 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00500\n",
            "Epoch 35/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0726 - mae: 0.0514 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712 - val_mae: 0.0464\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.00500\n",
            "Epoch 36/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - mae: 0.0516 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0720 - val_mae: 0.0470\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00500\n",
            "Epoch 37/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0052 - root_mean_squared_error: 0.0721 - mae: 0.0516 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0713 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.00500\n",
            "Epoch 38/50\n",
            "567/567 [==============================] - 1s 2ms/step - loss: 0.0053 - root_mean_squared_error: 0.0729 - mae: 0.0519 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710 - val_mae: 0.0462\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.00500\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - mae: 0.0445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0683944970369339,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "stream",
          "text": [
            "time: 53.4 s (started: 2021-01-15 17:28:49 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp-YfPAuAwDg"
      },
      "source": [
        "# Cross validate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0quBw7k4_Pyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fcf448-cf77-4168-a05a-d56712482817"
      },
      "source": [
        "#set learning rate and optimizer\n",
        "lr=1.e-3\n",
        "'''\n",
        "n_steps=2000\n",
        "global_step=1\n",
        "LR = keras.experimental.CosineDecayRestarts(\n",
        "    initial_learning_rate=lr,\n",
        "    first_decay_steps=n_steps,\n",
        "    t_mul= 1.5,\n",
        "    m_mul= 1,\n",
        "    alpha=0.1,\n",
        "    name=None\n",
        ")\n",
        "'''\n",
        "adam = Adam(learning_rate=lr) #, weight_decay=1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.35 ms (started: 2021-01-15 17:36:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfHfr-s9aE1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f5430a4-f54c-4321-dd97-1036ff3fb4ed"
      },
      "source": [
        "%time\n",
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_'+path_end+bs_name+'.hdf5') # Gave an error when loading without 'custom_objects'.. fixed by https://github.com/keras-team/keras/issues/3911\n",
        "#model = load_model('/content/drive/My Drive/Colab Notebooks/Thesis/best model/MLPGA.best_mse_data20116.hdf5')\n",
        "# Compile with the same settings as it has been saved with earlier\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=adam, metrics=['RootMeanSquaredError', 'mae'])\n",
        "\n",
        "print('FINISHED')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
            "Wall time: 9.54 µs\n",
            "FINISHED\n",
            "time: 175 ms (started: 2021-01-15 17:36:12 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqdOLzDB4kLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf1943b-613c-4cc2-99d7-41df10da3056"
      },
      "source": [
        "bs_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'16'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.02 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThaH8zR7Au-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154b39c8-1a06-43aa-ea39-298b1384060d"
      },
      "source": [
        "#predict value for test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_true = y_test.reshape(y_test.shape[0], 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 210 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUAtAF-xF651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc0cae9-b09e-491e-b2dd-ba6711ac55df"
      },
      "source": [
        "#evaluate the model result of the test set\n",
        "model.evaluate(X_test, y_test)[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 956us/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - mae: 0.0445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0683944970369339"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "text": [
            "time: 352 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AIrGfWxF6GT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f483adb4-b14d-4178-c1a5-b40bc8852f3b"
      },
      "source": [
        "# invert scaling for forecast\n",
        "inv_y_pred = np.concatenate((X_test[:, :], y_pred), axis=1)\n",
        "inv_y_pred = scaler.inverse_transform(inv_y_pred)\n",
        "inv_y_pred = inv_y_pred[:,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.99 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGQIwj8JXpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110d6446-c332-4aa2-abaf-46c81ca6eac4"
      },
      "source": [
        "inv_y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([183.98786223,  69.24548171,  83.22512971, ..., 162.96238554,\n",
              "        73.03595352, 153.64154863])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.27 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvXCZWadJIWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec067ca5-ae4e-4bd4-a271-816be6cb073a"
      },
      "source": [
        "# invert scaling for actual\n",
        "inv_y_true = np.concatenate(( X_test[:,:], y_true), axis=1)\n",
        "inv_y_true = scaler.inverse_transform(inv_y_true)\n",
        "inv_y_true = inv_y_true[:,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4.59 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg5_Hke-JQwo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f663a0f-34c5-4b04-863b-c6d2792f75d3"
      },
      "source": [
        "# calculate RMSE\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(inv_y_true, inv_y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(inv_y_true, inv_y_pred))\n",
        "mae = mean_absolute_error(inv_y_true, inv_y_pred)\n",
        "print('Test MSE: %.3f' % mse)\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "print('Test MAE: %.3f' % mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test MSE: 1717.859\n",
            "Test RMSE: 41.447\n",
            "Test MAE: 27.922\n",
            "time: 43.2 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Sfvun2KuuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0c8d4d-a141-4d59-db83-43c8dbb7a5ec"
      },
      "source": [
        "#for plotting graph\n",
        "\n",
        "x = data[split_index_test:]\n",
        "\n",
        "datetime_difference = len(x) - len(y_true)\n",
        "x = x[datetime_difference:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.46 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AMA-hgy3PQM"
      },
      "source": [
        "Show in the graph only first 50 points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d_Csz7EBAs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d970c180-3059-49ae-e57e-5e9367d9e29f"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(inv_y_true[:50], '.-', color='red', label='Real values', alpha=0.5)\n",
        "plt.plot(inv_y_pred[:50], '.-', color='blue', label='Predicted values', alpha=1)\n",
        "\n",
        "plt.ylabel(r'Driving time [s]', fontsize=14)\n",
        "plt.xlabel('time point', fontsize=14) \n",
        "\n",
        "plt.xticks(fontsize=10, rotation=90)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "plt.legend(loc='upper left', borderaxespad=0, frameon=False, fontsize=14, markerscale=3)\n",
        "\n",
        "mse_result, rmse_result, mae_result = model.evaluate(X_test, y_test)\n",
        "\n",
        "plt.title(path_name+'\\n MLPGA %.0f hidden layers result \\n batch_size = 2**%.0f with %.0f neurons in each layer \\n MSE = %.2f \\n RMSE = %.1f  \\n MAE = %.1f' \n",
        "          % (best_model['n_layers'], best_model['bs_double'], \n",
        "             best_model['n_neurons'], \n",
        "             mse, rmse, mae), fontsize = 14)\n",
        "\n",
        "print('FINISHED')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 1ms/step - loss: 0.0047 - root_mean_squared_error: 0.0684 - mae: 0.0461\n",
            "FINISHED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 449 ms (started: 2021-01-15 17:36:13 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToZ1K7xALIZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e770339-761f-41a3-b868-8e2260ae3a24"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.plot( inv_y_true, '.-', color='red', label='Real values', alpha=0.5)\n",
        "plt.plot( inv_y_pred, '.-', color='blue', label='Predicted values', alpha=1)\n",
        "\n",
        "plt.ylabel(r'Driving time [s]', fontsize=14)\n",
        "plt.xlabel('datetime [-]', fontsize=14)\n",
        "\n",
        "plt.xticks(fontsize=10, rotation=90)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "plt.legend(loc='upper left', borderaxespad=0, frameon=False, fontsize=14, markerscale=3)\n",
        "\n",
        "mse_result, rmse_result, mae_result = model.evaluate(X_test, y_test)\n",
        "\n",
        "plt.title(path_name+'\\n MLPGA %.0f hidden layers result \\n batch_size = 2**%.0f with %.0f neurons in each lstm layer \\n MSE = %.2f \\n RMASE = %.1f  \\n MAE = %.1f' \n",
        "          % (best_model['n_layers'], best_model['bs_double'], \n",
        "             best_model['n_neurons'],  mse, rmse, mae), fontsize = 14)\n",
        "\n",
        "print('FINISHED')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 0s 917us/step - loss: 0.0047 - root_mean_squared_error: 0.0684 - mae: 0.0461\n",
            "FINISHED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 559 ms (started: 2021-01-15 17:36:14 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmJnUXtLMPVD"
      },
      "source": [
        "# Combine results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BshbaVGdZqHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d20f05-d8ef-46ed-bfc6-7bfbc804d970"
      },
      "source": [
        "comb_result= comb_result.drop(['Unnamed: 0'], axis=1) #, 'Unnamed: 0.1', 'Unnamed: 0.1.1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 3.88 ms (started: 2021-01-15 17:36:34 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfSlVampL8wH"
      },
      "source": [
        "#comb_result=comb_result[datetime_difference:].reset_index()\n",
        "#comb_result.rename(columns={'Unnamed: 0.1': 'index'})\n",
        "comb_result = comb_result.rename(columns= {'Unnamed: 0.1':'index'})\n",
        "comb_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vntydP7qMItu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae969d32-6572-43ab-bd5e-f67e401fcaa1"
      },
      "source": [
        "len(inv_y_pred[len(comb_result['Path'].unique())*2:])\n",
        "#len(inv_y_pred[:])\n",
        "#len(comb_result['Path'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.02 ms (started: 2021-01-15 17:39:01 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy7dQKzhNIp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20007993-31d2-4030-cd82-5bc140ce75c8"
      },
      "source": [
        "#inv_y_pred[int(np.floor(size_trip*best_model['n_timewindow'])):]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 841 µs (started: 2021-01-15 17:36:46 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1mAVAfBMOPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "outputId": "13456ed2-20ee-40bc-c7b7-07615f42be59"
      },
      "source": [
        "comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name] = inv_y_pred[len(comb_result['Path'].unique())*2:]\n",
        "#comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name] = inv_y_pred[11:]\n",
        "#comb_result = comb_result[20:].reset_index(drop = True)\n",
        "comb_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date time</th>\n",
              "      <th>Path</th>\n",
              "      <th>Actual</th>\n",
              "      <th>Actual_trip_cum</th>\n",
              "      <th>MLP</th>\n",
              "      <th>MLP_trip_cum</th>\n",
              "      <th>MLP_Kalman</th>\n",
              "      <th>MLP_Kalman_trip_cum</th>\n",
              "      <th>LSTM_3H_64</th>\n",
              "      <th>LSTM_3H_64_trip_cum</th>\n",
              "      <th>LSTMGA_2H_32</th>\n",
              "      <th>LSTMGA_2H_32_trip_cum</th>\n",
              "      <th>MLPGA_3H_16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-04-23 07:10:00</td>\n",
              "      <td>Lufthansa-Basis (Haupteingang)|Obenhauptstraße</td>\n",
              "      <td>174.0</td>\n",
              "      <td>174</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>178.261693</td>\n",
              "      <td>178</td>\n",
              "      <td>189.055195</td>\n",
              "      <td>189</td>\n",
              "      <td>172.272097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-23 07:12:00</td>\n",
              "      <td>Obenhauptstraße|Alsterkrugchaussee (Mitte)</td>\n",
              "      <td>48.0</td>\n",
              "      <td>222</td>\n",
              "      <td>123.942955</td>\n",
              "      <td>248</td>\n",
              "      <td>148.804922</td>\n",
              "      <td>273.080989</td>\n",
              "      <td>59.364828</td>\n",
              "      <td>237</td>\n",
              "      <td>61.691786</td>\n",
              "      <td>250</td>\n",
              "      <td>55.095052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-23 07:13:00</td>\n",
              "      <td>Alsterkrugchaussee (Mitte)|Moltrechtweg</td>\n",
              "      <td>60.0</td>\n",
              "      <td>282</td>\n",
              "      <td>124.786484</td>\n",
              "      <td>373</td>\n",
              "      <td>107.759488</td>\n",
              "      <td>380.840477</td>\n",
              "      <td>87.526425</td>\n",
              "      <td>325</td>\n",
              "      <td>88.097661</td>\n",
              "      <td>338</td>\n",
              "      <td>91.779013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-04-23 07:15:00</td>\n",
              "      <td>Moltrechtweg|Brabandstraße</td>\n",
              "      <td>78.0</td>\n",
              "      <td>360</td>\n",
              "      <td>123.004773</td>\n",
              "      <td>496</td>\n",
              "      <td>98.294653</td>\n",
              "      <td>479.135130</td>\n",
              "      <td>70.076247</td>\n",
              "      <td>395</td>\n",
              "      <td>66.803394</td>\n",
              "      <td>405</td>\n",
              "      <td>74.915019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-04-23 07:16:00</td>\n",
              "      <td>Brabandstraße|Hindenburgstraße</td>\n",
              "      <td>132.0</td>\n",
              "      <td>492</td>\n",
              "      <td>123.666688</td>\n",
              "      <td>619</td>\n",
              "      <td>99.839662</td>\n",
              "      <td>578.974793</td>\n",
              "      <td>99.249550</td>\n",
              "      <td>494</td>\n",
              "      <td>106.504281</td>\n",
              "      <td>512</td>\n",
              "      <td>109.731180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1398</th>\n",
              "      <td>2019-04-25 07:41:00</td>\n",
              "      <td>U Habichtstraße|Habichtstraße (Mitte)</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1614</td>\n",
              "      <td>125.380412</td>\n",
              "      <td>1876</td>\n",
              "      <td>118.402453</td>\n",
              "      <td>1783.071842</td>\n",
              "      <td>94.599245</td>\n",
              "      <td>1458</td>\n",
              "      <td>94.112504</td>\n",
              "      <td>1389</td>\n",
              "      <td>97.871538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>2019-04-25 07:43:00</td>\n",
              "      <td>Habichtstraße (Mitte)|U Alter Teichweg</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1866</td>\n",
              "      <td>125.380394</td>\n",
              "      <td>2002</td>\n",
              "      <td>114.813404</td>\n",
              "      <td>1897.885246</td>\n",
              "      <td>227.284139</td>\n",
              "      <td>1686</td>\n",
              "      <td>232.691094</td>\n",
              "      <td>1622</td>\n",
              "      <td>243.765668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>2019-04-25 07:46:00</td>\n",
              "      <td>U Alter Teichweg|U Straßburger Straße</td>\n",
              "      <td>180.0</td>\n",
              "      <td>2046</td>\n",
              "      <td>124.038584</td>\n",
              "      <td>2126</td>\n",
              "      <td>122.162981</td>\n",
              "      <td>2020.048227</td>\n",
              "      <td>169.362381</td>\n",
              "      <td>1855</td>\n",
              "      <td>166.900649</td>\n",
              "      <td>1789</td>\n",
              "      <td>162.962386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1401</th>\n",
              "      <td>2019-04-25 07:48:00</td>\n",
              "      <td>U Straßburger Straße|Wandsbeker Allee</td>\n",
              "      <td>78.0</td>\n",
              "      <td>2124</td>\n",
              "      <td>125.380412</td>\n",
              "      <td>2251</td>\n",
              "      <td>126.822178</td>\n",
              "      <td>2146.870405</td>\n",
              "      <td>71.874325</td>\n",
              "      <td>1927</td>\n",
              "      <td>64.902828</td>\n",
              "      <td>1854</td>\n",
              "      <td>73.035954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1402</th>\n",
              "      <td>2019-04-25 07:49:00</td>\n",
              "      <td>Wandsbeker Allee|U Wandsbek Markt</td>\n",
              "      <td>186.0</td>\n",
              "      <td>2310</td>\n",
              "      <td>125.380412</td>\n",
              "      <td>2376</td>\n",
              "      <td>124.176707</td>\n",
              "      <td>2271.047112</td>\n",
              "      <td>158.606390</td>\n",
              "      <td>2085</td>\n",
              "      <td>169.363149</td>\n",
              "      <td>2023</td>\n",
              "      <td>153.641549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1403 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Date time  ... MLPGA_3H_16\n",
              "0     2019-04-23 07:10:00  ...  172.272097\n",
              "1     2019-04-23 07:12:00  ...   55.095052\n",
              "2     2019-04-23 07:13:00  ...   91.779013\n",
              "3     2019-04-23 07:15:00  ...   74.915019\n",
              "4     2019-04-23 07:16:00  ...  109.731180\n",
              "...                   ...  ...         ...\n",
              "1398  2019-04-25 07:41:00  ...   97.871538\n",
              "1399  2019-04-25 07:43:00  ...  243.765668\n",
              "1400  2019-04-25 07:46:00  ...  162.962386\n",
              "1401  2019-04-25 07:48:00  ...   73.035954\n",
              "1402  2019-04-25 07:49:00  ...  153.641549\n",
              "\n",
              "[1403 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "stream",
          "text": [
            "time: 43.1 ms (started: 2021-01-15 17:39:15 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlL6EP2qNZr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd781fc-023e-46b1-fa34-84955081fe04"
      },
      "source": [
        "if route == 202:\n",
        "  route_unique = np.array(['Lufthansa-Basis (Haupteingang)|Obenhauptstraße',\n",
        "        'Obenhauptstraße|Alsterkrugchaussee (Mitte)',\n",
        "        'Alsterkrugchaussee (Mitte)|Moltrechtweg',\n",
        "        'Moltrechtweg|Brabandstraße', 'Brabandstraße|Hindenburgstraße',\n",
        "        'Hindenburgstraße|U Alsterdorf', 'U Alsterdorf|Sydneystraße',\n",
        "        'Sydneystraße|Manilabrücke', 'Manilabrücke|Kapstadtring',\n",
        "        'Kapstadtring|S Rübenkamp', 'S Rübenkamp|AK Barmbek', 'AK Barmbek|Hartzloh',\n",
        "        'Hartzloh|Habichtsplatz', 'Habichtsplatz|U Habichtstraße',\n",
        "        'U Habichtstraße|Habichtstraße (Mitte)',\n",
        "        'Habichtstraße (Mitte)|U Alter Teichweg',\n",
        "        'U Alter Teichweg|U Straßburger Straße',\n",
        "        'U Straßburger Straße|Wandsbeker Allee',\n",
        "        'Wandsbeker Allee|U Wandsbek Markt'], dtype= object)\n",
        "else:\n",
        "  route_unique = (comb_result.Path.unique())\n",
        "route_unique"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Lufthansa-Basis (Haupteingang)|Obenhauptstraße',\n",
              "       'Obenhauptstraße|Alsterkrugchaussee (Mitte)',\n",
              "       'Alsterkrugchaussee (Mitte)|Moltrechtweg',\n",
              "       'Moltrechtweg|Brabandstraße', 'Brabandstraße|Hindenburgstraße',\n",
              "       'Hindenburgstraße|U Alsterdorf', 'U Alsterdorf|Sydneystraße',\n",
              "       'Sydneystraße|Manilabrücke', 'Manilabrücke|Kapstadtring',\n",
              "       'Kapstadtring|S Rübenkamp', 'S Rübenkamp|AK Barmbek',\n",
              "       'AK Barmbek|Hartzloh', 'Hartzloh|Habichtsplatz',\n",
              "       'Habichtsplatz|U Habichtstraße',\n",
              "       'U Habichtstraße|Habichtstraße (Mitte)',\n",
              "       'Habichtstraße (Mitte)|U Alter Teichweg',\n",
              "       'U Alter Teichweg|U Straßburger Straße',\n",
              "       'U Straßburger Straße|Wandsbeker Allee',\n",
              "       'Wandsbeker Allee|U Wandsbek Markt'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "stream",
          "text": [
            "time: 7.44 ms (started: 2021-01-15 17:41:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVJ84ivTUeqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb66288-47b0-4a3d-f553-1a844904f72e"
      },
      "source": [
        "comb_result['Path']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Lufthansa-Basis (Haupteingang)|Obenhauptstraße\n",
              "1           Obenhauptstraße|Alsterkrugchaussee (Mitte)\n",
              "2              Alsterkrugchaussee (Mitte)|Moltrechtweg\n",
              "3                           Moltrechtweg|Brabandstraße\n",
              "4                       Brabandstraße|Hindenburgstraße\n",
              "                             ...                      \n",
              "1398             U Habichtstraße|Habichtstraße (Mitte)\n",
              "1399            Habichtstraße (Mitte)|U Alter Teichweg\n",
              "1400             U Alter Teichweg|U Straßburger Straße\n",
              "1401             U Straßburger Straße|Wandsbeker Allee\n",
              "1402                 Wandsbeker Allee|U Wandsbek Markt\n",
              "Name: Path, Length: 1403, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.91 ms (started: 2021-01-15 17:41:24 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T_diThVNgxZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1c6982e-3fc7-4deb-e07c-e9f434617626"
      },
      "source": [
        "#add a new column for trip accumulate\n",
        "comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name+'_trip_cum'] = 0\n",
        "a = 0\n",
        "for i in range(len(comb_result)):\n",
        "  if comb_result['Path'][i] == route_unique[0]: #the first path\n",
        "    a = comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name][i]\n",
        "    comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name+'_trip_cum'][i] = a\n",
        "  else:\n",
        "    a += comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name][i] \n",
        "    comb_result['MLPGA_'+str(best_model['n_layers'])+'H_'+bs_name+'_trip_cum'][i] = a\n",
        "comb_result[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date time</th>\n",
              "      <th>Path</th>\n",
              "      <th>Actual</th>\n",
              "      <th>Actual_trip_cum</th>\n",
              "      <th>MLP</th>\n",
              "      <th>MLP_trip_cum</th>\n",
              "      <th>MLP_Kalman</th>\n",
              "      <th>MLP_Kalman_trip_cum</th>\n",
              "      <th>LSTM_3H_64</th>\n",
              "      <th>LSTM_3H_64_trip_cum</th>\n",
              "      <th>LSTMGA_2H_32</th>\n",
              "      <th>LSTMGA_2H_32_trip_cum</th>\n",
              "      <th>MLPGA_3H_16</th>\n",
              "      <th>MLPGA_3H_16_trip_cum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-04-23 07:10:00</td>\n",
              "      <td>Lufthansa-Basis (Haupteingang)|Obenhauptstraße</td>\n",
              "      <td>174.0</td>\n",
              "      <td>174</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>178.261693</td>\n",
              "      <td>178</td>\n",
              "      <td>189.055195</td>\n",
              "      <td>189</td>\n",
              "      <td>172.272097</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-23 07:12:00</td>\n",
              "      <td>Obenhauptstraße|Alsterkrugchaussee (Mitte)</td>\n",
              "      <td>48.0</td>\n",
              "      <td>222</td>\n",
              "      <td>123.942955</td>\n",
              "      <td>248</td>\n",
              "      <td>148.804922</td>\n",
              "      <td>273.080989</td>\n",
              "      <td>59.364828</td>\n",
              "      <td>237</td>\n",
              "      <td>61.691786</td>\n",
              "      <td>250</td>\n",
              "      <td>55.095052</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-23 07:13:00</td>\n",
              "      <td>Alsterkrugchaussee (Mitte)|Moltrechtweg</td>\n",
              "      <td>60.0</td>\n",
              "      <td>282</td>\n",
              "      <td>124.786484</td>\n",
              "      <td>373</td>\n",
              "      <td>107.759488</td>\n",
              "      <td>380.840477</td>\n",
              "      <td>87.526425</td>\n",
              "      <td>325</td>\n",
              "      <td>88.097661</td>\n",
              "      <td>338</td>\n",
              "      <td>91.779013</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-04-23 07:15:00</td>\n",
              "      <td>Moltrechtweg|Brabandstraße</td>\n",
              "      <td>78.0</td>\n",
              "      <td>360</td>\n",
              "      <td>123.004773</td>\n",
              "      <td>496</td>\n",
              "      <td>98.294653</td>\n",
              "      <td>479.135130</td>\n",
              "      <td>70.076247</td>\n",
              "      <td>395</td>\n",
              "      <td>66.803394</td>\n",
              "      <td>405</td>\n",
              "      <td>74.915019</td>\n",
              "      <td>394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-04-23 07:16:00</td>\n",
              "      <td>Brabandstraße|Hindenburgstraße</td>\n",
              "      <td>132.0</td>\n",
              "      <td>492</td>\n",
              "      <td>123.666688</td>\n",
              "      <td>619</td>\n",
              "      <td>99.839662</td>\n",
              "      <td>578.974793</td>\n",
              "      <td>99.249550</td>\n",
              "      <td>494</td>\n",
              "      <td>106.504281</td>\n",
              "      <td>512</td>\n",
              "      <td>109.731180</td>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2019-04-23 07:18:00</td>\n",
              "      <td>Hindenburgstraße|U Alsterdorf</td>\n",
              "      <td>78.0</td>\n",
              "      <td>570</td>\n",
              "      <td>123.158095</td>\n",
              "      <td>742</td>\n",
              "      <td>108.662296</td>\n",
              "      <td>687.637089</td>\n",
              "      <td>77.428864</td>\n",
              "      <td>571</td>\n",
              "      <td>73.940580</td>\n",
              "      <td>586</td>\n",
              "      <td>80.772079</td>\n",
              "      <td>584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2019-04-23 07:19:00</td>\n",
              "      <td>U Alsterdorf|Sydneystraße</td>\n",
              "      <td>102.0</td>\n",
              "      <td>672</td>\n",
              "      <td>122.702851</td>\n",
              "      <td>865</td>\n",
              "      <td>105.897553</td>\n",
              "      <td>793.534642</td>\n",
              "      <td>120.259061</td>\n",
              "      <td>692</td>\n",
              "      <td>130.223636</td>\n",
              "      <td>716</td>\n",
              "      <td>126.591069</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2019-04-23 07:21:00</td>\n",
              "      <td>Sydneystraße|Manilabrücke</td>\n",
              "      <td>30.0</td>\n",
              "      <td>702</td>\n",
              "      <td>124.994357</td>\n",
              "      <td>990</td>\n",
              "      <td>109.802527</td>\n",
              "      <td>903.337169</td>\n",
              "      <td>47.981692</td>\n",
              "      <td>740</td>\n",
              "      <td>46.763797</td>\n",
              "      <td>763</td>\n",
              "      <td>44.802138</td>\n",
              "      <td>755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2019-04-23 07:22:00</td>\n",
              "      <td>Manilabrücke|Kapstadtring</td>\n",
              "      <td>36.0</td>\n",
              "      <td>738</td>\n",
              "      <td>125.038731</td>\n",
              "      <td>1115</td>\n",
              "      <td>102.667935</td>\n",
              "      <td>1006.005104</td>\n",
              "      <td>89.594617</td>\n",
              "      <td>829</td>\n",
              "      <td>92.074744</td>\n",
              "      <td>855</td>\n",
              "      <td>90.022274</td>\n",
              "      <td>845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2019-04-23 07:23:00</td>\n",
              "      <td>Kapstadtring|S Rübenkamp</td>\n",
              "      <td>150.0</td>\n",
              "      <td>888</td>\n",
              "      <td>124.414995</td>\n",
              "      <td>1239</td>\n",
              "      <td>97.614485</td>\n",
              "      <td>1103.619588</td>\n",
              "      <td>101.137898</td>\n",
              "      <td>930</td>\n",
              "      <td>100.550616</td>\n",
              "      <td>955</td>\n",
              "      <td>104.710939</td>\n",
              "      <td>950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2019-04-23 07:25:00</td>\n",
              "      <td>S Rübenkamp|AK Barmbek</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1020</td>\n",
              "      <td>123.943145</td>\n",
              "      <td>1363</td>\n",
              "      <td>104.341364</td>\n",
              "      <td>1207.960952</td>\n",
              "      <td>164.015910</td>\n",
              "      <td>1094</td>\n",
              "      <td>171.654402</td>\n",
              "      <td>1127</td>\n",
              "      <td>170.104981</td>\n",
              "      <td>1120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2019-04-23 07:27:00</td>\n",
              "      <td>AK Barmbek|Hartzloh</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1080</td>\n",
              "      <td>125.380449</td>\n",
              "      <td>1489</td>\n",
              "      <td>109.717036</td>\n",
              "      <td>1317.677988</td>\n",
              "      <td>73.733881</td>\n",
              "      <td>1168</td>\n",
              "      <td>71.239162</td>\n",
              "      <td>1198</td>\n",
              "      <td>77.872409</td>\n",
              "      <td>1198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2019-04-23 07:28:00</td>\n",
              "      <td>Hartzloh|Habichtsplatz</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1212</td>\n",
              "      <td>123.881298</td>\n",
              "      <td>1613</td>\n",
              "      <td>105.598376</td>\n",
              "      <td>1423.276364</td>\n",
              "      <td>136.324681</td>\n",
              "      <td>1304</td>\n",
              "      <td>139.136466</td>\n",
              "      <td>1337</td>\n",
              "      <td>145.035101</td>\n",
              "      <td>1343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2019-04-23 07:30:00</td>\n",
              "      <td>Habichtsplatz|U Habichtstraße</td>\n",
              "      <td>54.0</td>\n",
              "      <td>1266</td>\n",
              "      <td>123.168913</td>\n",
              "      <td>1736</td>\n",
              "      <td>108.077744</td>\n",
              "      <td>1531.354108</td>\n",
              "      <td>96.549540</td>\n",
              "      <td>1401</td>\n",
              "      <td>104.373186</td>\n",
              "      <td>1442</td>\n",
              "      <td>98.667605</td>\n",
              "      <td>1442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2019-04-23 07:31:00</td>\n",
              "      <td>U Habichtstraße|Habichtstraße (Mitte)</td>\n",
              "      <td>66.0</td>\n",
              "      <td>1332</td>\n",
              "      <td>125.380421</td>\n",
              "      <td>1861</td>\n",
              "      <td>107.690148</td>\n",
              "      <td>1639.044256</td>\n",
              "      <td>97.415870</td>\n",
              "      <td>1498</td>\n",
              "      <td>125.256176</td>\n",
              "      <td>1567</td>\n",
              "      <td>98.476230</td>\n",
              "      <td>1540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2019-04-23 07:33:00</td>\n",
              "      <td>Habichtstraße (Mitte)|U Alter Teichweg</td>\n",
              "      <td>288.0</td>\n",
              "      <td>1620</td>\n",
              "      <td>125.380403</td>\n",
              "      <td>1987</td>\n",
              "      <td>106.190137</td>\n",
              "      <td>1745.234393</td>\n",
              "      <td>220.342843</td>\n",
              "      <td>1719</td>\n",
              "      <td>257.156119</td>\n",
              "      <td>1824</td>\n",
              "      <td>226.882841</td>\n",
              "      <td>1767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2019-04-23 07:36:00</td>\n",
              "      <td>U Alter Teichweg|U Straßburger Straße</td>\n",
              "      <td>318.0</td>\n",
              "      <td>1938</td>\n",
              "      <td>125.380449</td>\n",
              "      <td>2112</td>\n",
              "      <td>118.013720</td>\n",
              "      <td>1863.248112</td>\n",
              "      <td>166.442479</td>\n",
              "      <td>1885</td>\n",
              "      <td>168.974240</td>\n",
              "      <td>1993</td>\n",
              "      <td>161.066642</td>\n",
              "      <td>1928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2019-04-23 07:38:00</td>\n",
              "      <td>U Straßburger Straße|Wandsbeker Allee</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1986</td>\n",
              "      <td>123.180246</td>\n",
              "      <td>2235</td>\n",
              "      <td>127.333128</td>\n",
              "      <td>1990.581241</td>\n",
              "      <td>72.333019</td>\n",
              "      <td>1958</td>\n",
              "      <td>75.203811</td>\n",
              "      <td>2068</td>\n",
              "      <td>72.372729</td>\n",
              "      <td>2001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2019-04-23 07:39:00</td>\n",
              "      <td>Wandsbeker Allee|U Wandsbek Markt</td>\n",
              "      <td>246.0</td>\n",
              "      <td>2232</td>\n",
              "      <td>125.380412</td>\n",
              "      <td>2361</td>\n",
              "      <td>125.139294</td>\n",
              "      <td>2115.720535</td>\n",
              "      <td>158.119974</td>\n",
              "      <td>2116</td>\n",
              "      <td>169.435399</td>\n",
              "      <td>2238</td>\n",
              "      <td>152.770667</td>\n",
              "      <td>2153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2019-04-23 08:40:00</td>\n",
              "      <td>Lufthansa-Basis (Haupteingang)|Obenhauptstraße</td>\n",
              "      <td>138.0</td>\n",
              "      <td>138</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>124.276067</td>\n",
              "      <td>171.891822</td>\n",
              "      <td>171</td>\n",
              "      <td>180.786149</td>\n",
              "      <td>180</td>\n",
              "      <td>172.272097</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2019-04-23 08:42:00</td>\n",
              "      <td>Obenhauptstraße|Alsterkrugchaussee (Mitte)</td>\n",
              "      <td>36.0</td>\n",
              "      <td>174</td>\n",
              "      <td>123.942955</td>\n",
              "      <td>248</td>\n",
              "      <td>130.804922</td>\n",
              "      <td>255.080989</td>\n",
              "      <td>51.573948</td>\n",
              "      <td>223</td>\n",
              "      <td>53.210162</td>\n",
              "      <td>233</td>\n",
              "      <td>55.095052</td>\n",
              "      <td>227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2019-04-23 08:43:00</td>\n",
              "      <td>Alsterkrugchaussee (Mitte)|Moltrechtweg</td>\n",
              "      <td>48.0</td>\n",
              "      <td>222</td>\n",
              "      <td>124.786484</td>\n",
              "      <td>373</td>\n",
              "      <td>97.759488</td>\n",
              "      <td>352.840477</td>\n",
              "      <td>89.311948</td>\n",
              "      <td>312</td>\n",
              "      <td>102.731170</td>\n",
              "      <td>336</td>\n",
              "      <td>91.779013</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2019-04-23 08:45:00</td>\n",
              "      <td>Moltrechtweg|Brabandstraße</td>\n",
              "      <td>90.0</td>\n",
              "      <td>312</td>\n",
              "      <td>123.004773</td>\n",
              "      <td>496</td>\n",
              "      <td>90.294653</td>\n",
              "      <td>443.135130</td>\n",
              "      <td>69.795885</td>\n",
              "      <td>382</td>\n",
              "      <td>68.311439</td>\n",
              "      <td>405</td>\n",
              "      <td>74.915019</td>\n",
              "      <td>394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2019-04-23 08:46:00</td>\n",
              "      <td>Brabandstraße|Hindenburgstraße</td>\n",
              "      <td>156.0</td>\n",
              "      <td>468</td>\n",
              "      <td>123.666688</td>\n",
              "      <td>619</td>\n",
              "      <td>97.439662</td>\n",
              "      <td>540.574793</td>\n",
              "      <td>100.261256</td>\n",
              "      <td>482</td>\n",
              "      <td>109.193256</td>\n",
              "      <td>514</td>\n",
              "      <td>109.731180</td>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2019-04-23 08:48:00</td>\n",
              "      <td>Hindenburgstraße|U Alsterdorf</td>\n",
              "      <td>54.0</td>\n",
              "      <td>522</td>\n",
              "      <td>123.158095</td>\n",
              "      <td>742</td>\n",
              "      <td>111.062296</td>\n",
              "      <td>651.637089</td>\n",
              "      <td>76.317389</td>\n",
              "      <td>559</td>\n",
              "      <td>64.773237</td>\n",
              "      <td>579</td>\n",
              "      <td>80.772079</td>\n",
              "      <td>584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2019-04-23 08:49:00</td>\n",
              "      <td>U Alsterdorf|Sydneystraße</td>\n",
              "      <td>114.0</td>\n",
              "      <td>636</td>\n",
              "      <td>122.702851</td>\n",
              "      <td>865</td>\n",
              "      <td>104.183267</td>\n",
              "      <td>755.820356</td>\n",
              "      <td>119.525338</td>\n",
              "      <td>678</td>\n",
              "      <td>124.180926</td>\n",
              "      <td>703</td>\n",
              "      <td>126.591060</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2019-04-23 08:51:00</td>\n",
              "      <td>Sydneystraße|Manilabrücke</td>\n",
              "      <td>24.0</td>\n",
              "      <td>660</td>\n",
              "      <td>124.994357</td>\n",
              "      <td>990</td>\n",
              "      <td>110.016813</td>\n",
              "      <td>865.837169</td>\n",
              "      <td>47.032077</td>\n",
              "      <td>725</td>\n",
              "      <td>33.866127</td>\n",
              "      <td>737</td>\n",
              "      <td>44.802138</td>\n",
              "      <td>755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2019-04-23 08:52:00</td>\n",
              "      <td>Manilabrücke|Kapstadtring</td>\n",
              "      <td>54.0</td>\n",
              "      <td>714</td>\n",
              "      <td>125.038731</td>\n",
              "      <td>1115</td>\n",
              "      <td>102.167935</td>\n",
              "      <td>968.005104</td>\n",
              "      <td>89.922618</td>\n",
              "      <td>815</td>\n",
              "      <td>85.474208</td>\n",
              "      <td>822</td>\n",
              "      <td>90.022274</td>\n",
              "      <td>845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2019-04-23 08:53:00</td>\n",
              "      <td>Kapstadtring|S Rübenkamp</td>\n",
              "      <td>72.0</td>\n",
              "      <td>786</td>\n",
              "      <td>124.414995</td>\n",
              "      <td>1239</td>\n",
              "      <td>99.014485</td>\n",
              "      <td>1067.019588</td>\n",
              "      <td>100.008494</td>\n",
              "      <td>915</td>\n",
              "      <td>94.665923</td>\n",
              "      <td>917</td>\n",
              "      <td>104.710939</td>\n",
              "      <td>950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2019-04-23 08:55:00</td>\n",
              "      <td>S Rübenkamp|AK Barmbek</td>\n",
              "      <td>186.0</td>\n",
              "      <td>972</td>\n",
              "      <td>123.943145</td>\n",
              "      <td>1363</td>\n",
              "      <td>98.395910</td>\n",
              "      <td>1165.415498</td>\n",
              "      <td>162.710265</td>\n",
              "      <td>1078</td>\n",
              "      <td>169.077951</td>\n",
              "      <td>1086</td>\n",
              "      <td>170.104981</td>\n",
              "      <td>1120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2019-04-23 08:58:00</td>\n",
              "      <td>AK Barmbek|Hartzloh</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1008</td>\n",
              "      <td>125.380449</td>\n",
              "      <td>1489</td>\n",
              "      <td>109.262490</td>\n",
              "      <td>1274.677988</td>\n",
              "      <td>73.229514</td>\n",
              "      <td>1151</td>\n",
              "      <td>66.158943</td>\n",
              "      <td>1152</td>\n",
              "      <td>77.872409</td>\n",
              "      <td>1198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2019-04-23 08:59:00</td>\n",
              "      <td>Hartzloh|Habichtsplatz</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1164</td>\n",
              "      <td>123.881298</td>\n",
              "      <td>1613</td>\n",
              "      <td>103.367606</td>\n",
              "      <td>1378.045595</td>\n",
              "      <td>135.437961</td>\n",
              "      <td>1287</td>\n",
              "      <td>137.056300</td>\n",
              "      <td>1289</td>\n",
              "      <td>145.035101</td>\n",
              "      <td>1343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2019-04-23 09:02:00</td>\n",
              "      <td>Habichtsplatz|U Habichtstraße</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1248</td>\n",
              "      <td>123.168913</td>\n",
              "      <td>1736</td>\n",
              "      <td>107.879942</td>\n",
              "      <td>1485.925537</td>\n",
              "      <td>94.941748</td>\n",
              "      <td>1381</td>\n",
              "      <td>102.685468</td>\n",
              "      <td>1392</td>\n",
              "      <td>98.667605</td>\n",
              "      <td>1442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2019-04-23 09:03:00</td>\n",
              "      <td>U Habichtstraße|Habichtstraße (Mitte)</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1332</td>\n",
              "      <td>125.380421</td>\n",
              "      <td>1861</td>\n",
              "      <td>109.518719</td>\n",
              "      <td>1595.444256</td>\n",
              "      <td>96.839542</td>\n",
              "      <td>1478</td>\n",
              "      <td>123.053066</td>\n",
              "      <td>1515</td>\n",
              "      <td>98.476230</td>\n",
              "      <td>1540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2019-04-23 09:05:00</td>\n",
              "      <td>Habichtstraße (Mitte)|U Alter Teichweg</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1452</td>\n",
              "      <td>125.380403</td>\n",
              "      <td>1987</td>\n",
              "      <td>108.915137</td>\n",
              "      <td>1704.359393</td>\n",
              "      <td>216.905967</td>\n",
              "      <td>1695</td>\n",
              "      <td>256.307543</td>\n",
              "      <td>1771</td>\n",
              "      <td>226.882841</td>\n",
              "      <td>1767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2019-04-23 09:08:00</td>\n",
              "      <td>U Alter Teichweg|U Straßburger Straße</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1590</td>\n",
              "      <td>125.380449</td>\n",
              "      <td>2112</td>\n",
              "      <td>110.535778</td>\n",
              "      <td>1814.895171</td>\n",
              "      <td>165.627639</td>\n",
              "      <td>1861</td>\n",
              "      <td>168.260393</td>\n",
              "      <td>1939</td>\n",
              "      <td>161.066642</td>\n",
              "      <td>1928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2019-04-23 09:10:00</td>\n",
              "      <td>U Straßburger Straße|Wandsbeker Allee</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1638</td>\n",
              "      <td>123.180246</td>\n",
              "      <td>2235</td>\n",
              "      <td>110.686070</td>\n",
              "      <td>1925.581241</td>\n",
              "      <td>72.241675</td>\n",
              "      <td>1933</td>\n",
              "      <td>74.448677</td>\n",
              "      <td>2014</td>\n",
              "      <td>72.372729</td>\n",
              "      <td>2001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2019-04-23 09:11:00</td>\n",
              "      <td>Wandsbeker Allee|U Wandsbek Markt</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1794</td>\n",
              "      <td>125.380412</td>\n",
              "      <td>2361</td>\n",
              "      <td>110.244558</td>\n",
              "      <td>2035.825798</td>\n",
              "      <td>158.068087</td>\n",
              "      <td>2091</td>\n",
              "      <td>169.243328</td>\n",
              "      <td>2183</td>\n",
              "      <td>152.770667</td>\n",
              "      <td>2153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2019-04-23 10:20:00</td>\n",
              "      <td>Lufthansa-Basis (Haupteingang)|Obenhauptstraße</td>\n",
              "      <td>222.0</td>\n",
              "      <td>222</td>\n",
              "      <td>120.722847</td>\n",
              "      <td>120</td>\n",
              "      <td>120.722847</td>\n",
              "      <td>120.722847</td>\n",
              "      <td>171.891822</td>\n",
              "      <td>171</td>\n",
              "      <td>180.786149</td>\n",
              "      <td>180</td>\n",
              "      <td>171.591896</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2019-04-23 10:22:00</td>\n",
              "      <td>Obenhauptstraße|Alsterkrugchaussee (Mitte)</td>\n",
              "      <td>30.0</td>\n",
              "      <td>252</td>\n",
              "      <td>120.389736</td>\n",
              "      <td>241</td>\n",
              "      <td>171.028312</td>\n",
              "      <td>291.751160</td>\n",
              "      <td>49.975773</td>\n",
              "      <td>221</td>\n",
              "      <td>52.505272</td>\n",
              "      <td>233</td>\n",
              "      <td>53.373381</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2019-04-23 10:23:00</td>\n",
              "      <td>Alsterkrugchaussee (Mitte)|Moltrechtweg</td>\n",
              "      <td>78.0</td>\n",
              "      <td>330</td>\n",
              "      <td>121.233283</td>\n",
              "      <td>362</td>\n",
              "      <td>107.982897</td>\n",
              "      <td>399.734056</td>\n",
              "      <td>89.099582</td>\n",
              "      <td>310</td>\n",
              "      <td>94.583117</td>\n",
              "      <td>327</td>\n",
              "      <td>90.821212</td>\n",
              "      <td>315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2019-04-23 10:25:00</td>\n",
              "      <td>Moltrechtweg|Brabandstraße</td>\n",
              "      <td>60.0</td>\n",
              "      <td>390</td>\n",
              "      <td>119.451562</td>\n",
              "      <td>481</td>\n",
              "      <td>102.018048</td>\n",
              "      <td>501.752105</td>\n",
              "      <td>69.241874</td>\n",
              "      <td>380</td>\n",
              "      <td>68.124101</td>\n",
              "      <td>395</td>\n",
              "      <td>72.015416</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2019-04-23 10:26:00</td>\n",
              "      <td>Brabandstraße|Hindenburgstraße</td>\n",
              "      <td>126.0</td>\n",
              "      <td>516</td>\n",
              "      <td>120.113469</td>\n",
              "      <td>601</td>\n",
              "      <td>97.763048</td>\n",
              "      <td>599.515153</td>\n",
              "      <td>101.959051</td>\n",
              "      <td>482</td>\n",
              "      <td>108.083393</td>\n",
              "      <td>504</td>\n",
              "      <td>110.765442</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2019-04-23 10:28:00</td>\n",
              "      <td>Hindenburgstraße|U Alsterdorf</td>\n",
              "      <td>120.0</td>\n",
              "      <td>636</td>\n",
              "      <td>119.604866</td>\n",
              "      <td>721</td>\n",
              "      <td>105.685674</td>\n",
              "      <td>705.200827</td>\n",
              "      <td>74.717792</td>\n",
              "      <td>556</td>\n",
              "      <td>59.452384</td>\n",
              "      <td>563</td>\n",
              "      <td>79.911244</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2019-04-23 10:29:00</td>\n",
              "      <td>U Alsterdorf|Sydneystraße</td>\n",
              "      <td>120.0</td>\n",
              "      <td>756</td>\n",
              "      <td>119.149641</td>\n",
              "      <td>840</td>\n",
              "      <td>109.263808</td>\n",
              "      <td>814.464635</td>\n",
              "      <td>116.192896</td>\n",
              "      <td>673</td>\n",
              "      <td>106.880728</td>\n",
              "      <td>670</td>\n",
              "      <td>125.488214</td>\n",
              "      <td>703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2019-04-23 10:31:00</td>\n",
              "      <td>Sydneystraße|Manilabrücke</td>\n",
              "      <td>24.0</td>\n",
              "      <td>780</td>\n",
              "      <td>121.441147</td>\n",
              "      <td>962</td>\n",
              "      <td>114.133068</td>\n",
              "      <td>928.597703</td>\n",
              "      <td>46.333643</td>\n",
              "      <td>719</td>\n",
              "      <td>31.710811</td>\n",
              "      <td>702</td>\n",
              "      <td>41.955885</td>\n",
              "      <td>745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2019-04-23 10:32:00</td>\n",
              "      <td>Manilabrücke|Kapstadtring</td>\n",
              "      <td>54.0</td>\n",
              "      <td>834</td>\n",
              "      <td>121.485521</td>\n",
              "      <td>1083</td>\n",
              "      <td>104.974665</td>\n",
              "      <td>1033.572368</td>\n",
              "      <td>89.129373</td>\n",
              "      <td>808</td>\n",
              "      <td>96.095786</td>\n",
              "      <td>798</td>\n",
              "      <td>87.585320</td>\n",
              "      <td>833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2019-04-23 10:33:00</td>\n",
              "      <td>Kapstadtring|S Rübenkamp</td>\n",
              "      <td>168.0</td>\n",
              "      <td>1002</td>\n",
              "      <td>120.861758</td>\n",
              "      <td>1204</td>\n",
              "      <td>100.904521</td>\n",
              "      <td>1134.476889</td>\n",
              "      <td>100.003907</td>\n",
              "      <td>908</td>\n",
              "      <td>109.510655</td>\n",
              "      <td>907</td>\n",
              "      <td>113.072842</td>\n",
              "      <td>946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2019-04-23 10:35:00</td>\n",
              "      <td>S Rübenkamp|AK Barmbek</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1146</td>\n",
              "      <td>120.389908</td>\n",
              "      <td>1324</td>\n",
              "      <td>108.346554</td>\n",
              "      <td>1242.823443</td>\n",
              "      <td>166.262563</td>\n",
              "      <td>1074</td>\n",
              "      <td>178.888454</td>\n",
              "      <td>1086</td>\n",
              "      <td>172.742168</td>\n",
              "      <td>1119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2019-04-23 10:38:00</td>\n",
              "      <td>AK Barmbek|Hartzloh</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1224</td>\n",
              "      <td>122.782542</td>\n",
              "      <td>1447</td>\n",
              "      <td>114.713922</td>\n",
              "      <td>1357.537364</td>\n",
              "      <td>75.283894</td>\n",
              "      <td>1150</td>\n",
              "      <td>84.049023</td>\n",
              "      <td>1170</td>\n",
              "      <td>77.875425</td>\n",
              "      <td>1197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date time  ... MLPGA_3H_16_trip_cum\n",
              "0   2019-04-23 07:10:00  ...                  172\n",
              "1   2019-04-23 07:12:00  ...                  227\n",
              "2   2019-04-23 07:13:00  ...                  319\n",
              "3   2019-04-23 07:15:00  ...                  394\n",
              "4   2019-04-23 07:16:00  ...                  503\n",
              "5   2019-04-23 07:18:00  ...                  584\n",
              "6   2019-04-23 07:19:00  ...                  711\n",
              "7   2019-04-23 07:21:00  ...                  755\n",
              "8   2019-04-23 07:22:00  ...                  845\n",
              "9   2019-04-23 07:23:00  ...                  950\n",
              "10  2019-04-23 07:25:00  ...                 1120\n",
              "11  2019-04-23 07:27:00  ...                 1198\n",
              "12  2019-04-23 07:28:00  ...                 1343\n",
              "13  2019-04-23 07:30:00  ...                 1442\n",
              "14  2019-04-23 07:31:00  ...                 1540\n",
              "15  2019-04-23 07:33:00  ...                 1767\n",
              "16  2019-04-23 07:36:00  ...                 1928\n",
              "17  2019-04-23 07:38:00  ...                 2001\n",
              "18  2019-04-23 07:39:00  ...                 2153\n",
              "19  2019-04-23 08:40:00  ...                  172\n",
              "20  2019-04-23 08:42:00  ...                  227\n",
              "21  2019-04-23 08:43:00  ...                  319\n",
              "22  2019-04-23 08:45:00  ...                  394\n",
              "23  2019-04-23 08:46:00  ...                  503\n",
              "24  2019-04-23 08:48:00  ...                  584\n",
              "25  2019-04-23 08:49:00  ...                  711\n",
              "26  2019-04-23 08:51:00  ...                  755\n",
              "27  2019-04-23 08:52:00  ...                  845\n",
              "28  2019-04-23 08:53:00  ...                  950\n",
              "29  2019-04-23 08:55:00  ...                 1120\n",
              "30  2019-04-23 08:58:00  ...                 1198\n",
              "31  2019-04-23 08:59:00  ...                 1343\n",
              "32  2019-04-23 09:02:00  ...                 1442\n",
              "33  2019-04-23 09:03:00  ...                 1540\n",
              "34  2019-04-23 09:05:00  ...                 1767\n",
              "35  2019-04-23 09:08:00  ...                 1928\n",
              "36  2019-04-23 09:10:00  ...                 2001\n",
              "37  2019-04-23 09:11:00  ...                 2153\n",
              "38  2019-04-23 10:20:00  ...                  171\n",
              "39  2019-04-23 10:22:00  ...                  224\n",
              "40  2019-04-23 10:23:00  ...                  315\n",
              "41  2019-04-23 10:25:00  ...                  387\n",
              "42  2019-04-23 10:26:00  ...                  498\n",
              "43  2019-04-23 10:28:00  ...                  578\n",
              "44  2019-04-23 10:29:00  ...                  703\n",
              "45  2019-04-23 10:31:00  ...                  745\n",
              "46  2019-04-23 10:32:00  ...                  833\n",
              "47  2019-04-23 10:33:00  ...                  946\n",
              "48  2019-04-23 10:35:00  ...                 1119\n",
              "49  2019-04-23 10:38:00  ...                 1197\n",
              "\n",
              "[50 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "stream",
          "text": [
            "time: 181 ms (started: 2021-01-15 17:41:52 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKyin5mMmQQW"
      },
      "source": [
        "# Export data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFZbMxb3lwvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ae9c41-89dc-4e4f-c314-03c276419357"
      },
      "source": [
        "#path_file = 'combine_result'+path_end+'.csv'\n",
        "#comb_result.to_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/Mon_1_5_combine_result_\"+path_end+\".csv\")\n",
        "#comb_result_rmse.to_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/Mon_1_5_combine_result_rmse_\"+path_end+\".csv\")\n",
        "#!cp path_file \"/content/drive/My Drive/Colab Notebooks/Thesis\"\n",
        "\n",
        "comb_result.to_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/combine_result_\"+path_end+\"_m\"+str(month)+\".csv\")\n",
        "#comb_result_rmse.to_csv(\"/content/drive/My Drive/Colab Notebooks/Thesis/combine_result_rmse_\"+path_end+\"_m\"+str(month)+\".csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 746 ms (started: 2021-01-15 17:42:32 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}